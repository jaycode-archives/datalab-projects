{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from cStringIO import StringIO\n",
    "import gzip\n",
    "import os\n",
    "import glob\n",
    "import re\n",
    "import pdb\n",
    "\n",
    "import gcp\n",
    "from gcp import storage\n",
    "from gcp import bigquery as bq\n",
    "import pandas as pd\n",
    "\n",
    "# Import zip file from Google Cloud Storage\n",
    "project = gcp.Context.default().project_id\n",
    "bucket_name = project + '-datalab'\n",
    "bucket_path = 'gs://' + bucket_name + '/data'\n",
    "print 'Bucket: ' + bucket_path\n",
    "compressed_filename = 'citydata2'\n",
    "season_name = 'season_2'\n",
    "subdirectory_name = 'training_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Downloading and extracting the files from cloud storage.\n",
    "\n",
    "def process_datafile(localpath, storagepath, table, mode='create', overwrite=False):\n",
    "  global compressed_filename\n",
    "  gzip_filename = '{}.tar.gz'.format(compressed_filename)\n",
    "  tar_filename = '{}.tar'.format(compressed_filename)\n",
    "  datadir = 'season_2'\n",
    "  storagepath_r = storagepath.split('/')\n",
    "  # If data has not been extracted, extract it.\n",
    "  if not os.path.isdir(datadir):\n",
    "    # If citydata.tar has not been downloaded, download it\n",
    "    if not os.path.isfile(tar_filename):\n",
    "      \n",
    "      bucket_object = '{}/{}.tar.gz'.format('/'.join(storagepath_r[:3]), compressed_filename)\n",
    "      %storage read --object $bucket_object --variable compressed_file\n",
    "      \n",
    "      gzip_file = gzip.GzipFile(fileobj=StringIO(compressed_file))\n",
    "      del compressed_file\n",
    "\n",
    "      import shutil\n",
    "      with open(tar_filename, 'wb') as f_out:\n",
    "        shutil.copyfileobj(gzip_file, f_out)\n",
    "\n",
    "    import tarfile\n",
    "    tar = tarfile.open(tar_filename, \"r\")\n",
    "    tar.extractall()\n",
    "    tar.close()\n",
    "    os.remove(tar_filename)\n",
    "\n",
    "  # Upload extracted file into GCS\n",
    "  bucketname = storagepath_r[2]\n",
    "  itempath = '/'.join(storagepath_r[3:])\n",
    "  item = storage.Item(bucketname, itempath)\n",
    "  if not item.exists() or overwrite:    \n",
    "    with open(localpath, 'rb') as f:\n",
    "      item.write_to(f.read(), 'text/plain')\n",
    "  # Load data into Google BigQuery\n",
    "  table.load(storagepath, mode=mode, csv_options=bq.CSVOptions(delimiter='\\t'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process Training Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Districts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "table = bq.Table('datalab-projects-1331:xjk_algo_comp.districts')\n",
    "if not table.exists():\n",
    "  schema = bq.Schema([\n",
    "      {'name': 'district_hash', 'type': 'STRING'},\n",
    "      {'name': 'district_id', 'type': 'INTEGER'}\n",
    "    ])\n",
    "  table.create(schema)\n",
    "  \n",
    "  localpath = '{}/{}/cluster_map/cluster_map'.format(season_name, subdirectory_name)\n",
    "  storagepath = os.path.join(bucket_path,localpath)\n",
    "  process_datafile(localpath, storagepath, table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "table = bq.Table('datalab-projects-1331:xjk_algo_comp.weather')\n",
    "if not table.exists():\n",
    "  schema = bq.Schema([\n",
    "      {'name': 'time', 'type': 'STRING'},\n",
    "      {'name': 'weather', 'type': 'INTEGER'},\n",
    "      {'name': 'temperature', 'type': 'FLOAT'},\n",
    "      {'name': 'pm25', 'type': 'FLOAT'}\n",
    "    ])\n",
    "  table.create(schema)\n",
    "  \n",
    "  wildpath = '{}/{}/weather_data/*'.format(season_name, subdirectory_name)\n",
    "  for localpath in glob.glob(wildpath):\n",
    "    storagepath = os.path.join(bucket_path,localpath)\n",
    "    process_datafile(localpath, storagepath, table, mode='append')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bigquery udf --module transform_weather_time\n",
    "\n",
    "/**\n",
    " * Pad with 0 or given string.\n",
    " *\n",
    " * @param int n Number to add padding to.\n",
    " * @param int width Width of number + padding.\n",
    " * @param string z (Optional) Other string to replace '0' as padding.\n",
    " */\n",
    "function pad(n, width, z) {\n",
    "  z = z || '0';\n",
    "  n = n + '';\n",
    "  return n.length >= width ? n : new Array(width - n.length + 1).join(z) + n;\n",
    "}\n",
    "\n",
    "/**\n",
    " * Transform timestamps of weather table into timeslots in weather table.\n",
    " *\n",
    " * @param {{time: string, weather: integer, temperature: float, pm25: float}} r\n",
    " * @param function({{time: string, weather: integer, temperature: float, pm25: float,\n",
    "                     timeslot: string}}) emitFn\n",
    " */\n",
    "function(r, emitFn) {\n",
    "  var t = r.time.split(/[ :\\-]/);\n",
    "  var slot = Math.floor((parseInt(t[3]) * 60 + parseInt(t[4])) / 10) + 1;\n",
    "  r.timeslot = t[0] + '-' + pad(t[1], 2) +\n",
    "               '-' + pad(t[2], 2) + '-' + slot;\n",
    "  emitFn(r);\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bigquery execute -t datalab-projects-1331:xjk_algo_comp.weather -m overwrite\n",
    "SELECT time, weather, temperature, pm25, timeslot\n",
    "FROM transform_weather_time([datalab-projects-1331:xjk_algo_comp.weather])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Traffic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "table = bq.Table('datalab-projects-1331:xjk_algo_comp.traffic')\n",
    "if not table.exists():\n",
    "  schema = bq.Schema([\n",
    "      {'name': 'district_hash', 'type': 'STRING'},\n",
    "      {'name': 'tj_level1', 'type': 'INTEGER'},\n",
    "      {'name': 'tj_level2', 'type': 'INTEGER'},\n",
    "      {'name': 'tj_level3', 'type': 'INTEGER'},\n",
    "      {'name': 'tj_level4', 'type': 'INTEGER'},\n",
    "      {'name': 'tj_time', 'type': 'STRING'}\n",
    "    ])\n",
    "  table.create(schema)\n",
    "  \n",
    "  wildpath = '{}/{}/traffic_data/*'.format(season_name, subdirectory_name)\n",
    "  for localpath in glob.glob(wildpath):\n",
    "    with open(localpath, 'rb') as f:\n",
    "      text = f.read()\n",
    "    with open(localpath, 'wb') as f:\n",
    "      f.write(re.sub(r'\\b\\t[0-9]:\\b', '\\t', text))\n",
    "    storagepath = os.path.join(bucket_path,localpath)\n",
    "    process_datafile(localpath, storagepath, table, mode='append', overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bigquery udf --module transform_traffic_time\n",
    "  \n",
    "/**\n",
    " * Pad with 0 or given string.\n",
    " *\n",
    " * @param int n Number to add padding to.\n",
    " * @param int width Width of number + padding.\n",
    " * @param string z (Optional) Other string to replace '0' as padding.\n",
    " */\n",
    "function pad(n, width, z) {\n",
    "  z = z || '0';\n",
    "  n = n + '';\n",
    "  return n.length >= width ? n : new Array(width - n.length + 1).join(z) + n;\n",
    "}\n",
    "\n",
    "/**\n",
    " * Transform timestamps of weather table into timeslots in traffic table.\n",
    " *\n",
    " * @param {{district_hash: string, tj_level1: integer, tj_level2: integer, tj_level3: integer, \n",
    "            tj_level4: integer, tj_time: string}} r\n",
    " * @param function({{district_hash: string, tj_level1: integer, tj_level2: integer, tj_level3: integer, \n",
    "                     tj_level4: integer, tj_time: string, timeslot: string}}) emitFn\n",
    " */\n",
    "function(r, emitFn) {\n",
    "  var t = r.tj_time.split(/[ :\\-]/);\n",
    "  var slot = Math.floor((parseInt(t[3]) * 60 + parseInt(t[4])) / 10) + 1;\n",
    "  r.timeslot = t[0] + '-' + pad(t[1], 2) +\n",
    "               '-' + pad(t[2], 2) + '-' + slot;\n",
    "  emitFn(r);\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bigquery execute -t datalab-projects-1331:xjk_algo_comp.traffic -m overwrite\n",
    "  \n",
    "SELECT district_hash, tj_level1, tj_level2, tj_level3, tj_level4, tj_time, timeslot\n",
    "FROM transform_traffic_time([datalab-projects-1331:xjk_algo_comp.traffic])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## POIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "table = bq.Table('datalab-projects-1331:xjk_algo_comp.pois')\n",
    "  \n",
    "localpath = '{}/{}/poi_data/poi_data'.format(season_name, subdirectory_name)\n",
    "\n",
    "pois = []\n",
    "pois_schema = [{'name': 'district_hash', 'type': 'STRING'}]\n",
    "with open(localpath, 'rb') as f:\n",
    "  for line in f:\n",
    "    line_pois = map(lambda x: ['f{}'.format(x.split(':')[0].replace('#', '_')), x.split(':')[1]],\n",
    "                    line.split('\\t')[1:])\n",
    "  for poi in line_pois:\n",
    "    if poi[0] not in pois:\n",
    "      pois.append(poi[0])\n",
    "      pois_schema.append({'name': poi[0], 'type': 'INTEGER'})\n",
    "pois.sort()\n",
    "pois_schema = sorted(pois_schema, key=lambda k: k['name']) \n",
    "\n",
    "if not table.exists():\n",
    "  schema = bq.Schema.from_data(pois_schema)\n",
    "  table.create(schema)\n",
    "  \n",
    "  pois_data = pd.DataFrame(columns=['district_hash'] + pois)\n",
    "  with open(localpath, 'rb') as f:\n",
    "    for line in f:\n",
    "      hash_pois = {}\n",
    "      for poi_line in line.split('\\t')[1:]:\n",
    "        hash_pois['f{}'.format(poi_line.split(':')[0].replace('#', '_'))] = poi_line.split(':')[1]\n",
    "      poi_data = [line.split('\\t')[0]]\n",
    "      # hash_pois = {f1_1: 15, ...}\n",
    "      # pois = ['f1_1', ...]\n",
    "      for poi in pois:\n",
    "        value = '0'\n",
    "        if poi in hash_pois:\n",
    "          value = hash_pois[poi].strip()\n",
    "        poi_data.append(value)\n",
    "      pois_data.loc[len(pois_data)] = poi_data\n",
    "  for poi in pois:\n",
    "    pois_data[poi] = pd.to_numeric(pois_data[poi])\n",
    "  table.insert_data(pois_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following code can be used to print out feature fields to be used when selecting from tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_text = ''\n",
    "for counter, poi_text in enumerate(map(lambda x: 'FIRST(pois.{}) AS {}'.format(x,x), pois)):\n",
    "  if counter%3 == 0:\n",
    "    final_text = '{}\\n'.format(final_text)\n",
    "  final_text = '{}{}, '.format(final_text, poi_text)\n",
    "print final_text[1:(len(final_text)-2)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "table = bq.Table('datalab-projects-1331:xjk_algo_comp.orders')\n",
    "if not table.exists():\n",
    "  schema = bq.Schema([{'name': 'order_id', 'type': 'STRING'},\n",
    "                      {'name': 'driver_id', 'type': 'STRING'},\n",
    "                      {'name': 'passenger_id', 'type': 'STRING'},\n",
    "                      {'name': 'start_district_hash', 'type': 'STRING'},\n",
    "                      {'name': 'dest_district_hash', 'type': 'STRING'},\n",
    "                      {'name': 'price', 'type': 'FLOAT'},\n",
    "                      {'name': 'time', 'type': 'STRING'}])\n",
    "  table.create(schema)\n",
    "  \n",
    "  wildpath = '{}/{}/order_data/*'.format(season_name, subdirectory_name)\n",
    "  for localpath in glob.glob(wildpath):\n",
    "    print 'loading {}'.format(localpath)\n",
    "    storagepath = os.path.join(bucket_path,localpath)\n",
    "    process_datafile(localpath, storagepath, table, mode='append')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
