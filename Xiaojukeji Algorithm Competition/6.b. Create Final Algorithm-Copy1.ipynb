{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pdb\n",
    "import numpy as np\n",
    "import gcp.bigquery as bq\n",
    "import gcp.storage as storage\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import backend as K\n",
    "from keras.optimizers import SGD\n",
    "import tensorflow as tf\n",
    "import h5py\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "import time\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers import Dropout\n",
    "\n",
    "\n",
    "try:\n",
    "  import cPickle as pickle\n",
    "except:\n",
    "  import pickle\n",
    "HDF_FILENAME = 'final_model.hdf5'\n",
    "JSON_MODEL_FILENAME = 'final_model.json'\n",
    "\n",
    "GRID_HDF_FILENAME = 'best_grid_model.hdf5'\n",
    "\n",
    "seed = 13\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Put all categorical data first for easier implementation of One Hot Encoding.\n",
    "fields_str = \"\"\"\n",
    "gap\tday_in_week\tweather_1_slots_ago\tweather_2_slots_ago\tweather_3_slots_ago\tbusy_time\t\n",
    "tj_level1_1_slots_ago\ttj_level2_1_slots_ago\ttj_level3_1_slots_ago\ttj_level4_1_slots_ago\t\n",
    "tj_level1_2_slots_ago\ttj_level2_2_slots_ago\ttj_level3_2_slots_ago\ttj_level4_2_slots_ago\t\n",
    "tj_level1_3_slots_ago\ttj_level2_3_slots_ago\ttj_level3_3_slots_ago\ttj_level4_3_slots_ago\t\n",
    "temperature_1_slots_ago\tpm25_1_slots_ago\t\n",
    "temperature_2_slots_ago\tpm25_2_slots_ago\t\n",
    "temperature_3_slots_ago\tpm25_3_slots_ago\t\n",
    "gap_1_slots_ago\tsum_price_1_slots_ago\t\n",
    "gap_2_slots_ago\tsum_price_2_slots_ago\t\n",
    "gap_3_slots_ago\tsum_price_3_slots_ago\t\n",
    "f1\tf11\tf11_1\tf11_2\tf11_3\tf11_4\tf11_5\tf11_6\tf11_7\t\n",
    "f11_8\tf13_4\tf13_8\tf14\tf14_1\tf14_10\tf14_2\tf14_3\tf14_6\tf14_8\tf15\tf15_1\t\n",
    "f15_2\tf15_3\tf15_4\tf15_6\tf15_7\tf15_8\tf16\tf16_1\tf16_10\tf16_11\tf16_12\tf16_3\t\n",
    "f16_4\tf16_6\tf17\tf17_2\tf17_3\tf17_4\tf17_5\tf19\tf19_1\tf19_2\tf19_3\tf19_4\tf1_1\t\n",
    "f1_10\tf1_11\tf1_2\tf1_3\tf1_4\tf1_5\tf1_6\tf1_7\tf1_8\tf20\tf20_1\tf20_2\t\n",
    "f20_4\tf20_5\tf20_6\tf20_7\tf20_8\tf20_9\tf21_1\tf21_2\tf22\tf22_1\tf22_2\tf22_3\t\n",
    "f22_4\tf22_5\tf23\tf23_1\tf23_2\tf23_3\tf23_4\tf23_5\tf23_6\tf24\tf24_1\tf24_2\tf24_3\t\n",
    "f25\tf25_1\tf25_3\tf25_7\tf25_8\tf25_9\tf2_1\tf2_10\tf2_11\tf2_12\tf2_13\tf2_2\t\n",
    "f2_4\tf2_5\tf2_6\tf2_7\tf2_8\tf3_1\tf3_2\tf3_3\tf4\tf4_1\tf4_10\tf4_11\t\n",
    "f4_13\tf4_14\tf4_16\tf4_17\tf4_18\tf4_2\tf4_3\tf4_5\tf4_6\tf4_7\tf4_8\tf4_9\t\n",
    "f5\tf5_1\tf5_3\tf5_4\tf6\tf6_1\tf6_2\tf6_4\tf7\tf8\tf8_1\tf8_2\tf8_3\tf8_4\t\n",
    "f8_5\n",
    "\"\"\"\n",
    "fields = map(lambda x: x.strip(), fields_str.split('\\t'))\n",
    "features = fields[1:]\n",
    "\n",
    "# Use this instead of len(features) since this variable can change\n",
    "# e.g. when one hot encoding is used and/or new features are added.\n",
    "n_features = len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%sql --module q_all\n",
    "\n",
    "SELECT *, HASH(CAST(district_id AS STRING) +timeslot) AS hash_value,\n",
    "  IF(ABS(HASH(CAST(district_id AS STRING) + timeslot)) % 2 == 1, 'True', 'False')\n",
    "    AS included_in_sample, IF(timeofday_slot >= 50 AND timeofday_slot <= 53, 1, 0) AS busy_time\n",
    "FROM [datalab-projects-1331:xjk_algo_comp.gaps]\n",
    "WHERE gap > 0\n",
    "LIMIT 100\n",
    "\n",
    "# The above query randomizes its outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 100 rows\n",
      "processed 0 rows\n"
     ]
    }
   ],
   "source": [
    "query = bq.Query(q_all)\n",
    "tableresult = query.results()\n",
    "\n",
    "all_data = np.zeros((tableresult.length, len(fields)))\n",
    "print 'there are {} rows'.format(tableresult.length)\n",
    "for rcounter, row in enumerate(tableresult):\n",
    "  for fcounter, field in enumerate(fields):\n",
    "    all_data[rcounter, fcounter] = row[field]\n",
    "  if rcounter % 5000 == 0:\n",
    "    print 'processed {} rows'.format(rcounter)\n",
    "all_data_original = np.copy(all_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Preprocess Data\n",
    "\n",
    "Note that in the end we don't use data adjusted from Preprocessing steps, but rather including the preprocessing instances in Pipeline to be applied to original data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_data = np.copy(all_data_original)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Impute NaN and inf values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkinf for NaN and Inf\n",
      "np.nan= (array([ 5,  5, 19, 19, 19, 19, 25, 25, 25, 25, 48, 48]), array([24, 25, 24, 25, 28, 29, 26, 27, 28, 29, 26, 27]))\n",
      "is.inf= (array([], dtype=int64), array([], dtype=int64))\n",
      "np.max= nan\n",
      "Shape of old data:\n",
      "(100, 164)\n",
      "Stats (NaN values are replaced with following means for each feature):\n",
      "[  1.27300000e+01   0.00000000e+00   5.08000000e+00   4.67166667e+00\n",
      "   4.47333333e+00   0.00000000e+00   9.75290000e+02   2.38140000e+02\n",
      "   7.27400000e+01   4.73600000e+01   9.74210000e+02   2.36950000e+02\n",
      "   7.27100000e+01   5.00400000e+01   9.75730000e+02   2.41340000e+02\n",
      "   7.27700000e+01   4.76300000e+01   5.34666667e+00   2.36906667e+02\n",
      "   5.30500000e+00   2.32936667e+02   5.30333333e+00   2.30106667e+02\n",
      "   1.22551020e+01   1.47184388e+03   1.29183673e+01   1.50956429e+03\n",
      "   1.25918367e+01   1.44275204e+03   1.58945000e+03   6.81596000e+03\n",
      "   1.30559000e+03   3.13159000e+03   3.58477000e+03   2.10844900e+04\n",
      "   1.06987000e+03   7.54221000e+03   1.51558000e+03   1.92750900e+04\n",
      "   1.86318400e+04   2.85271000e+03   9.43710000e+02   1.32800000e+01\n",
      "   2.11650000e+02   6.88900000e+01   4.53180000e+02   5.67720000e+02\n",
      "   1.55210000e+02   4.09273000e+03   4.31600000e+01   2.89836000e+03\n",
      "   4.98581000e+03   2.91330000e+02   2.67426000e+03   1.44171000e+03\n",
      "   5.31200000e+01   6.04240000e+03   5.22900000e+01   8.26763000e+03\n",
      "   4.38323000e+03   1.39855000e+03   3.37810000e+02   3.54991000e+03\n",
      "   2.24100000e+01   1.01343000e+03   5.57912000e+03   1.76790000e+02\n",
      "   1.61767000e+03   5.77597000e+03   4.47809900e+04   1.21512000e+03\n",
      "   4.87210000e+02   2.25253700e+04   8.79800000e+02   1.60190000e+02\n",
      "   1.08730000e+02   1.29563000e+03   9.01380000e+02   3.56070000e+02\n",
      "   1.91730000e+02   6.05900000e+03   8.79800000e+01   8.05100000e+01\n",
      "   2.89255000e+03   2.49000000e+04   5.89715000e+03   3.75160000e+03\n",
      "   4.22304000e+03   2.67094000e+03   3.02950000e+02   9.43876000e+03\n",
      "   3.89660100e+04   5.81000000e+00   6.22500000e+01   1.21180000e+02\n",
      "   1.33962000e+03   4.30770000e+02   1.12216000e+03   4.17490000e+02\n",
      "   1.23255000e+03   4.70610000e+02   1.24002000e+03   2.01690000e+02\n",
      "   1.10390000e+02   3.99230000e+02   1.30310000e+02   5.88470000e+02\n",
      "   3.95080000e+02   1.10141000e+03   5.92877200e+04   3.98234000e+03\n",
      "   4.19980000e+02   1.52056000e+03   4.39900000e+01   3.85200000e+02\n",
      "   1.44503000e+03   1.09062000e+03   3.30755000e+03   1.63510000e+02\n",
      "   1.24085000e+03   1.94220000e+02   3.69516000e+03   9.22130000e+02\n",
      "   3.74828000e+03   1.66000000e+02   5.66060000e+02   1.97955000e+03\n",
      "   4.67290000e+02   3.32000000e+01   2.67177000e+03   9.71100000e+01\n",
      "   1.35290000e+02   6.34618000e+03   4.12510000e+02   1.95963000e+03\n",
      "   1.57783000e+03   1.79778000e+03   1.49732000e+03   3.00460000e+02\n",
      "   1.60107000e+03   1.45831000e+03   2.26839000e+03   7.42020000e+02\n",
      "   2.12812000e+03   4.20810000e+02   5.88470000e+02   1.97540000e+02\n",
      "   1.47740000e+03   1.51060000e+02   2.08496000e+03   1.46993000e+03\n",
      "   4.39900000e+01   7.40692000e+03   1.15121000e+03   7.07160000e+02\n",
      "   3.90930000e+02   5.82743000e+03   3.47770000e+02   1.58530000e+02\n",
      "   4.43220000e+03   2.92326000e+03   3.03116000e+03   4.98000000e+01]\n",
      "Shape of new data:\n",
      "(100, 164)\n",
      "Checkinf for NaN and Inf\n",
      "np.nan= (array([], dtype=int64), array([], dtype=int64))\n",
      "is.inf= (array([], dtype=int64), array([], dtype=int64))\n",
      "np.max= 461563.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import Imputer\n",
    "# Useful code to check NaN and Inf values. This is needed since these values would\n",
    "# cause \"Input contains NaN, infinity or a value too large for dtype('float32')\n",
    "# errors when left unchecked.\n",
    "print \"Checkinf for NaN and Inf\"\n",
    "print \"np.nan=\", np.where(np.isnan(all_data))\n",
    "print \"is.inf=\", np.where(np.isinf(all_data))\n",
    "print \"np.max=\", np.max(abs(all_data))\n",
    "\n",
    "# Impute\n",
    "imputer = Imputer()\n",
    "imputer.fit(all_data)\n",
    "print 'Shape of old data:'\n",
    "print all_data.shape\n",
    "print 'Stats (NaN values are replaced with following means for each feature):'\n",
    "print imputer.statistics_\n",
    "all_data = imputer.fit_transform(all_data)\n",
    "print 'Shape of new data:'\n",
    "print all_data.shape\n",
    "\n",
    "# See that NaN and Inf values replaced\n",
    "print \"Checkinf for NaN and Inf\"\n",
    "print \"np.nan=\", np.where(np.isnan(all_data))\n",
    "print \"is.inf=\", np.where(np.isinf(all_data))\n",
    "print \"np.max=\", np.max(abs(all_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. One Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_values_:\n",
      "[ 7 10 10 10]\n",
      "feature_indices_:\n",
      "[ 0  7 17 27 37]\n",
      "new number of features: 196\n"
     ]
    }
   ],
   "source": [
    "one_hot = OneHotEncoder(categorical_features=[1, 2, 3, 4], n_values=[7, 10, 10, 10])\n",
    "one_hot.fit(all_data)\n",
    "print \"n_values_:\"\n",
    "print one_hot.n_values_\n",
    "print \"feature_indices_:\"\n",
    "print one_hot.feature_indices_\n",
    "all_data = one_hot.fit_transform(all_data).todense()\n",
    "n_features = all_data.shape[1] - 1\n",
    "print 'new number of features: {}'.format(n_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3. Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "old data:\n",
      "means: 2430.2805102, min: 0.0, max: 461563.0\n",
      "new data:\n",
      "means: 1.15418109362e-17, min: -2.28589190215, max: 8.71481455667\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "print 'old data:'\n",
    "print 'means: {}, min: {}, max: {}'.format(np.mean(all_data), np.min(all_data), np.max(all_data))\n",
    "all_data = scaler.fit_transform(all_data)\n",
    "print 'new data:'\n",
    "print 'means: {}, min: {}, max: {}'.format(np.mean(all_data), np.min(all_data), np.max(all_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Split into Train and Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split the originaldata into train and test sets.\n",
    "data_size = all_data_original.shape[0]\n",
    "training_size = data_size * 90/100\n",
    "indices = np.random.permutation(data_size)\n",
    "training_idx, test_idx = indices[:training_size], indices[training_size:]\n",
    "all_data_train, all_data_test = all_data_original[training_idx,:], all_data_original[test_idx,:]\n",
    "\n",
    "data_train = all_data_train[:,1:]\n",
    "targets_train = all_data_train[:,0]\n",
    "data_test = all_data_test[:,1:]\n",
    "targets_test = all_data_test[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Model Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1. Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mape(y, predictions):\n",
    "  return K.mean(K.abs(y-predictions/K.clip(K.abs(y), K.epsilon(), np.inf)), axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2. Create Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_model(optimizer='adagrad', init='uniform'):\n",
    "  model = Sequential()\n",
    "  model.add(Dense(n_features, input_dim=n_features, init=init, activation='relu'))\n",
    "  model.add(Dense(int(n_features/2), init=init, activation='relu'))\n",
    "  model.add(Dense(int(n_features/4), init=init, activation='relu'))\n",
    "  model.add(Dense(1))\n",
    "  model.compile(loss=mape, optimizer=optimizer)\n",
    "  return model\n",
    "\n",
    "model = KerasRegressor(build_fn=create_model, nb_epoch=20, batch_size=10, verbose=2)\n",
    "\n",
    "steps = [\n",
    "  ('impute', Imputer()),\n",
    "  # Remember that gap, the first variable, is removed, thus categorical_features\n",
    "  # should start at index 0.\n",
    "  ('one_hot', OneHotEncoder(categorical_features=[0, 1, 2, 3], sparse=False)),\n",
    "  ('scale', StandardScaler()),\n",
    "#   ('pca', PCA(n_components=120)),\n",
    "  ('estimate', model)\n",
    "]\n",
    "final_est = Pipeline(steps)\n",
    "\n",
    "# kfold = StratifiedKFold(y=targets_train, n_folds=10, shuffle=True, random_state=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3. Grid Search to Find Best Hyperparameters\n",
    "\n",
    "Use subset of training data in grid search just to find what hyperparameters are best for this project. Specifically we want to find the best optimizer, initializer, and batch size. Topology of the model will be adjusted in crossvalidation step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# model.fit(data_train, targets_train, validation_split=0.33,  nb_epoch=100, batch_size=10, \n",
    "#           callbacks=callbacks_list)\n",
    "# results = cross_val_score(model, data_train, targets_train, cv=kfold)\n",
    "\n",
    "# checkpoint = ModelCheckpoint(GRID_HDF_FILENAME, monitor='loss', save_best_only=True, mode='min')\n",
    "# callbacks_list = [checkpoint]\n",
    "\n",
    "# epochs = 150\n",
    "# learning_rate = 0.1\n",
    "# decay_rate = learning_rate / epochs\n",
    "# momentum = 0.8\n",
    "# sgd = SGD(lr=learning_rate, momentum=momentum, decay=decay_rate, nesterov=False)\n",
    "\n",
    "# data_train_s = data_train[:1000]\n",
    "# targets_train_s = targets_train[:1000]\n",
    "# optimizers = [sgd, 'adam', 'adagrad']\n",
    "# init = ['glorot_uniform', 'normal', 'uniform']\n",
    "# epochs_r = np.array([epochs])\n",
    "# batches = np.array([5, 10, 20])\n",
    "# param_grid = {\n",
    "#   'estimate__optimizer': optimizers,\n",
    "#   'estimate__nb_epoch': epochs_r, \n",
    "#   'estimate__batch_size': batches,\n",
    "#   'estimate__init': init,\n",
    "#   'estimate__callbacks': [callbacks_list]\n",
    "# }\n",
    "\n",
    "# grid = GridSearchCV(estimator=final_est, param_grid=param_grid, cv=3)\n",
    "# grid_result = grid.fit(data_train_s, targets_train_s)\n",
    "# time.sleep(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# summarize results\n",
    "# print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "# for params, mean_score, scores in grid_result.grid_scores_:\n",
    "# print(\"%f (%f) with: %r\" % (scores.mean(), scores.std(), params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# scores = model.evaluate(data_train, targets_train)\n",
    "# print(\"\\nscore: %.2f%\" % (scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# scores = model.evaluate(data_test, targets_test)\n",
    "# print(\"\\nscore: %.2f%\" % (scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4. Crossvalidation\n",
    "\n",
    "Use entire training data for cross validation. Resulting model from here will be the final model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "steps = [\n",
    "  ('impute', Imputer()),\n",
    "  # Remember that gap, the first variable, is removed, thus categorical_features\n",
    "  # should start at index 0.\n",
    "  ('one_hot', OneHotEncoder(categorical_features=[0, 1, 2, 3], sparse=False,\n",
    "                           n_values=[7, 10, 10, 10])),\n",
    "  ('scale', StandardScaler()),\n",
    "#   ('pca', PCA(n_components=120)),\n",
    "#   ('estimate', final_model)\n",
    "]\n",
    "transformer = Pipeline(steps)\n",
    "data_train2 = transformer.fit_transform(data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epochs = 5\n",
    "\n",
    "def get_optimizer(epochs=50):\n",
    "  learning_rate = 0.1\n",
    "  decay_rate = learning_rate / epochs\n",
    "  momentum = 0.8\n",
    "  return SGD(lr=learning_rate, momentum=momentum, decay=decay_rate, nesterov=False)\n",
    "\n",
    "def create_final_model():\n",
    "  init='uniform'\n",
    "  final_model = Sequential()\n",
    "  final_model.add(Dropout(0.2, input_shape=(n_features,)))\n",
    "  final_model.add(Dense(n_features, init=init, activation='relu'))\n",
    "  final_model.add(Dropout(0.2))\n",
    "  final_model.add(Dense(int(n_features/2), init=init, activation='relu'))\n",
    "  final_model.add(Dropout(0.2))\n",
    "  final_model.add(Dense(int(n_features/4), init=init, activation='relu'))\n",
    "  final_model.add(Dropout(0.2))\n",
    "  final_model.add(Dense(1))\n",
    "  final_model.compile(loss=mape, optimizer=get_optimizer(epochs))\n",
    "  return final_model\n",
    "\n",
    "final_est = KerasRegressor(build_fn=create_final_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00000: val_loss improved from inf to 20.11314, saving model to final_model.hdf5\n",
      "Epoch 00001: val_loss improved from 20.11314 to 20.07811, saving model to final_model.hdf5\n",
      "Epoch 00002: val_loss improved from 20.07811 to 20.03879, saving model to final_model.hdf5\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 00004: val_loss improved from 20.03879 to 20.03077, saving model to final_model.hdf5\n"
     ]
    }
   ],
   "source": [
    "checkpoint = ModelCheckpoint(HDF_FILENAME, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "history = final_est.fit(data_train2, targets_train, validation_split=0.33,\n",
    "                          nb_epoch=epochs, batch_size=10, verbose=0, callbacks=callbacks_list)\n",
    "time.sleep(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfcAAAFwCAYAAAClwDJHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nWopF91GHAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe0ec840d10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# kfold = KFold(n=len(data_train), n_folds=10, random_state=seed)\n",
    "# results = cross_val_score(estimator, data_train, targets_train, cv=kfold)\n",
    "# print(\"Results: %.2f (%.2f) MSE\" % (results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Store Model to File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_json = final_est.model.to_json()\n",
    "with open(JSON_MODEL_FILENAME, \"w\") as json_file:\n",
    "  json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n",
      "loss: 4.41\n",
      "[[ 1.00297546]\n",
      " [ 2.12108731]\n",
      " [ 1.26768386]\n",
      " [ 1.14150047]\n",
      " [ 1.10341513]\n",
      " [ 1.00500298]\n",
      " [ 1.16552496]\n",
      " [ 1.02552843]\n",
      " [ 0.98139918]\n",
      " [ 1.24404454]]\n"
     ]
    }
   ],
   "source": [
    "from keras.models import model_from_json\n",
    "json_file = open(JSON_MODEL_FILENAME, 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(HDF_FILENAME)\n",
    "print(\"Loaded model from disk\")\n",
    "\n",
    "# evaluate loaded model on test data\n",
    "data_test2 = transformer.fit_transform(data_test)\n",
    "loaded_model.compile(loss=mape, optimizer=get_optimizer(epochs))\n",
    "score = loaded_model.evaluate(data_test2, targets_test, verbose=0)\n",
    "print \"%s: %.2f\" % (loaded_model.metrics_names[0], score)\n",
    "predictions = loaded_model.predict(data_test2)\n",
    "print 'sample predictions:'\n",
    "print(predictions[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'loss'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model.metrics_names[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_test2.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
