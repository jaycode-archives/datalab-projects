{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pdb\n",
    "import numpy as np\n",
    "import gcp.bigquery as bq\n",
    "import gcp.storage as storage\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import backend as K\n",
    "from keras.optimizers import SGD\n",
    "import tensorflow as tf\n",
    "import h5py\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "import time\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers import Dropout\n",
    "\n",
    "\n",
    "try:\n",
    "  import cPickle as pickle\n",
    "except:\n",
    "  import pickle\n",
    "HDF_FILENAME = 'final_model.hdf5'\n",
    "JSON_MODEL_FILENAME = 'final_model.json'\n",
    "\n",
    "GRID_HDF_FILENAME = 'best_grid_model.hdf5'\n",
    "\n",
    "seed = 13\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Put all categorical data first for easier implementation of One Hot Encoding.\n",
    "fields_str = \"\"\"\n",
    "gap\tday_in_week\tweather_1_slots_ago\tweather_2_slots_ago\tweather_3_slots_ago\tbusy_time\t\n",
    "tj_level1_1_slots_ago\ttj_level2_1_slots_ago\ttj_level3_1_slots_ago\ttj_level4_1_slots_ago\t\n",
    "tj_level1_2_slots_ago\ttj_level2_2_slots_ago\ttj_level3_2_slots_ago\ttj_level4_2_slots_ago\t\n",
    "tj_level1_3_slots_ago\ttj_level2_3_slots_ago\ttj_level3_3_slots_ago\ttj_level4_3_slots_ago\t\n",
    "temperature_1_slots_ago\tpm25_1_slots_ago\t\n",
    "temperature_2_slots_ago\tpm25_2_slots_ago\t\n",
    "temperature_3_slots_ago\tpm25_3_slots_ago\t\n",
    "gap_1_slots_ago\tsum_price_1_slots_ago\t\n",
    "gap_2_slots_ago\tsum_price_2_slots_ago\t\n",
    "gap_3_slots_ago\tsum_price_3_slots_ago\t\n",
    "f1\tf11\tf11_1\tf11_2\tf11_3\tf11_4\tf11_5\tf11_6\tf11_7\t\n",
    "f11_8\tf13_4\tf13_8\tf14\tf14_1\tf14_10\tf14_2\tf14_3\tf14_6\tf14_8\tf15\tf15_1\t\n",
    "f15_2\tf15_3\tf15_4\tf15_6\tf15_7\tf15_8\tf16\tf16_1\tf16_10\tf16_11\tf16_12\tf16_3\t\n",
    "f16_4\tf16_6\tf17\tf17_2\tf17_3\tf17_4\tf17_5\tf19\tf19_1\tf19_2\tf19_3\tf19_4\tf1_1\t\n",
    "f1_10\tf1_11\tf1_2\tf1_3\tf1_4\tf1_5\tf1_6\tf1_7\tf1_8\tf20\tf20_1\tf20_2\t\n",
    "f20_4\tf20_5\tf20_6\tf20_7\tf20_8\tf20_9\tf21_1\tf21_2\tf22\tf22_1\tf22_2\tf22_3\t\n",
    "f22_4\tf22_5\tf23\tf23_1\tf23_2\tf23_3\tf23_4\tf23_5\tf23_6\tf24\tf24_1\tf24_2\tf24_3\t\n",
    "f25\tf25_1\tf25_3\tf25_7\tf25_8\tf25_9\tf2_1\tf2_10\tf2_11\tf2_12\tf2_13\tf2_2\t\n",
    "f2_4\tf2_5\tf2_6\tf2_7\tf2_8\tf3_1\tf3_2\tf3_3\tf4\tf4_1\tf4_10\tf4_11\t\n",
    "f4_13\tf4_14\tf4_16\tf4_17\tf4_18\tf4_2\tf4_3\tf4_5\tf4_6\tf4_7\tf4_8\tf4_9\t\n",
    "f5\tf5_1\tf5_3\tf5_4\tf6\tf6_1\tf6_2\tf6_4\tf7\tf8\tf8_1\tf8_2\tf8_3\tf8_4\t\n",
    "f8_5\n",
    "\"\"\"\n",
    "fields = map(lambda x: x.strip(), fields_str.split('\\t'))\n",
    "features = fields[1:]\n",
    "\n",
    "# Use this instead of len(features) since this variable can change\n",
    "# e.g. when one hot encoding is used and/or new features are added.\n",
    "n_features = len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%sql --module q_all\n",
    "\n",
    "SELECT *, HASH(CAST(district_id AS STRING) +timeslot) AS hash_value,\n",
    "  IF(ABS(HASH(CAST(district_id AS STRING) + timeslot)) % 2 == 1, 'True', 'False')\n",
    "    AS included_in_sample, IF(timeofday_slot >= 50 AND timeofday_slot <= 53, 1, 0) AS busy_time\n",
    "FROM [datalab-projects-1331:xjk_algo_comp.gaps]\n",
    "WHERE gap > 0\n",
    "LIMIT 100\n",
    "\n",
    "# The above query randomizes its outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 100 rows\n",
      "processed 0 rows\n"
     ]
    }
   ],
   "source": [
    "query = bq.Query(q_all)\n",
    "tableresult = query.results()\n",
    "\n",
    "all_data = np.zeros((tableresult.length, len(fields)))\n",
    "print 'there are {} rows'.format(tableresult.length)\n",
    "for rcounter, row in enumerate(tableresult):\n",
    "  for fcounter, field in enumerate(fields):\n",
    "    all_data[rcounter, fcounter] = row[field]\n",
    "  if rcounter % 5000 == 0:\n",
    "    print 'processed {} rows'.format(rcounter)\n",
    "all_data_original = np.copy(all_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Preprocess Data\n",
    "\n",
    "Note that in the end we don't use data adjusted from Preprocessing steps, but rather including the preprocessing instances in Pipeline to be applied to original data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_data = np.copy(all_data_original)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Impute NaN and inf values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkinf for NaN and Inf\n",
      "np.nan= (array([ 5,  5, 19, 19, 19, 19, 25, 25, 25, 25, 48, 48]), array([24, 25, 24, 25, 28, 29, 26, 27, 28, 29, 26, 27]))\n",
      "is.inf= (array([], dtype=int64), array([], dtype=int64))\n",
      "np.max= nan\n",
      "Shape of old data:\n",
      "(100, 164)\n",
      "Stats (NaN values are replaced with following means for each feature):\n",
      "[  1.27300000e+01   0.00000000e+00   5.08000000e+00   4.67166667e+00\n",
      "   4.47333333e+00   0.00000000e+00   9.75290000e+02   2.38140000e+02\n",
      "   7.27400000e+01   4.73600000e+01   9.74210000e+02   2.36950000e+02\n",
      "   7.27100000e+01   5.00400000e+01   9.75730000e+02   2.41340000e+02\n",
      "   7.27700000e+01   4.76300000e+01   5.34666667e+00   2.36906667e+02\n",
      "   5.30500000e+00   2.32936667e+02   5.30333333e+00   2.30106667e+02\n",
      "   1.22551020e+01   1.47184388e+03   1.29183673e+01   1.50956429e+03\n",
      "   1.25918367e+01   1.44275204e+03   1.58945000e+03   6.81596000e+03\n",
      "   1.30559000e+03   3.13159000e+03   3.58477000e+03   2.10844900e+04\n",
      "   1.06987000e+03   7.54221000e+03   1.51558000e+03   1.92750900e+04\n",
      "   1.86318400e+04   2.85271000e+03   9.43710000e+02   1.32800000e+01\n",
      "   2.11650000e+02   6.88900000e+01   4.53180000e+02   5.67720000e+02\n",
      "   1.55210000e+02   4.09273000e+03   4.31600000e+01   2.89836000e+03\n",
      "   4.98581000e+03   2.91330000e+02   2.67426000e+03   1.44171000e+03\n",
      "   5.31200000e+01   6.04240000e+03   5.22900000e+01   8.26763000e+03\n",
      "   4.38323000e+03   1.39855000e+03   3.37810000e+02   3.54991000e+03\n",
      "   2.24100000e+01   1.01343000e+03   5.57912000e+03   1.76790000e+02\n",
      "   1.61767000e+03   5.77597000e+03   4.47809900e+04   1.21512000e+03\n",
      "   4.87210000e+02   2.25253700e+04   8.79800000e+02   1.60190000e+02\n",
      "   1.08730000e+02   1.29563000e+03   9.01380000e+02   3.56070000e+02\n",
      "   1.91730000e+02   6.05900000e+03   8.79800000e+01   8.05100000e+01\n",
      "   2.89255000e+03   2.49000000e+04   5.89715000e+03   3.75160000e+03\n",
      "   4.22304000e+03   2.67094000e+03   3.02950000e+02   9.43876000e+03\n",
      "   3.89660100e+04   5.81000000e+00   6.22500000e+01   1.21180000e+02\n",
      "   1.33962000e+03   4.30770000e+02   1.12216000e+03   4.17490000e+02\n",
      "   1.23255000e+03   4.70610000e+02   1.24002000e+03   2.01690000e+02\n",
      "   1.10390000e+02   3.99230000e+02   1.30310000e+02   5.88470000e+02\n",
      "   3.95080000e+02   1.10141000e+03   5.92877200e+04   3.98234000e+03\n",
      "   4.19980000e+02   1.52056000e+03   4.39900000e+01   3.85200000e+02\n",
      "   1.44503000e+03   1.09062000e+03   3.30755000e+03   1.63510000e+02\n",
      "   1.24085000e+03   1.94220000e+02   3.69516000e+03   9.22130000e+02\n",
      "   3.74828000e+03   1.66000000e+02   5.66060000e+02   1.97955000e+03\n",
      "   4.67290000e+02   3.32000000e+01   2.67177000e+03   9.71100000e+01\n",
      "   1.35290000e+02   6.34618000e+03   4.12510000e+02   1.95963000e+03\n",
      "   1.57783000e+03   1.79778000e+03   1.49732000e+03   3.00460000e+02\n",
      "   1.60107000e+03   1.45831000e+03   2.26839000e+03   7.42020000e+02\n",
      "   2.12812000e+03   4.20810000e+02   5.88470000e+02   1.97540000e+02\n",
      "   1.47740000e+03   1.51060000e+02   2.08496000e+03   1.46993000e+03\n",
      "   4.39900000e+01   7.40692000e+03   1.15121000e+03   7.07160000e+02\n",
      "   3.90930000e+02   5.82743000e+03   3.47770000e+02   1.58530000e+02\n",
      "   4.43220000e+03   2.92326000e+03   3.03116000e+03   4.98000000e+01]\n",
      "Shape of new data:\n",
      "(100, 164)\n",
      "Checkinf for NaN and Inf\n",
      "np.nan= (array([], dtype=int64), array([], dtype=int64))\n",
      "is.inf= (array([], dtype=int64), array([], dtype=int64))\n",
      "np.max= 461563.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import Imputer\n",
    "# Useful code to check NaN and Inf values. This is needed since these values would\n",
    "# cause \"Input contains NaN, infinity or a value too large for dtype('float32')\n",
    "# errors when left unchecked.\n",
    "print \"Checkinf for NaN and Inf\"\n",
    "print \"np.nan=\", np.where(np.isnan(all_data))\n",
    "print \"is.inf=\", np.where(np.isinf(all_data))\n",
    "print \"np.max=\", np.max(abs(all_data))\n",
    "\n",
    "# Impute\n",
    "imputer = Imputer()\n",
    "imputer.fit(all_data)\n",
    "print 'Shape of old data:'\n",
    "print all_data.shape\n",
    "print 'Stats (NaN values are replaced with following means for each feature):'\n",
    "print imputer.statistics_\n",
    "all_data = imputer.fit_transform(all_data)\n",
    "print 'Shape of new data:'\n",
    "print all_data.shape\n",
    "\n",
    "# See that NaN and Inf values replaced\n",
    "print \"Checkinf for NaN and Inf\"\n",
    "print \"np.nan=\", np.where(np.isnan(all_data))\n",
    "print \"is.inf=\", np.where(np.isinf(all_data))\n",
    "print \"np.max=\", np.max(abs(all_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. One Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_values_:\n",
      "[ 1 10 10 10]\n",
      "feature_indices_:\n",
      "[ 0  1 11 21 31]\n",
      "new number of features: 174\n"
     ]
    }
   ],
   "source": [
    "one_hot = OneHotEncoder(categorical_features=[1, 2, 3, 4], n_values='auto')\n",
    "one_hot.fit(all_data)\n",
    "print \"n_values_:\"\n",
    "print one_hot.n_values_\n",
    "print \"feature_indices_:\"\n",
    "print one_hot.feature_indices_\n",
    "all_data = one_hot.fit_transform(all_data).todense()\n",
    "n_features = all_data.shape[1] - 1\n",
    "print 'new number of features: {}'.format(n_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3. Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "old data:\n",
      "means: 2735.80148863, min: 0.0, max: 461563.0\n",
      "new data:\n",
      "means: 1.13686837722e-17, min: -2.28589190215, max: 8.71481455667\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "print 'old data:'\n",
    "print 'means: {}, min: {}, max: {}'.format(np.mean(all_data), np.min(all_data), np.max(all_data))\n",
    "all_data = scaler.fit_transform(all_data)\n",
    "print 'new data:'\n",
    "print 'means: {}, min: {}, max: {}'.format(np.mean(all_data), np.min(all_data), np.max(all_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Split into Train and Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split the originaldata into train and test sets.\n",
    "data_size = all_data_original.shape[0]\n",
    "training_size = data_size * 90/100\n",
    "indices = np.random.permutation(data_size)\n",
    "training_idx, test_idx = indices[:training_size], indices[training_size:]\n",
    "all_data_train, all_data_test = all_data_original[training_idx,:], all_data_original[test_idx,:]\n",
    "\n",
    "data_train = all_data_train[:,1:]\n",
    "targets_train = all_data_train[:,0]\n",
    "data_test = all_data_test[:,1:]\n",
    "targets_test = all_data_test[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Model Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1. Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mape(y, predictions):\n",
    "  return K.mean(K.abs(y-predictions/K.clip(K.abs(y), K.epsilon(), np.inf)), axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2. Create Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_model(optimizer='adagrad', init='uniform'):\n",
    "  model = Sequential()\n",
    "  model.add(Dense(n_features, input_dim=n_features, init=init, activation='relu'))\n",
    "  model.add(Dense(int(n_features/2), init=init, activation='relu'))\n",
    "  model.add(Dense(int(n_features/4), init=init, activation='relu'))\n",
    "  model.add(Dense(1))\n",
    "  model.compile(loss=mape, optimizer=optimizer)\n",
    "  return model\n",
    "\n",
    "model = KerasRegressor(build_fn=create_model, nb_epoch=20, batch_size=10, verbose=2)\n",
    "\n",
    "steps = [\n",
    "  ('impute', Imputer()),\n",
    "  # Remember that gap, the first variable, is removed, thus categorical_features\n",
    "  # should start at index 0.\n",
    "  ('one_hot', OneHotEncoder(categorical_features=[0, 1, 2, 3], sparse=False)),\n",
    "  ('scale', StandardScaler()),\n",
    "#   ('pca', PCA(n_components=120)),\n",
    "  ('estimate', model)\n",
    "]\n",
    "final_est = Pipeline(steps)\n",
    "\n",
    "# kfold = StratifiedKFold(y=targets_train, n_folds=10, shuffle=True, random_state=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3. Grid Search to Find Best Hyperparameters\n",
    "\n",
    "Use subset of training data in grid search just to find what hyperparameters are best for this project. Specifically we want to find the best optimizer, initializer, and batch size. Topology of the model will be adjusted in crossvalidation step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# model.fit(data_train, targets_train, validation_split=0.33,  nb_epoch=100, batch_size=10, \n",
    "#           callbacks=callbacks_list)\n",
    "# results = cross_val_score(model, data_train, targets_train, cv=kfold)\n",
    "\n",
    "# checkpoint = ModelCheckpoint(GRID_HDF_FILENAME, monitor='loss', save_best_only=True, mode='min')\n",
    "# callbacks_list = [checkpoint]\n",
    "\n",
    "# epochs = 150\n",
    "# learning_rate = 0.1\n",
    "# decay_rate = learning_rate / epochs\n",
    "# momentum = 0.8\n",
    "# sgd = SGD(lr=learning_rate, momentum=momentum, decay=decay_rate, nesterov=False)\n",
    "\n",
    "# data_train_s = data_train[:1000]\n",
    "# targets_train_s = targets_train[:1000]\n",
    "# optimizers = [sgd, 'adam', 'adagrad']\n",
    "# init = ['glorot_uniform', 'normal', 'uniform']\n",
    "# epochs_r = np.array([epochs])\n",
    "# batches = np.array([5, 10, 20])\n",
    "# param_grid = {\n",
    "#   'estimate__optimizer': optimizers,\n",
    "#   'estimate__nb_epoch': epochs_r, \n",
    "#   'estimate__batch_size': batches,\n",
    "#   'estimate__init': init,\n",
    "#   'estimate__callbacks': [callbacks_list]\n",
    "# }\n",
    "\n",
    "# grid = GridSearchCV(estimator=final_est, param_grid=param_grid, cv=3)\n",
    "# grid_result = grid.fit(data_train_s, targets_train_s)\n",
    "# time.sleep(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# summarize results\n",
    "# print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "# for params, mean_score, scores in grid_result.grid_scores_:\n",
    "# print(\"%f (%f) with: %r\" % (scores.mean(), scores.std(), params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# scores = model.evaluate(data_train, targets_train)\n",
    "# print(\"\\nscore: %.2f%\" % (scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# scores = model.evaluate(data_test, targets_test)\n",
    "# print(\"\\nscore: %.2f%\" % (scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4. Crossvalidation\n",
    "\n",
    "Use entire training data for cross validation. Resulting model from here will be the final model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "steps = [\n",
    "  ('impute', Imputer()),\n",
    "  # Remember that gap, the first variable, is removed, thus categorical_features\n",
    "  # should start at index 0.\n",
    "  ('one_hot', OneHotEncoder(categorical_features=[0, 1, 2, 3], sparse=False)),\n",
    "  ('scale', StandardScaler()),\n",
    "#   ('pca', PCA(n_components=120)),\n",
    "#   ('estimate', final_model)\n",
    "]\n",
    "transformer = Pipeline(steps)\n",
    "data_train2 = transformer.fit_transform(data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epochs = 5\n",
    "\n",
    "def get_optimizer(epochs=50):\n",
    "  learning_rate = 0.1\n",
    "  decay_rate = learning_rate / epochs\n",
    "  momentum = 0.8\n",
    "  return SGD(lr=learning_rate, momentum=momentum, decay=decay_rate, nesterov=False)\n",
    "\n",
    "def create_final_model():\n",
    "  init='uniform'\n",
    "  final_model = Sequential()\n",
    "  final_model.add(Dropout(0.2, input_shape=(n_features,)))\n",
    "  final_model.add(Dense(n_features, init=init, activation='relu'))\n",
    "  final_model.add(Dropout(0.2))\n",
    "  final_model.add(Dense(int(n_features/2), init=init, activation='relu'))\n",
    "  final_model.add(Dropout(0.2))\n",
    "  final_model.add(Dense(int(n_features/4), init=init, activation='relu'))\n",
    "  final_model.add(Dropout(0.2))\n",
    "  final_model.add(Dense(1))\n",
    "  final_model.compile(loss=mape, optimizer=get_optimizer(epochs))\n",
    "  return final_model\n",
    "\n",
    "final_est = KerasRegressor(build_fn=create_final_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00000: val_loss improved from inf to 20.12803, saving model to final_model.hdf5\n",
      "Epoch 00001: val_loss improved from 20.12803 to 20.11920, saving model to final_model.hdf5\n",
      "Epoch 00002: val_loss improved from 20.11920 to 20.04587, saving model to final_model.hdf5\n",
      "Epoch 00003: val_loss improved from 20.04587 to 20.03599, saving model to final_model.hdf5\n",
      "Epoch 00004: val_loss did not improve\n"
     ]
    }
   ],
   "source": [
    "checkpoint = ModelCheckpoint(HDF_FILENAME, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "history = final_est.fit(data_train2, targets_train, validation_split=0.33,\n",
    "                          nb_epoch=epochs, batch_size=10, verbose=0, callbacks=callbacks_list)\n",
    "time.sleep(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfcAAAFwCAYAAAClwDJHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ndwAALEO4AwBgmf8PsxqCj43lchYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe0f9043910>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# kfold = KFold(n=len(data_train), n_folds=10, random_state=seed)\n",
    "# results = cross_val_score(estimator, data_train, targets_train, cv=kfold)\n",
    "# print(\"Results: %.2f (%.2f) MSE\" % (results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Store Model to File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_json = final_est.model.to_json()\n",
    "with open(JSON_MODEL_FILENAME, \"w\") as json_file:\n",
    "  json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "Error when checking model input: expected dropout_input_2 to have shape (None, 174) but got array with shape (10, 167)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m\u001b[0m",
      "\u001b[1;31mException\u001b[0mTraceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-65fe16f3d821>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mdata_test2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mloaded_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mget_optimizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloaded_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_test2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[1;34m\"%s: %.2f%%\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mloaded_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics_names\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloaded_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_test2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/keras/models.pyc\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, **kwargs)\u001b[0m\n\u001b[0;32m    441\u001b[0m                                    \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    442\u001b[0m                                    \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 443\u001b[1;33m                                    sample_weight=sample_weight)\n\u001b[0m\u001b[0;32m    444\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    445\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight)\u001b[0m\n\u001b[0;32m   1078\u001b[0m                                                            \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1079\u001b[0m                                                            \u001b[0mcheck_batch_dim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1080\u001b[1;33m                                                            batch_size=batch_size)\n\u001b[0m\u001b[0;32m   1081\u001b[0m         \u001b[1;31m# prepare inputs, delegate logic to _test_loop\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1082\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muses_learning_phase\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, check_batch_dim, batch_size)\u001b[0m\n\u001b[0;32m    919\u001b[0m                                    \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minternal_input_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    920\u001b[0m                                    \u001b[0mcheck_batch_dim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 921\u001b[1;33m                                    exception_prefix='model input')\n\u001b[0m\u001b[0;32m    922\u001b[0m         y = standardize_input_data(y, self.output_names,\n\u001b[0;32m    923\u001b[0m                                    \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minternal_output_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[1;34m(data, names, shapes, check_batch_dim, exception_prefix)\u001b[0m\n\u001b[0;32m    102\u001b[0m                                         \u001b[1;34m' to have shape '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshapes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m                                         \u001b[1;34m' but got array with shape '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 104\u001b[1;33m                                         str(array.shape))\n\u001b[0m\u001b[0;32m    105\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0marrays\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mException\u001b[0m: Error when checking model input: expected dropout_input_2 to have shape (None, 174) but got array with shape (10, 167)"
     ]
    }
   ],
   "source": [
    "from keras.models import model_from_json\n",
    "json_file = open(JSON_MODEL_FILENAME, 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(HDF_FILENAME)\n",
    "print(\"Loaded model from disk\")\n",
    "\n",
    "# evaluate loaded model on test data\n",
    "data_test2 = transformer.fit_transform(data_test)\n",
    "loaded_model.compile(loss=mape, optimizer=get_optimizer(epochs))\n",
    "score = loaded_model.evaluate(data_test2, targets_test, verbose=0)\n",
    "print \"%s: %.2f%%\" % (loaded_model.metrics_names[1], score[1]*100)\n",
    "predictions = loaded_model.predict(data_test2)\n",
    "print(predictions[0:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
