{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pdb\n",
    "import numpy as np\n",
    "import gcp.bigquery as bq\n",
    "import gcp.storage as storage\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import backend as K\n",
    "from keras.optimizers import SGD\n",
    "import tensorflow as tf\n",
    "import h5py\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "import time\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers import Dropout\n",
    "\n",
    "\n",
    "try:\n",
    "  import cPickle as pickle\n",
    "except:\n",
    "  import pickle\n",
    "HDF_FILENAME = 'final_model.hdf5'\n",
    "JSON_MODEL_FILENAME = 'final_model.json'\n",
    "\n",
    "GRID_HDF_FILENAME = 'best_grid_model.hdf5'\n",
    "\n",
    "seed = 13\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Put all categorical data first for easier implementation of One Hot Encoding.\n",
    "fields_str = \"\"\"\n",
    "gap\tday_in_week\tweather_1_slots_ago\tweather_2_slots_ago\tweather_3_slots_ago\tbusy_time\t\n",
    "tj_level1_1_slots_ago\ttj_level2_1_slots_ago\ttj_level3_1_slots_ago\ttj_level4_1_slots_ago\t\n",
    "tj_level1_2_slots_ago\ttj_level2_2_slots_ago\ttj_level3_2_slots_ago\ttj_level4_2_slots_ago\t\n",
    "tj_level1_3_slots_ago\ttj_level2_3_slots_ago\ttj_level3_3_slots_ago\ttj_level4_3_slots_ago\t\n",
    "temperature_1_slots_ago\tpm25_1_slots_ago\t\n",
    "temperature_2_slots_ago\tpm25_2_slots_ago\t\n",
    "temperature_3_slots_ago\tpm25_3_slots_ago\t\n",
    "gap_1_slots_ago\tsum_price_1_slots_ago\t\n",
    "gap_2_slots_ago\tsum_price_2_slots_ago\t\n",
    "gap_3_slots_ago\tsum_price_3_slots_ago\t\n",
    "f1\tf11\tf11_1\tf11_2\tf11_3\tf11_4\tf11_5\tf11_6\tf11_7\t\n",
    "f11_8\tf13_4\tf13_8\tf14\tf14_1\tf14_10\tf14_2\tf14_3\tf14_6\tf14_8\tf15\tf15_1\t\n",
    "f15_2\tf15_3\tf15_4\tf15_6\tf15_7\tf15_8\tf16\tf16_1\tf16_10\tf16_11\tf16_12\tf16_3\t\n",
    "f16_4\tf16_6\tf17\tf17_2\tf17_3\tf17_4\tf17_5\tf19\tf19_1\tf19_2\tf19_3\tf19_4\tf1_1\t\n",
    "f1_10\tf1_11\tf1_2\tf1_3\tf1_4\tf1_5\tf1_6\tf1_7\tf1_8\tf20\tf20_1\tf20_2\t\n",
    "f20_4\tf20_5\tf20_6\tf20_7\tf20_8\tf20_9\tf21_1\tf21_2\tf22\tf22_1\tf22_2\tf22_3\t\n",
    "f22_4\tf22_5\tf23\tf23_1\tf23_2\tf23_3\tf23_4\tf23_5\tf23_6\tf24\tf24_1\tf24_2\tf24_3\t\n",
    "f25\tf25_1\tf25_3\tf25_7\tf25_8\tf25_9\tf2_1\tf2_10\tf2_11\tf2_12\tf2_13\tf2_2\t\n",
    "f2_4\tf2_5\tf2_6\tf2_7\tf2_8\tf3_1\tf3_2\tf3_3\tf4\tf4_1\tf4_10\tf4_11\t\n",
    "f4_13\tf4_14\tf4_16\tf4_17\tf4_18\tf4_2\tf4_3\tf4_5\tf4_6\tf4_7\tf4_8\tf4_9\t\n",
    "f5\tf5_1\tf5_3\tf5_4\tf6\tf6_1\tf6_2\tf6_4\tf7\tf8\tf8_1\tf8_2\tf8_3\tf8_4\t\n",
    "f8_5\n",
    "\"\"\"\n",
    "fields = map(lambda x: x.strip(), fields_str.split('\\t'))\n",
    "features = fields[1:]\n",
    "\n",
    "# Use this instead of len(features) since this variable can change\n",
    "# e.g. when one hot encoding is used and/or new features are added.\n",
    "n_features = len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%sql --module q_all\n",
    "\n",
    "SELECT *, HASH(CAST(district_id AS STRING) +timeslot) AS hash_value,\n",
    "  IF(ABS(HASH(CAST(district_id AS STRING) + timeslot)) % 2 == 1, 'True', 'False')\n",
    "    AS included_in_sample, IF(timeofday_slot >= 50 AND timeofday_slot <= 53, 1, 0) AS busy_time\n",
    "FROM [datalab-projects-1331:xjk_algo_comp.gaps]\n",
    "WHERE gap > 0\n",
    "LIMIT 100\n",
    "\n",
    "# The above query randomizes its outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 100 rows\n",
      "processed 0 rows\n"
     ]
    }
   ],
   "source": [
    "query = bq.Query(q_all)\n",
    "tableresult = query.results()\n",
    "\n",
    "all_data = np.zeros((tableresult.length, len(fields)))\n",
    "print 'there are {} rows'.format(tableresult.length)\n",
    "for rcounter, row in enumerate(tableresult):\n",
    "  for fcounter, field in enumerate(fields):\n",
    "    all_data[rcounter, fcounter] = row[field]\n",
    "  if rcounter % 5000 == 0:\n",
    "    print 'processed {} rows'.format(rcounter)\n",
    "all_data_original = np.copy(all_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Preprocess Data\n",
    "\n",
    "Note that in the end we don't use data adjusted from Preprocessing steps, but rather including the preprocessing instances in Pipeline to be applied to original data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_data = np.copy(all_data_original)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Impute NaN and inf values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkinf for NaN and Inf\n",
      "np.nan= (array([ 5,  5, 19, 19, 19, 19, 25, 25, 25, 25, 48, 48]), array([24, 25, 24, 25, 28, 29, 26, 27, 28, 29, 26, 27]))\n",
      "is.inf= (array([], dtype=int64), array([], dtype=int64))\n",
      "np.max= nan\n",
      "Shape of old data:\n",
      "(100, 164)\n",
      "Stats (NaN values are replaced with following means for each feature):\n",
      "[  1.27300000e+01   0.00000000e+00   5.08000000e+00   4.67166667e+00\n",
      "   4.47333333e+00   0.00000000e+00   9.75290000e+02   2.38140000e+02\n",
      "   7.27400000e+01   4.73600000e+01   9.74210000e+02   2.36950000e+02\n",
      "   7.27100000e+01   5.00400000e+01   9.75730000e+02   2.41340000e+02\n",
      "   7.27700000e+01   4.76300000e+01   5.34666667e+00   2.36906667e+02\n",
      "   5.30500000e+00   2.32936667e+02   5.30333333e+00   2.30106667e+02\n",
      "   1.22551020e+01   1.47184388e+03   1.29183673e+01   1.50956429e+03\n",
      "   1.25918367e+01   1.44275204e+03   1.58945000e+03   6.81596000e+03\n",
      "   1.30559000e+03   3.13159000e+03   3.58477000e+03   2.10844900e+04\n",
      "   1.06987000e+03   7.54221000e+03   1.51558000e+03   1.92750900e+04\n",
      "   1.86318400e+04   2.85271000e+03   9.43710000e+02   1.32800000e+01\n",
      "   2.11650000e+02   6.88900000e+01   4.53180000e+02   5.67720000e+02\n",
      "   1.55210000e+02   4.09273000e+03   4.31600000e+01   2.89836000e+03\n",
      "   4.98581000e+03   2.91330000e+02   2.67426000e+03   1.44171000e+03\n",
      "   5.31200000e+01   6.04240000e+03   5.22900000e+01   8.26763000e+03\n",
      "   4.38323000e+03   1.39855000e+03   3.37810000e+02   3.54991000e+03\n",
      "   2.24100000e+01   1.01343000e+03   5.57912000e+03   1.76790000e+02\n",
      "   1.61767000e+03   5.77597000e+03   4.47809900e+04   1.21512000e+03\n",
      "   4.87210000e+02   2.25253700e+04   8.79800000e+02   1.60190000e+02\n",
      "   1.08730000e+02   1.29563000e+03   9.01380000e+02   3.56070000e+02\n",
      "   1.91730000e+02   6.05900000e+03   8.79800000e+01   8.05100000e+01\n",
      "   2.89255000e+03   2.49000000e+04   5.89715000e+03   3.75160000e+03\n",
      "   4.22304000e+03   2.67094000e+03   3.02950000e+02   9.43876000e+03\n",
      "   3.89660100e+04   5.81000000e+00   6.22500000e+01   1.21180000e+02\n",
      "   1.33962000e+03   4.30770000e+02   1.12216000e+03   4.17490000e+02\n",
      "   1.23255000e+03   4.70610000e+02   1.24002000e+03   2.01690000e+02\n",
      "   1.10390000e+02   3.99230000e+02   1.30310000e+02   5.88470000e+02\n",
      "   3.95080000e+02   1.10141000e+03   5.92877200e+04   3.98234000e+03\n",
      "   4.19980000e+02   1.52056000e+03   4.39900000e+01   3.85200000e+02\n",
      "   1.44503000e+03   1.09062000e+03   3.30755000e+03   1.63510000e+02\n",
      "   1.24085000e+03   1.94220000e+02   3.69516000e+03   9.22130000e+02\n",
      "   3.74828000e+03   1.66000000e+02   5.66060000e+02   1.97955000e+03\n",
      "   4.67290000e+02   3.32000000e+01   2.67177000e+03   9.71100000e+01\n",
      "   1.35290000e+02   6.34618000e+03   4.12510000e+02   1.95963000e+03\n",
      "   1.57783000e+03   1.79778000e+03   1.49732000e+03   3.00460000e+02\n",
      "   1.60107000e+03   1.45831000e+03   2.26839000e+03   7.42020000e+02\n",
      "   2.12812000e+03   4.20810000e+02   5.88470000e+02   1.97540000e+02\n",
      "   1.47740000e+03   1.51060000e+02   2.08496000e+03   1.46993000e+03\n",
      "   4.39900000e+01   7.40692000e+03   1.15121000e+03   7.07160000e+02\n",
      "   3.90930000e+02   5.82743000e+03   3.47770000e+02   1.58530000e+02\n",
      "   4.43220000e+03   2.92326000e+03   3.03116000e+03   4.98000000e+01]\n",
      "Shape of new data:\n",
      "(100, 164)\n",
      "Checkinf for NaN and Inf\n",
      "np.nan= (array([], dtype=int64), array([], dtype=int64))\n",
      "is.inf= (array([], dtype=int64), array([], dtype=int64))\n",
      "np.max= 461563.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import Imputer\n",
    "# Useful code to check NaN and Inf values. This is needed since these values would\n",
    "# cause \"Input contains NaN, infinity or a value too large for dtype('float32')\n",
    "# errors when left unchecked.\n",
    "print \"Checkinf for NaN and Inf\"\n",
    "print \"np.nan=\", np.where(np.isnan(all_data))\n",
    "print \"is.inf=\", np.where(np.isinf(all_data))\n",
    "print \"np.max=\", np.max(abs(all_data))\n",
    "\n",
    "# Impute\n",
    "imputer = Imputer()\n",
    "imputer.fit(all_data)\n",
    "print 'Shape of old data:'\n",
    "print all_data.shape\n",
    "print 'Stats (NaN values are replaced with following means for each feature):'\n",
    "print imputer.statistics_\n",
    "all_data = imputer.fit_transform(all_data)\n",
    "print 'Shape of new data:'\n",
    "print all_data.shape\n",
    "\n",
    "# See that NaN and Inf values replaced\n",
    "print \"Checkinf for NaN and Inf\"\n",
    "print \"np.nan=\", np.where(np.isnan(all_data))\n",
    "print \"is.inf=\", np.where(np.isinf(all_data))\n",
    "print \"np.max=\", np.max(abs(all_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. One Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_values_:\n",
      "[ 7 10 10 10]\n",
      "feature_indices_:\n",
      "[ 0  7 17 27 37]\n",
      "new number of features: 196\n"
     ]
    }
   ],
   "source": [
    "one_hot = OneHotEncoder(categorical_features=[1, 2, 3, 4], n_values=[7, 10, 10, 10])\n",
    "one_hot.fit(all_data)\n",
    "print \"n_values_:\"\n",
    "print one_hot.n_values_\n",
    "print \"feature_indices_:\"\n",
    "print one_hot.feature_indices_\n",
    "all_data = one_hot.fit_transform(all_data).todense()\n",
    "n_features = all_data.shape[1] - 1\n",
    "print 'new number of features: {}'.format(n_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3. Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "old data:\n",
      "means: 2430.2805102, min: 0.0, max: 461563.0\n",
      "new data:\n",
      "means: 1.15418109362e-17, min: -2.28589190215, max: 8.71481455667\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "print 'old data:'\n",
    "print 'means: {}, min: {}, max: {}'.format(np.mean(all_data), np.min(all_data), np.max(all_data))\n",
    "all_data = scaler.fit_transform(all_data)\n",
    "print 'new data:'\n",
    "print 'means: {}, min: {}, max: {}'.format(np.mean(all_data), np.min(all_data), np.max(all_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Split into Train and Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split the originaldata into train and test sets.\n",
    "data_size = all_data_original.shape[0]\n",
    "training_size = data_size * 90/100\n",
    "indices = np.random.permutation(data_size)\n",
    "training_idx, test_idx = indices[:training_size], indices[training_size:]\n",
    "all_data_train, all_data_test = all_data_original[training_idx,:], all_data_original[test_idx,:]\n",
    "\n",
    "data_train = all_data_train[:,1:]\n",
    "targets_train = all_data_train[:,0]\n",
    "data_test = all_data_test[:,1:]\n",
    "targets_test = all_data_test[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Model Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1. Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mape(y, predictions):\n",
    "  return K.mean(K.abs(y-predictions/K.clip(K.abs(y), K.epsilon(), np.inf)), axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2. Create Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_model(optimizer='adagrad', init='uniform'):\n",
    "  model = Sequential()\n",
    "  model.add(Dense(n_features, input_dim=n_features, init=init, activation='relu'))\n",
    "  model.add(Dense(int(n_features/2), init=init, activation='relu'))\n",
    "  model.add(Dense(int(n_features/4), init=init, activation='relu'))\n",
    "  model.add(Dense(1))\n",
    "  model.compile(loss=mape, optimizer=optimizer)\n",
    "  return model\n",
    "\n",
    "model = KerasRegressor(build_fn=create_model, nb_epoch=20, batch_size=10, verbose=2)\n",
    "\n",
    "steps = [\n",
    "  ('impute', Imputer()),\n",
    "  # Remember that gap, the first variable, is removed, thus categorical_features\n",
    "  # should start at index 0.\n",
    "  ('one_hot', OneHotEncoder(categorical_features=[0, 1, 2, 3], sparse=False)),\n",
    "  ('scale', StandardScaler()),\n",
    "#   ('pca', PCA(n_components=120)),\n",
    "  ('estimate', model)\n",
    "]\n",
    "final_est = Pipeline(steps)\n",
    "\n",
    "# kfold = StratifiedKFold(y=targets_train, n_folds=10, shuffle=True, random_state=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3. Grid Search to Find Best Hyperparameters\n",
    "\n",
    "Use subset of training data in grid search just to find what hyperparameters are best for this project. Specifically we want to find the best optimizer, initializer, and batch size. Topology of the model will be adjusted in crossvalidation step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# model.fit(data_train, targets_train, validation_split=0.33,  nb_epoch=100, batch_size=10, \n",
    "#           callbacks=callbacks_list)\n",
    "# results = cross_val_score(model, data_train, targets_train, cv=kfold)\n",
    "\n",
    "# checkpoint = ModelCheckpoint(GRID_HDF_FILENAME, monitor='loss', save_best_only=True, mode='min')\n",
    "# callbacks_list = [checkpoint]\n",
    "\n",
    "# epochs = 150\n",
    "# learning_rate = 0.1\n",
    "# decay_rate = learning_rate / epochs\n",
    "# momentum = 0.8\n",
    "# sgd = SGD(lr=learning_rate, momentum=momentum, decay=decay_rate, nesterov=False)\n",
    "\n",
    "# data_train_s = data_train[:1000]\n",
    "# targets_train_s = targets_train[:1000]\n",
    "# optimizers = [sgd, 'adam', 'adagrad']\n",
    "# init = ['glorot_uniform', 'normal', 'uniform']\n",
    "# epochs_r = np.array([epochs])\n",
    "# batches = np.array([5, 10, 20])\n",
    "# param_grid = {\n",
    "#   'estimate__optimizer': optimizers,\n",
    "#   'estimate__nb_epoch': epochs_r, \n",
    "#   'estimate__batch_size': batches,\n",
    "#   'estimate__init': init,\n",
    "#   'estimate__callbacks': [callbacks_list]\n",
    "# }\n",
    "\n",
    "# grid = GridSearchCV(estimator=final_est, param_grid=param_grid, cv=3)\n",
    "# grid_result = grid.fit(data_train_s, targets_train_s)\n",
    "# time.sleep(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# summarize results\n",
    "# print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "# for params, mean_score, scores in grid_result.grid_scores_:\n",
    "# print(\"%f (%f) with: %r\" % (scores.mean(), scores.std(), params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# scores = model.evaluate(data_train, targets_train)\n",
    "# print(\"\\nscore: %.2f%\" % (scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# scores = model.evaluate(data_test, targets_test)\n",
    "# print(\"\\nscore: %.2f%\" % (scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4. Crossvalidation\n",
    "\n",
    "Use entire training data for cross validation. Resulting model from here will be the final model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "steps = [\n",
    "  ('impute', Imputer()),\n",
    "  # Remember that gap, the first variable, is removed, thus categorical_features\n",
    "  # should start at index 0.\n",
    "  ('one_hot', OneHotEncoder(categorical_features=[0, 1, 2, 3], sparse=False,\n",
    "                           n_values=[7, 10, 10, 10])),\n",
    "  ('scale', StandardScaler()),\n",
    "#   ('pca', PCA(n_components=120)),\n",
    "#   ('estimate', final_model)\n",
    "]\n",
    "transformer = Pipeline(steps)\n",
    "data_train2 = transformer.fit_transform(data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epochs = 1000\n",
    "\n",
    "def get_optimizer(epochs=50):\n",
    "  learning_rate = 0.1\n",
    "  decay_rate = learning_rate / epochs\n",
    "  momentum = 0.8\n",
    "  return SGD(lr=learning_rate, momentum=momentum, decay=decay_rate, nesterov=False)\n",
    "\n",
    "def create_final_model():\n",
    "  init='uniform'\n",
    "  final_model = Sequential()\n",
    "  final_model.add(Dropout(0.2, input_shape=(n_features,)))\n",
    "  final_model.add(Dense(n_features, init=init, activation='relu'))\n",
    "  final_model.add(Dropout(0.2))\n",
    "  final_model.add(Dense(int(n_features/2), init=init, activation='relu'))\n",
    "  final_model.add(Dropout(0.2))\n",
    "  final_model.add(Dense(int(n_features/4), init=init, activation='relu'))\n",
    "  final_model.add(Dropout(0.2))\n",
    "  final_model.add(Dense(1))\n",
    "  final_model.compile(loss=mape, optimizer=get_optimizer(epochs))\n",
    "  return final_model\n",
    "\n",
    "final_est = KerasRegressor(build_fn=create_final_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00000: val_loss improved from inf to 20.11314, saving model to final_model.hdf5\n",
      "Epoch 00001: val_loss improved from 20.11314 to 20.07812, saving model to final_model.hdf5\n",
      "Epoch 00002: val_loss improved from 20.07812 to 20.03879, saving model to final_model.hdf5\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 00004: val_loss improved from 20.03879 to 20.03076, saving model to final_model.hdf5\n"
     ]
    }
   ],
   "source": [
    "checkpoint = ModelCheckpoint(HDF_FILENAME, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "history = final_est.fit(data_train2, targets_train, validation_split=0.33,\n",
    "                          nb_epoch=epochs, batch_size=10, verbose=0, callbacks=callbacks_list)\n",
    "time.sleep(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfcAAAFwCAYAAAClwDJHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIdwBALAM4Q4AgGX+P4WmWIp8Ol+1AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fbd852dba50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# kfold = KFold(n=len(data_train), n_folds=10, random_state=seed)\n",
    "# results = cross_val_score(estimator, data_train, targets_train, cv=kfold)\n",
    "# print(\"Results: %.2f (%.2f) MSE\" % (results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Store Model to File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_json = final_est.model.to_json()\n",
    "with open(JSON_MODEL_FILENAME, \"w\") as json_file:\n",
    "  json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n",
      "loss: 4.41\n",
      "sample predictions:\n",
      "[[ 1.00299489]\n",
      " [ 2.12118793]\n",
      " [ 1.26778364]\n",
      " [ 1.14150071]\n",
      " [ 1.10343719]\n",
      " [ 1.00503707]\n",
      " [ 1.16558719]\n",
      " [ 1.02556276]\n",
      " [ 0.98141098]\n",
      " [ 1.24408364]]\n"
     ]
    }
   ],
   "source": [
    "from keras.models import model_from_json\n",
    "json_file = open(JSON_MODEL_FILENAME, 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(HDF_FILENAME)\n",
    "print(\"Loaded model from disk\")\n",
    "\n",
    "# evaluate loaded model on test data\n",
    "data_test2 = transformer.fit_transform(data_test)\n",
    "loaded_model.compile(loss=mape, optimizer=get_optimizer(epochs))\n",
    "score = loaded_model.evaluate(data_test2, targets_test, verbose=0)\n",
    "print \"%s: %.2f\" % (loaded_model.metrics_names[0], score)\n",
    "predictions = loaded_model.predict(data_test2)\n",
    "print 'sample predictions:'\n",
    "print(predictions[0:10])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
