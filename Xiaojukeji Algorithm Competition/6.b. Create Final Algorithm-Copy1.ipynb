{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pdb\n",
    "import numpy as np\n",
    "import gcp.bigquery as bq\n",
    "import gcp.storage as storage\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import backend as K\n",
    "from keras.optimizers import SGD\n",
    "import tensorflow as tf\n",
    "import h5py\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "import time\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers import Dropout\n",
    "\n",
    "\n",
    "try:\n",
    "  import cPickle as pickle\n",
    "except:\n",
    "  import pickle\n",
    "HDF_FILENAME = 'final_model.hdf5'\n",
    "JSON_MODEL_FILENAME = 'final_model.json'\n",
    "\n",
    "GRID_HDF_FILENAME = 'best_grid_model.hdf5'\n",
    "\n",
    "seed = 13\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Put all categorical data first for easier implementation of One Hot Encoding.\n",
    "fields_str = \"\"\"\n",
    "gap\tday_in_week\tweather_1_slots_ago\tweather_2_slots_ago\tweather_3_slots_ago\tbusy_time\t\n",
    "tj_level1_1_slots_ago\ttj_level2_1_slots_ago\ttj_level3_1_slots_ago\ttj_level4_1_slots_ago\t\n",
    "tj_level1_2_slots_ago\ttj_level2_2_slots_ago\ttj_level3_2_slots_ago\ttj_level4_2_slots_ago\t\n",
    "tj_level1_3_slots_ago\ttj_level2_3_slots_ago\ttj_level3_3_slots_ago\ttj_level4_3_slots_ago\t\n",
    "temperature_1_slots_ago\tpm25_1_slots_ago\t\n",
    "temperature_2_slots_ago\tpm25_2_slots_ago\t\n",
    "temperature_3_slots_ago\tpm25_3_slots_ago\t\n",
    "gap_1_slots_ago\tsum_price_1_slots_ago\t\n",
    "gap_2_slots_ago\tsum_price_2_slots_ago\t\n",
    "gap_3_slots_ago\tsum_price_3_slots_ago\t\n",
    "f1\tf11\tf11_1\tf11_2\tf11_3\tf11_4\tf11_5\tf11_6\tf11_7\t\n",
    "f11_8\tf13_4\tf13_8\tf14\tf14_1\tf14_10\tf14_2\tf14_3\tf14_6\tf14_8\tf15\tf15_1\t\n",
    "f15_2\tf15_3\tf15_4\tf15_6\tf15_7\tf15_8\tf16\tf16_1\tf16_10\tf16_11\tf16_12\tf16_3\t\n",
    "f16_4\tf16_6\tf17\tf17_2\tf17_3\tf17_4\tf17_5\tf19\tf19_1\tf19_2\tf19_3\tf19_4\tf1_1\t\n",
    "f1_10\tf1_11\tf1_2\tf1_3\tf1_4\tf1_5\tf1_6\tf1_7\tf1_8\tf20\tf20_1\tf20_2\t\n",
    "f20_4\tf20_5\tf20_6\tf20_7\tf20_8\tf20_9\tf21_1\tf21_2\tf22\tf22_1\tf22_2\tf22_3\t\n",
    "f22_4\tf22_5\tf23\tf23_1\tf23_2\tf23_3\tf23_4\tf23_5\tf23_6\tf24\tf24_1\tf24_2\tf24_3\t\n",
    "f25\tf25_1\tf25_3\tf25_7\tf25_8\tf25_9\tf2_1\tf2_10\tf2_11\tf2_12\tf2_13\tf2_2\t\n",
    "f2_4\tf2_5\tf2_6\tf2_7\tf2_8\tf3_1\tf3_2\tf3_3\tf4\tf4_1\tf4_10\tf4_11\t\n",
    "f4_13\tf4_14\tf4_16\tf4_17\tf4_18\tf4_2\tf4_3\tf4_5\tf4_6\tf4_7\tf4_8\tf4_9\t\n",
    "f5\tf5_1\tf5_3\tf5_4\tf6\tf6_1\tf6_2\tf6_4\tf7\tf8\tf8_1\tf8_2\tf8_3\tf8_4\t\n",
    "f8_5\n",
    "\"\"\"\n",
    "fields = map(lambda x: x.strip(), fields_str.split('\\t'))\n",
    "features = fields[1:]\n",
    "\n",
    "# Use this instead of len(features) since this variable can change\n",
    "# e.g. when one hot encoding is used and/or new features are added.\n",
    "n_features = len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%sql --module q_all\n",
    "\n",
    "SELECT *, HASH(CAST(district_id AS STRING) +timeslot) AS hash_value,\n",
    "  IF(ABS(HASH(CAST(district_id AS STRING) + timeslot)) % 2 == 1, 'True', 'False')\n",
    "    AS included_in_sample, IF(timeofday_slot >= 50 AND timeofday_slot <= 53, 1, 0) AS busy_time\n",
    "FROM [datalab-projects-1331:xjk_algo_comp.gaps]\n",
    "WHERE gap > 0\n",
    "LIMIT 100\n",
    "\n",
    "# The above query randomizes its outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 100 rows\n",
      "processed 0 rows\n"
     ]
    }
   ],
   "source": [
    "query = bq.Query(q_all)\n",
    "tableresult = query.results()\n",
    "\n",
    "all_data = np.zeros((tableresult.length, len(fields)))\n",
    "print 'there are {} rows'.format(tableresult.length)\n",
    "for rcounter, row in enumerate(tableresult):\n",
    "  for fcounter, field in enumerate(fields):\n",
    "    all_data[rcounter, fcounter] = row[field]\n",
    "  if rcounter % 5000 == 0:\n",
    "    print 'processed {} rows'.format(rcounter)\n",
    "all_data_original = np.copy(all_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Preprocess Data\n",
    "\n",
    "Note that in the end we don't use data adjusted from Preprocessing steps, but rather including the preprocessing instances in Pipeline to be applied to original data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_data = np.copy(all_data_original)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Impute NaN and inf values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkinf for NaN and Inf\n",
      "np.nan= (array([ 5,  5, 19, 19, 19, 19, 25, 25, 25, 25, 48, 48]), array([24, 25, 24, 25, 28, 29, 26, 27, 28, 29, 26, 27]))\n",
      "is.inf= (array([], dtype=int64), array([], dtype=int64))\n",
      "np.max= nan\n",
      "Shape of old data:\n",
      "(100, 164)\n",
      "Stats (NaN values are replaced with following means for each feature):\n",
      "[  1.27300000e+01   0.00000000e+00   5.08000000e+00   4.67166667e+00\n",
      "   4.47333333e+00   0.00000000e+00   9.75290000e+02   2.38140000e+02\n",
      "   7.27400000e+01   4.73600000e+01   9.74210000e+02   2.36950000e+02\n",
      "   7.27100000e+01   5.00400000e+01   9.75730000e+02   2.41340000e+02\n",
      "   7.27700000e+01   4.76300000e+01   5.34666667e+00   2.36906667e+02\n",
      "   5.30500000e+00   2.32936667e+02   5.30333333e+00   2.30106667e+02\n",
      "   1.22551020e+01   1.47184388e+03   1.29183673e+01   1.50956429e+03\n",
      "   1.25918367e+01   1.44275204e+03   1.58945000e+03   6.81596000e+03\n",
      "   1.30559000e+03   3.13159000e+03   3.58477000e+03   2.10844900e+04\n",
      "   1.06987000e+03   7.54221000e+03   1.51558000e+03   1.92750900e+04\n",
      "   1.86318400e+04   2.85271000e+03   9.43710000e+02   1.32800000e+01\n",
      "   2.11650000e+02   6.88900000e+01   4.53180000e+02   5.67720000e+02\n",
      "   1.55210000e+02   4.09273000e+03   4.31600000e+01   2.89836000e+03\n",
      "   4.98581000e+03   2.91330000e+02   2.67426000e+03   1.44171000e+03\n",
      "   5.31200000e+01   6.04240000e+03   5.22900000e+01   8.26763000e+03\n",
      "   4.38323000e+03   1.39855000e+03   3.37810000e+02   3.54991000e+03\n",
      "   2.24100000e+01   1.01343000e+03   5.57912000e+03   1.76790000e+02\n",
      "   1.61767000e+03   5.77597000e+03   4.47809900e+04   1.21512000e+03\n",
      "   4.87210000e+02   2.25253700e+04   8.79800000e+02   1.60190000e+02\n",
      "   1.08730000e+02   1.29563000e+03   9.01380000e+02   3.56070000e+02\n",
      "   1.91730000e+02   6.05900000e+03   8.79800000e+01   8.05100000e+01\n",
      "   2.89255000e+03   2.49000000e+04   5.89715000e+03   3.75160000e+03\n",
      "   4.22304000e+03   2.67094000e+03   3.02950000e+02   9.43876000e+03\n",
      "   3.89660100e+04   5.81000000e+00   6.22500000e+01   1.21180000e+02\n",
      "   1.33962000e+03   4.30770000e+02   1.12216000e+03   4.17490000e+02\n",
      "   1.23255000e+03   4.70610000e+02   1.24002000e+03   2.01690000e+02\n",
      "   1.10390000e+02   3.99230000e+02   1.30310000e+02   5.88470000e+02\n",
      "   3.95080000e+02   1.10141000e+03   5.92877200e+04   3.98234000e+03\n",
      "   4.19980000e+02   1.52056000e+03   4.39900000e+01   3.85200000e+02\n",
      "   1.44503000e+03   1.09062000e+03   3.30755000e+03   1.63510000e+02\n",
      "   1.24085000e+03   1.94220000e+02   3.69516000e+03   9.22130000e+02\n",
      "   3.74828000e+03   1.66000000e+02   5.66060000e+02   1.97955000e+03\n",
      "   4.67290000e+02   3.32000000e+01   2.67177000e+03   9.71100000e+01\n",
      "   1.35290000e+02   6.34618000e+03   4.12510000e+02   1.95963000e+03\n",
      "   1.57783000e+03   1.79778000e+03   1.49732000e+03   3.00460000e+02\n",
      "   1.60107000e+03   1.45831000e+03   2.26839000e+03   7.42020000e+02\n",
      "   2.12812000e+03   4.20810000e+02   5.88470000e+02   1.97540000e+02\n",
      "   1.47740000e+03   1.51060000e+02   2.08496000e+03   1.46993000e+03\n",
      "   4.39900000e+01   7.40692000e+03   1.15121000e+03   7.07160000e+02\n",
      "   3.90930000e+02   5.82743000e+03   3.47770000e+02   1.58530000e+02\n",
      "   4.43220000e+03   2.92326000e+03   3.03116000e+03   4.98000000e+01]\n",
      "Shape of new data:\n",
      "(100, 164)\n",
      "Checkinf for NaN and Inf\n",
      "np.nan= (array([], dtype=int64), array([], dtype=int64))\n",
      "is.inf= (array([], dtype=int64), array([], dtype=int64))\n",
      "np.max= 461563.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import Imputer\n",
    "# Useful code to check NaN and Inf values. This is needed since these values would\n",
    "# cause \"Input contains NaN, infinity or a value too large for dtype('float32')\n",
    "# errors when left unchecked.\n",
    "print \"Checkinf for NaN and Inf\"\n",
    "print \"np.nan=\", np.where(np.isnan(all_data))\n",
    "print \"is.inf=\", np.where(np.isinf(all_data))\n",
    "print \"np.max=\", np.max(abs(all_data))\n",
    "\n",
    "# Impute\n",
    "imputer = Imputer()\n",
    "imputer.fit(all_data)\n",
    "print 'Shape of old data:'\n",
    "print all_data.shape\n",
    "print 'Stats (NaN values are replaced with following means for each feature):'\n",
    "print imputer.statistics_\n",
    "all_data = imputer.fit_transform(all_data)\n",
    "print 'Shape of new data:'\n",
    "print all_data.shape\n",
    "\n",
    "# See that NaN and Inf values replaced\n",
    "print \"Checkinf for NaN and Inf\"\n",
    "print \"np.nan=\", np.where(np.isnan(all_data))\n",
    "print \"is.inf=\", np.where(np.isinf(all_data))\n",
    "print \"np.max=\", np.max(abs(all_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. One Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_values_:\n",
      "[ 1 10 10 10]\n",
      "feature_indices_:\n",
      "[ 0  1 11 21 31]\n",
      "new number of features: 174\n"
     ]
    }
   ],
   "source": [
    "one_hot = OneHotEncoder(categorical_features=[1, 2, 3, 4], n_values='auto')\n",
    "one_hot.fit(all_data)\n",
    "print \"n_values_:\"\n",
    "print one_hot.n_values_\n",
    "print \"feature_indices_:\"\n",
    "print one_hot.feature_indices_\n",
    "all_data = one_hot.fit_transform(all_data).todense()\n",
    "n_features = all_data.shape[1] - 1\n",
    "print 'new number of features: {}'.format(n_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3. Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "old data:\n",
      "means: 2735.80148863, min: 0.0, max: 461563.0\n",
      "new data:\n",
      "means: 1.13686837722e-17, min: -2.28589190215, max: 8.71481455667\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "print 'old data:'\n",
    "print 'means: {}, min: {}, max: {}'.format(np.mean(all_data), np.min(all_data), np.max(all_data))\n",
    "all_data = scaler.fit_transform(all_data)\n",
    "print 'new data:'\n",
    "print 'means: {}, min: {}, max: {}'.format(np.mean(all_data), np.min(all_data), np.max(all_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Split into Train and Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split the originaldata into train and test sets.\n",
    "data_size = all_data_original.shape[0]\n",
    "training_size = data_size * 90/100\n",
    "indices = np.random.permutation(data_size)\n",
    "training_idx, test_idx = indices[:training_size], indices[training_size:]\n",
    "all_data_train, all_data_test = all_data_original[training_idx,:], all_data_original[test_idx,:]\n",
    "\n",
    "data_train = all_data_train[:,1:]\n",
    "targets_train = all_data_train[:,0]\n",
    "data_test = all_data_test[:,1:]\n",
    "targets_test = all_data_test[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Model Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1. Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mape(y, predictions):\n",
    "  return K.mean(K.abs(y-predictions/K.clip(K.abs(y), K.epsilon(), np.inf)), axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2. Create Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_model(optimizer='adagrad', init='uniform'):\n",
    "  model = Sequential()\n",
    "  model.add(Dense(n_features, input_dim=n_features, init=init, activation='relu'))\n",
    "  model.add(Dense(int(n_features/2), init=init, activation='relu'))\n",
    "  model.add(Dense(int(n_features/4), init=init, activation='relu'))\n",
    "  model.add(Dense(1))\n",
    "  model.compile(loss=mape, optimizer=optimizer)\n",
    "  return model\n",
    "\n",
    "model = KerasRegressor(build_fn=create_model, nb_epoch=20, batch_size=10, verbose=2)\n",
    "\n",
    "steps = [\n",
    "  ('impute', Imputer()),\n",
    "  # Remember that gap, the first variable, is removed, thus categorical_features\n",
    "  # should start at index 0.\n",
    "  ('one_hot', OneHotEncoder(categorical_features=[0, 1, 2, 3], sparse=False)),\n",
    "  ('scale', StandardScaler()),\n",
    "#   ('pca', PCA(n_components=120)),\n",
    "  ('estimate', model)\n",
    "]\n",
    "final_est = Pipeline(steps)\n",
    "\n",
    "# kfold = StratifiedKFold(y=targets_train, n_folds=10, shuffle=True, random_state=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3. Grid Search to Find Best Hyperparameters\n",
    "\n",
    "Use subset of training data in grid search just to find what hyperparameters are best for this project. Specifically we want to find the best optimizer, initializer, and batch size. Topology of the model will be adjusted in crossvalidation step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# model.fit(data_train, targets_train, validation_split=0.33,  nb_epoch=100, batch_size=10, \n",
    "#           callbacks=callbacks_list)\n",
    "# results = cross_val_score(model, data_train, targets_train, cv=kfold)\n",
    "\n",
    "# checkpoint = ModelCheckpoint(GRID_HDF_FILENAME, monitor='loss', save_best_only=True, mode='min')\n",
    "# callbacks_list = [checkpoint]\n",
    "\n",
    "# epochs = 150\n",
    "# learning_rate = 0.1\n",
    "# decay_rate = learning_rate / epochs\n",
    "# momentum = 0.8\n",
    "# sgd = SGD(lr=learning_rate, momentum=momentum, decay=decay_rate, nesterov=False)\n",
    "\n",
    "# data_train_s = data_train[:1000]\n",
    "# targets_train_s = targets_train[:1000]\n",
    "# optimizers = [sgd, 'adam', 'adagrad']\n",
    "# init = ['glorot_uniform', 'normal', 'uniform']\n",
    "# epochs_r = np.array([epochs])\n",
    "# batches = np.array([5, 10, 20])\n",
    "# param_grid = {\n",
    "#   'estimate__optimizer': optimizers,\n",
    "#   'estimate__nb_epoch': epochs_r, \n",
    "#   'estimate__batch_size': batches,\n",
    "#   'estimate__init': init,\n",
    "#   'estimate__callbacks': [callbacks_list]\n",
    "# }\n",
    "\n",
    "# grid = GridSearchCV(estimator=final_est, param_grid=param_grid, cv=3)\n",
    "# grid_result = grid.fit(data_train_s, targets_train_s)\n",
    "# time.sleep(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# summarize results\n",
    "# print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "# for params, mean_score, scores in grid_result.grid_scores_:\n",
    "# print(\"%f (%f) with: %r\" % (scores.mean(), scores.std(), params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# scores = model.evaluate(data_train, targets_train)\n",
    "# print(\"\\nscore: %.2f%\" % (scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# scores = model.evaluate(data_test, targets_test)\n",
    "# print(\"\\nscore: %.2f%\" % (scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4. Crossvalidation\n",
    "\n",
    "Use entire training data for cross validation. Resulting model from here will be the final model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "steps = [\n",
    "  ('impute', Imputer()),\n",
    "  # Remember that gap, the first variable, is removed, thus categorical_features\n",
    "  # should start at index 0.\n",
    "  ('one_hot', OneHotEncoder(categorical_features=[0, 1, 2, 3], sparse=False)),\n",
    "  ('scale', StandardScaler()),\n",
    "#   ('pca', PCA(n_components=120)),\n",
    "#   ('estimate', final_model)\n",
    "]\n",
    "transformer = Pipeline(steps)\n",
    "data_train2 = transformer.fit_transform(data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epochs = 5\n",
    "\n",
    "def get_optimizer(epochs=50):\n",
    "  learning_rate = 0.1\n",
    "  decay_rate = learning_rate / epochs\n",
    "  momentum = 0.8\n",
    "  return SGD(lr=learning_rate, momentum=momentum, decay=decay_rate, nesterov=False)\n",
    "\n",
    "def create_final_model():\n",
    "  init='uniform'\n",
    "  final_model = Sequential()\n",
    "  final_model.add(Dropout(0.2, input_shape=(n_features,)))\n",
    "  final_model.add(Dense(n_features, init=init, activation='relu'))\n",
    "  final_model.add(Dropout(0.2))\n",
    "  final_model.add(Dense(int(n_features/2), init=init, activation='relu'))\n",
    "  final_model.add(Dropout(0.2))\n",
    "  final_model.add(Dense(int(n_features/4), init=init, activation='relu'))\n",
    "  final_model.add(Dropout(0.2))\n",
    "  final_model.add(Dense(1))\n",
    "  final_model.compile(loss=mape, optimizer=get_optimizer(epochs))\n",
    "  return final_model\n",
    "\n",
    "final_est = KerasRegressor(build_fn=create_final_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00000: val_loss improved from inf to 20.12825, saving model to final_model.hdf5\n",
      "Epoch 00001: val_loss improved from 20.12825 to 20.11922, saving model to final_model.hdf5\n",
      "Epoch 00002: val_loss improved from 20.11922 to 20.04584, saving model to final_model.hdf5\n",
      "Epoch 00003: val_loss improved from 20.04584 to 20.03606, saving model to final_model.hdf5\n",
      "Epoch 00004: val_loss did not improve\n"
     ]
    }
   ],
   "source": [
    "checkpoint = ModelCheckpoint(HDF_FILENAME, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "history = final_est.fit(data_train2, targets_train, validation_split=0.33,\n",
    "                          nb_epoch=epochs, batch_size=10, verbose=0, callbacks=callbacks_list)\n",
    "time.sleep(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfcAAAFwCAYAAAClwDJHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAACWIdwBALDM/wdtR4VudR9/EgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc77def1650>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# kfold = KFold(n=len(data_train), n_folds=10, random_state=seed)\n",
    "# results = cross_val_score(estimator, data_train, targets_train, cv=kfold)\n",
    "# print(\"Results: %.2f (%.2f) MSE\" % (results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'KerasRegressor' object has no attribute 'model'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0mTraceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-5d1b5535e88c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/keras/wrappers/scikit_learn.pyc\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X, **kwargs)\u001b[0m\n\u001b[0;32m    253\u001b[0m         '''\n\u001b[0;32m    254\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilter_sk_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSequential\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 255\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    256\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    257\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'KerasRegressor' object has no attribute 'model'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(predictions[0:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Store Model to File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_json = final_est.model.to_json()\n",
    "with open(JSON_MODEL_FILENAME, \"w\") as json_file:\n",
    "  json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.models import model_from_json\n",
    "json_file = open(JSON_MODEL_FILENAME, 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(HDF_FILENAME)\n",
    "print(\"Loaded model from disk\")\n",
    "\n",
    "# evaluate loaded model on test data\n",
    "data_test2 = transformer.fit_transform(data_test)\n",
    "loaded_model.compile(loss=mape, optimizer=get_optimizer(epochs))\n",
    "score = loaded_model.evaluate(data_test2, targets_test, verbose=0)\n",
    "print \"%s: %.2f%%\" % (loaded_model.metrics_names[1], score[1]*100)\n",
    "predictions = loaded_model.predict(data_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
