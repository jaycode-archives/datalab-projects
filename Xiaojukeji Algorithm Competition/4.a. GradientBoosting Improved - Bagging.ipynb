{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pdb\n",
    "import numpy as np\n",
    "import gcp.bigquery as bq\n",
    "import gcp.storage as storage\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import Imputer, MinMaxScaler, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.preprocessing import Imputer, OneHotEncoder\n",
    "from sklearn.grid_search import RandomizedSearchCV\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import cross_validation\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.feature_selection import RFECV\n",
    "\n",
    "try:\n",
    "   import cPickle as pickle\n",
    "except:\n",
    "   import pickle\n",
    "EST_PICKLE_FILENAME1 = 'BaggingGradientBoostingRegressor_initial.pkl'\n",
    "EST_PICKLE_FILENAME2 = 'BaggingGradientBoostingRegressor_final.pkl'\n",
    "\n",
    "seed = 13\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Put all categorical data first for easier implementation of One Hot Encoding.\n",
    "fields_str = \"\"\"\n",
    "gap\tday_in_week\tweather_1_slots_ago\tweather_2_slots_ago\tweather_3_slots_ago\tbusy_time\t\n",
    "tj_level1_1_slots_ago\ttj_level2_1_slots_ago\ttj_level3_1_slots_ago\ttj_level4_1_slots_ago\t\n",
    "tj_level1_2_slots_ago\ttj_level2_2_slots_ago\ttj_level3_2_slots_ago\ttj_level4_2_slots_ago\t\n",
    "tj_level1_3_slots_ago\ttj_level2_3_slots_ago\ttj_level3_3_slots_ago\ttj_level4_3_slots_ago\t\n",
    "temperature_1_slots_ago\tpm25_1_slots_ago\t\n",
    "temperature_2_slots_ago\tpm25_2_slots_ago\t\n",
    "temperature_3_slots_ago\tpm25_3_slots_ago\t\n",
    "gap_1_slots_ago\tsum_price_1_slots_ago\t\n",
    "gap_2_slots_ago\tsum_price_2_slots_ago\t\n",
    "gap_3_slots_ago\tsum_price_3_slots_ago\t\n",
    "f1\tf11\tf11_1\tf11_2\tf11_3\tf11_4\tf11_5\tf11_6\tf11_7\t\n",
    "f11_8\tf13_4\tf13_8\tf14\tf14_1\tf14_10\tf14_2\tf14_3\tf14_6\tf14_8\tf15\tf15_1\t\n",
    "f15_2\tf15_3\tf15_4\tf15_6\tf15_7\tf15_8\tf16\tf16_1\tf16_10\tf16_11\tf16_12\tf16_3\t\n",
    "f16_4\tf16_6\tf17\tf17_2\tf17_3\tf17_4\tf17_5\tf19\tf19_1\tf19_2\tf19_3\tf19_4\tf1_1\t\n",
    "f1_10\tf1_11\tf1_2\tf1_3\tf1_4\tf1_5\tf1_6\tf1_7\tf1_8\tf20\tf20_1\tf20_2\t\n",
    "f20_4\tf20_5\tf20_6\tf20_7\tf20_8\tf20_9\tf21_1\tf21_2\tf22\tf22_1\tf22_2\tf22_3\t\n",
    "f22_4\tf22_5\tf23\tf23_1\tf23_2\tf23_3\tf23_4\tf23_5\tf23_6\tf24\tf24_1\tf24_2\tf24_3\t\n",
    "f25\tf25_1\tf25_3\tf25_7\tf25_8\tf25_9\tf2_1\tf2_10\tf2_11\tf2_12\tf2_13\tf2_2\t\n",
    "f2_4\tf2_5\tf2_6\tf2_7\tf2_8\tf3_1\tf3_2\tf3_3\tf4\tf4_1\tf4_10\tf4_11\t\n",
    "f4_13\tf4_14\tf4_16\tf4_17\tf4_18\tf4_2\tf4_3\tf4_5\tf4_6\tf4_7\tf4_8\tf4_9\t\n",
    "f5\tf5_1\tf5_3\tf5_4\tf6\tf6_1\tf6_2\tf6_4\tf7\tf8\tf8_1\tf8_2\tf8_3\tf8_4\t\n",
    "f8_5\n",
    "\"\"\"\n",
    "fields = map(lambda x: x.strip(), fields_str.split('\\t'))\n",
    "features = fields[1:]\n",
    "\n",
    "# Use this instead of len(features) since this variable can change\n",
    "# e.g. when one hot encoding is used and/or new features are added.\n",
    "n_features = len(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scorer Creation (MAPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def mape(y, predictions):\n",
    "#   num_timeslots = 43\n",
    "#   num_districts = 66\n",
    "  if len(y.shape) == 1:\n",
    "    y = np.asmatrix(y)\n",
    "  if len(predictions.shape) == 1:\n",
    "    predictions = np.asmatrix(predictions)\n",
    "  y = y.astype(float)\n",
    "  predictions = predictions.astype(float)\n",
    "  return np.mean(np.absolute((y-predictions)/y))\n",
    "\n",
    "# from keras import backend as K\n",
    "\n",
    "# def mape(y, predictions):\n",
    "#   return K.mean(K.abs(y-predictions/K.clip(K.abs(y), K.epsilon(), np.inf)), axis=-1)\n",
    "\n",
    "mape_scorer = make_scorer(mape, greater_is_better=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%sql --module q_all\n",
    "\n",
    "SELECT *, HASH(CAST(district_id AS STRING) +timeslot) AS hash_value,\n",
    "  IF(ABS(HASH(CAST(district_id AS STRING) + timeslot)) % 2 == 1, 'True', 'False')\n",
    "    AS included_in_sample, IF(timeofday_slot >= 50 AND timeofday_slot <= 53, 1, 0) AS busy_time\n",
    "FROM [datalab-projects-1331:xjk_algo_comp.gaps]\n",
    "WHERE gap > 0\n",
    "LIMIT 5000\n",
    "\n",
    "# The above query randomizes its outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 1000 rows\n",
      "processed 0 rows\n"
     ]
    }
   ],
   "source": [
    "query = bq.Query(q_all)\n",
    "tableresult = query.results()\n",
    "\n",
    "all_data = np.zeros((tableresult.length, len(fields)))\n",
    "print 'there are {} rows'.format(tableresult.length)\n",
    "for rcounter, row in enumerate(tableresult):\n",
    "  for fcounter, field in enumerate(fields):\n",
    "    all_data[rcounter, fcounter] = row[field]\n",
    "  if rcounter % 5000 == 0:\n",
    "    print 'processed {} rows'.format(rcounter)\n",
    "all_data_original = np.copy(all_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_values_:\n",
      "[ 7 10 10 10]\n",
      "feature_indices_:\n",
      "[ 0  7 17 27 37]\n",
      "new number of features: 196\n"
     ]
    }
   ],
   "source": [
    "one_hot = OneHotEncoder(categorical_features=[1, 2, 3, 4], sparse=False,\n",
    "                        n_values=[7, 10, 10, 10])\n",
    "one_hot.fit(Imputer().fit_transform(all_data_original))\n",
    "print \"n_values_:\"\n",
    "print one_hot.n_values_\n",
    "print \"feature_indices_:\"\n",
    "print one_hot.feature_indices_\n",
    "all_data = StandardScaler().fit_transform(one_hot.fit_transform(Imputer().fit_transform(\n",
    "      all_data_original)))\n",
    "n_features = all_data.shape[1] - 1\n",
    "print 'new number of features: {}'.format(n_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Split the data into train and test sets.\n",
    "data_size = all_data.shape[0]\n",
    "training_size = data_size * 80/100\n",
    "indices = np.random.permutation(data_size)\n",
    "training_idx, test_idx = indices[:training_size], indices[training_size:]\n",
    "all_data_train, all_data_test = all_data_original[training_idx,:], all_data_original[test_idx,:]\n",
    "\n",
    "data_train = all_data_train[:,1:]\n",
    "targets_train = all_data_train[:,0]\n",
    "data_test = all_data_test[:,1:]\n",
    "targets_test = all_data_test[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished fold with 1 / 196 feature ranks, score=-0.049055\n",
      "Finished fold with 2 / 196 feature ranks, score=-0.027650\n",
      "Finished fold with 3 / 196 feature ranks, score=-0.026438\n",
      "Finished fold with 4 / 196 feature ranks, score=-0.028867\n",
      "Finished fold with 5 / 196 feature ranks, score=-0.027727\n",
      "Finished fold with 6 / 196 feature ranks, score=-0.028258\n",
      "Finished fold with 7 / 196 feature ranks, score=-0.028624\n",
      "Finished fold with 8 / 196 feature ranks, score=-0.030387\n",
      "Finished fold with 9 / 196 feature ranks, score=-0.031699\n",
      "Finished fold with 10 / 196 feature ranks, score=-0.033777\n",
      "Finished fold with 11 / 196 feature ranks, score=-0.033637\n",
      "Finished fold with 12 / 196 feature ranks, score=-0.034078\n",
      "Finished fold with 13 / 196 feature ranks, score=-0.033224\n",
      "Finished fold with 14 / 196 feature ranks, score=-0.032425\n",
      "Finished fold with 15 / 196 feature ranks, score=-0.036007\n",
      "Finished fold with 16 / 196 feature ranks, score=-0.036468\n",
      "Finished fold with 17 / 196 feature ranks, score=-0.037544\n",
      "Finished fold with 18 / 196 feature ranks, score=-0.037573\n",
      "Finished fold with 19 / 196 feature ranks, score=-0.037669\n",
      "Finished fold with 20 / 196 feature ranks, score=-0.037744\n",
      "Finished fold with 21 / 196 feature ranks, score=-0.037928\n",
      "Finished fold with 22 / 196 feature ranks, score=-0.038683\n",
      "Finished fold with 23 / 196 feature ranks, score=-0.038952\n",
      "Finished fold with 24 / 196 feature ranks, score=-0.039186\n",
      "Finished fold with 25 / 196 feature ranks, score=-0.039426\n",
      "Finished fold with 26 / 196 feature ranks, score=-0.039062\n",
      "Finished fold with 27 / 196 feature ranks, score=-0.039400\n",
      "Finished fold with 28 / 196 feature ranks, score=-0.039754\n",
      "Finished fold with 29 / 196 feature ranks, score=-0.039881\n",
      "Finished fold with 30 / 196 feature ranks, score=-0.039453\n",
      "Finished fold with 31 / 196 feature ranks, score=-0.039337\n",
      "Finished fold with 32 / 196 feature ranks, score=-0.040552\n",
      "Finished fold with 33 / 196 feature ranks, score=-0.040679\n",
      "Finished fold with 34 / 196 feature ranks, score=-0.040939\n",
      "Finished fold with 35 / 196 feature ranks, score=-0.040953\n",
      "Finished fold with 36 / 196 feature ranks, score=-0.042170\n",
      "Finished fold with 37 / 196 feature ranks, score=-0.043550\n",
      "Finished fold with 38 / 196 feature ranks, score=-0.044624\n",
      "Finished fold with 39 / 196 feature ranks, score=-0.045242\n",
      "Finished fold with 40 / 196 feature ranks, score=-0.045297\n",
      "Finished fold with 41 / 196 feature ranks, score=-0.043817\n",
      "Finished fold with 42 / 196 feature ranks, score=-0.044047\n",
      "Finished fold with 43 / 196 feature ranks, score=-0.043796\n",
      "Finished fold with 44 / 196 feature ranks, score=-0.044300\n",
      "Finished fold with 45 / 196 feature ranks, score=-0.044283\n",
      "Finished fold with 46 / 196 feature ranks, score=-0.044747\n",
      "Finished fold with 47 / 196 feature ranks, score=-0.044352\n",
      "Finished fold with 48 / 196 feature ranks, score=-0.044308\n",
      "Finished fold with 49 / 196 feature ranks, score=-0.045765\n",
      "Finished fold with 50 / 196 feature ranks, score=-0.045251\n",
      "Finished fold with 51 / 196 feature ranks, score=-0.045178\n",
      "Finished fold with 52 / 196 feature ranks, score=-0.044995\n",
      "Finished fold with 53 / 196 feature ranks, score=-0.044977\n",
      "Finished fold with 54 / 196 feature ranks, score=-0.043892\n",
      "Finished fold with 55 / 196 feature ranks, score=-0.043458\n",
      "Finished fold with 56 / 196 feature ranks, score=-0.043614\n",
      "Finished fold with 57 / 196 feature ranks, score=-0.043585\n",
      "Finished fold with 58 / 196 feature ranks, score=-0.044274\n",
      "Finished fold with 59 / 196 feature ranks, score=-0.044268\n",
      "Finished fold with 60 / 196 feature ranks, score=-0.044462\n",
      "Finished fold with 61 / 196 feature ranks, score=-0.044279\n",
      "Finished fold with 62 / 196 feature ranks, score=-0.044212\n",
      "Finished fold with 63 / 196 feature ranks, score=-0.044090\n",
      "Finished fold with 64 / 196 feature ranks, score=-0.044044\n",
      "Finished fold with 65 / 196 feature ranks, score=-0.045180\n",
      "Finished fold with 66 / 196 feature ranks, score=-0.045163\n",
      "Finished fold with 67 / 196 feature ranks, score=-0.045129\n",
      "Finished fold with 68 / 196 feature ranks, score=-0.045080\n",
      "Finished fold with 69 / 196 feature ranks, score=-0.045116\n",
      "Finished fold with 70 / 196 feature ranks, score=-0.045083\n",
      "Finished fold with 71 / 196 feature ranks, score=-0.045088\n",
      "Finished fold with 72 / 196 feature ranks, score=-0.045264\n",
      "Finished fold with 73 / 196 feature ranks, score=-0.045761\n",
      "Finished fold with 74 / 196 feature ranks, score=-0.045665\n",
      "Finished fold with 75 / 196 feature ranks, score=-0.045702\n",
      "Finished fold with 76 / 196 feature ranks, score=-0.045785\n",
      "Finished fold with 77 / 196 feature ranks, score=-0.045431\n",
      "Finished fold with 78 / 196 feature ranks, score=-0.045306\n",
      "Finished fold with 79 / 196 feature ranks, score=-0.045237\n",
      "Finished fold with 80 / 196 feature ranks, score=-0.044921\n",
      "Finished fold with 81 / 196 feature ranks, score=-0.045058\n",
      "Finished fold with 82 / 196 feature ranks, score=-0.045107\n",
      "Finished fold with 83 / 196 feature ranks, score=-0.045474\n",
      "Finished fold with 84 / 196 feature ranks, score=-0.045536\n",
      "Finished fold with 85 / 196 feature ranks, score=-0.045616\n",
      "Finished fold with 86 / 196 feature ranks, score=-0.045584\n",
      "Finished fold with 87 / 196 feature ranks, score=-0.045580\n",
      "Finished fold with 88 / 196 feature ranks, score=-0.045590\n",
      "Finished fold with 89 / 196 feature ranks, score=-0.045623\n",
      "Finished fold with 90 / 196 feature ranks, score=-0.045631\n",
      "Finished fold with 91 / 196 feature ranks, score=-0.045571\n",
      "Finished fold with 92 / 196 feature ranks, score=-0.045576\n",
      "Finished fold with 93 / 196 feature ranks, score=-0.045634\n",
      "Finished fold with 94 / 196 feature ranks, score=-0.045581\n",
      "Finished fold with 95 / 196 feature ranks, score=-0.045727\n",
      "Finished fold with 96 / 196 feature ranks, score=-0.045677\n",
      "Finished fold with 97 / 196 feature ranks, score=-0.045605\n",
      "Finished fold with 98 / 196 feature ranks, score=-0.045646\n",
      "Finished fold with 99 / 196 feature ranks, score=-0.045756\n",
      "Finished fold with 100 / 196 feature ranks, score=-0.045450\n",
      "Finished fold with 101 / 196 feature ranks, score=-0.045446\n",
      "Finished fold with 102 / 196 feature ranks, score=-0.045442\n",
      "Finished fold with 103 / 196 feature ranks, score=-0.045463\n",
      "Finished fold with 104 / 196 feature ranks, score=-0.045436\n",
      "Finished fold with 105 / 196 feature ranks, score=-0.045454\n",
      "Finished fold with 106 / 196 feature ranks, score=-0.045427\n",
      "Finished fold with 107 / 196 feature ranks, score=-0.045416\n",
      "Finished fold with 108 / 196 feature ranks, score=-0.045264\n",
      "Finished fold with 109 / 196 feature ranks, score=-0.045328\n",
      "Finished fold with 110 / 196 feature ranks, score=-0.045407\n",
      "Finished fold with 111 / 196 feature ranks, score=-0.045446\n",
      "Finished fold with 112 / 196 feature ranks, score=-0.045440\n",
      "Finished fold with 113 / 196 feature ranks, score=-0.045779\n",
      "Finished fold with 114 / 196 feature ranks, score=-0.045814\n",
      "Finished fold with 115 / 196 feature ranks, score=-0.045812\n",
      "Finished fold with 116 / 196 feature ranks, score=-0.045852\n",
      "Finished fold with 117 / 196 feature ranks, score=-0.045839\n",
      "Finished fold with 118 / 196 feature ranks, score=-0.045788\n",
      "Finished fold with 119 / 196 feature ranks, score=-0.045895\n",
      "Finished fold with 120 / 196 feature ranks, score=-0.045976\n",
      "Finished fold with 121 / 196 feature ranks, score=-0.046109\n",
      "Finished fold with 122 / 196 feature ranks, score=-0.045895\n",
      "Finished fold with 123 / 196 feature ranks, score=-0.045846\n",
      "Finished fold with 124 / 196 feature ranks, score=-0.045921\n",
      "Finished fold with 125 / 196 feature ranks, score=-0.045770\n",
      "Finished fold with 126 / 196 feature ranks, score=-0.045725\n",
      "Finished fold with 127 / 196 feature ranks, score=-0.045767\n",
      "Finished fold with 128 / 196 feature ranks, score=-0.045774\n",
      "Finished fold with 129 / 196 feature ranks, score=-0.045697\n",
      "Finished fold with 130 / 196 feature ranks, score=-0.045779\n",
      "Finished fold with 131 / 196 feature ranks, score=-0.045753\n",
      "Finished fold with 132 / 196 feature ranks, score=-0.045803\n",
      "Finished fold with 133 / 196 feature ranks, score=-0.046833\n",
      "Finished fold with 134 / 196 feature ranks, score=-0.047091\n",
      "Finished fold with 135 / 196 feature ranks, score=-0.046996\n",
      "Finished fold with 136 / 196 feature ranks, score=-0.046986\n",
      "Finished fold with 137 / 196 feature ranks, score=-0.046993\n",
      "Finished fold with 138 / 196 feature ranks, score=-0.046887\n",
      "Finished fold with 139 / 196 feature ranks, score=-0.046907\n",
      "Finished fold with 140 / 196 feature ranks, score=-0.047107\n",
      "Finished fold with 141 / 196 feature ranks, score=-0.046977\n",
      "Finished fold with 142 / 196 feature ranks, score=-0.047066\n",
      "Finished fold with 143 / 196 feature ranks, score=-0.046920\n",
      "Finished fold with 144 / 196 feature ranks, score=-0.046917\n",
      "Finished fold with 145 / 196 feature ranks, score=-0.046869\n",
      "Finished fold with 146 / 196 feature ranks, score=-0.046853\n",
      "Finished fold with 147 / 196 feature ranks, score=-0.046896\n",
      "Finished fold with 148 / 196 feature ranks, score=-0.046851\n",
      "Finished fold with 149 / 196 feature ranks, score=-0.046901\n",
      "Finished fold with 150 / 196 feature ranks, score=-0.046206\n",
      "Finished fold with 151 / 196 feature ranks, score=-0.046386\n",
      "Finished fold with 152 / 196 feature ranks, score=-0.046325\n",
      "Finished fold with 153 / 196 feature ranks, score=-0.046311\n",
      "Finished fold with 154 / 196 feature ranks, score=-0.046340\n",
      "Finished fold with 155 / 196 feature ranks, score=-0.046265\n",
      "Finished fold with 156 / 196 feature ranks, score=-0.046167\n",
      "Finished fold with 157 / 196 feature ranks, score=-0.046298\n",
      "Finished fold with 158 / 196 feature ranks, score=-0.046752\n",
      "Finished fold with 159 / 196 feature ranks, score=-0.046729\n",
      "Finished fold with 160 / 196 feature ranks, score=-0.046712\n",
      "Finished fold with 161 / 196 feature ranks, score=-0.046740\n",
      "Finished fold with 162 / 196 feature ranks, score=-0.046710\n",
      "Finished fold with 163 / 196 feature ranks, score=-0.046703\n",
      "Finished fold with 164 / 196 feature ranks, score=-0.046703\n",
      "Finished fold with 165 / 196 feature ranks, score=-0.046682\n",
      "Finished fold with 166 / 196 feature ranks, score=-0.046682\n",
      "Finished fold with 167 / 196 feature ranks, score=-0.046682\n",
      "Finished fold with 168 / 196 feature ranks, score=-0.046682\n",
      "Finished fold with 169 / 196 feature ranks, score=-0.046682\n",
      "Finished fold with 170 / 196 feature ranks, score=-0.046682\n",
      "Finished fold with 171 / 196 feature ranks, score=-0.046682\n",
      "Finished fold with 172 / 196 feature ranks, score=-0.046682\n",
      "Finished fold with 173 / 196 feature ranks, score=-0.046682\n",
      "Finished fold with 174 / 196 feature ranks, score=-0.046682\n",
      "Finished fold with 175 / 196 feature ranks, score=-0.046682\n",
      "Finished fold with 176 / 196 feature ranks, score=-0.046682\n",
      "Finished fold with 177 / 196 feature ranks, score=-0.046682\n",
      "Finished fold with 178 / 196 feature ranks, score=-0.046682\n",
      "Finished fold with 179 / 196 feature ranks, score=-0.046682\n",
      "Finished fold with 180 / 196 feature ranks, score=-0.046682\n",
      "Finished fold with 181 / 196 feature ranks, score=-0.046682\n",
      "Finished fold with 182 / 196 feature ranks, score=-0.046682\n",
      "Finished fold with 183 / 196 feature ranks, score=-0.046682\n",
      "Finished fold with 184 / 196 feature ranks, score=-0.046682\n",
      "Finished fold with 185 / 196 feature ranks, score=-0.046682\n",
      "Finished fold with 186 / 196 feature ranks, score=-0.046682\n",
      "Finished fold with 187 / 196 feature ranks, score=-0.046682\n",
      "Finished fold with 188 / 196 feature ranks, score=-0.046682\n",
      "Finished fold with 189 / 196 feature ranks, score=-0.046682\n",
      "Finished fold with 190 / 196 feature ranks, score=-0.046682\n",
      "Finished fold with 191 / 196 feature ranks, score=-0.046682\n",
      "Finished fold with 192 / 196 feature ranks, score=-0.046682\n",
      "Finished fold with 193 / 196 feature ranks, score=-0.046682\n",
      "Finished fold with 194 / 196 feature ranks, score=-0.046682\n",
      "Finished fold with 195 / 196 feature ranks, score=-0.046682\n",
      "Finished fold with 196 / 196 feature ranks, score=-0.046682\n",
      "Finished fold with 1 / 196 feature ranks, score=-0.043530\n",
      "Finished fold with 2 / 196 feature ranks, score=-0.037770\n",
      "Finished fold with 3 / 196 feature ranks, score=-0.039811\n",
      "Finished fold with 4 / 196 feature ranks, score=-0.057599\n",
      "Finished fold with 5 / 196 feature ranks, score=-0.059952\n",
      "Finished fold with 6 / 196 feature ranks, score=-0.059897\n",
      "Finished fold with 7 / 196 feature ranks, score=-0.060694\n",
      "Finished fold with 8 / 196 feature ranks, score=-0.060420\n",
      "Finished fold with 9 / 196 feature ranks, score=-0.060140\n",
      "Finished fold with 10 / 196 feature ranks, score=-0.059635\n",
      "Finished fold with 11 / 196 feature ranks, score=-0.062424\n",
      "Finished fold with 12 / 196 feature ranks, score=-0.061462\n",
      "Finished fold with 13 / 196 feature ranks, score=-0.063102\n",
      "Finished fold with 14 / 196 feature ranks, score=-0.067599\n",
      "Finished fold with 15 / 196 feature ranks, score=-0.068004\n",
      "Finished fold with 16 / 196 feature ranks, score=-0.069409\n",
      "Finished fold with 17 / 196 feature ranks, score=-0.070253\n",
      "Finished fold with 18 / 196 feature ranks, score=-0.072388\n",
      "Finished fold with 19 / 196 feature ranks, score=-0.072289\n",
      "Finished fold with 20 / 196 feature ranks, score=-0.074728\n",
      "Finished fold with 21 / 196 feature ranks, score=-0.074222\n",
      "Finished fold with 22 / 196 feature ranks, score=-0.073066\n",
      "Finished fold with 23 / 196 feature ranks, score=-0.074931\n",
      "Finished fold with 24 / 196 feature ranks, score=-0.075381\n",
      "Finished fold with 25 / 196 feature ranks, score=-0.075502\n",
      "Finished fold with 26 / 196 feature ranks, score=-0.075395\n",
      "Finished fold with 27 / 196 feature ranks, score=-0.075924\n",
      "Finished fold with 28 / 196 feature ranks, score=-0.076482\n",
      "Finished fold with 29 / 196 feature ranks, score=-0.077376\n",
      "Finished fold with 30 / 196 feature ranks, score=-0.077159\n",
      "Finished fold with 31 / 196 feature ranks, score=-0.079148\n",
      "Finished fold with 32 / 196 feature ranks, score=-0.079662\n",
      "Finished fold with 33 / 196 feature ranks, score=-0.078321\n",
      "Finished fold with 34 / 196 feature ranks, score=-0.078697\n",
      "Finished fold with 35 / 196 feature ranks, score=-0.077884\n",
      "Finished fold with 36 / 196 feature ranks, score=-0.080241\n",
      "Finished fold with 37 / 196 feature ranks, score=-0.079969\n",
      "Finished fold with 38 / 196 feature ranks, score=-0.080519\n",
      "Finished fold with 39 / 196 feature ranks, score=-0.079962\n",
      "Finished fold with 40 / 196 feature ranks, score=-0.079985\n",
      "Finished fold with 41 / 196 feature ranks, score=-0.080246\n",
      "Finished fold with 42 / 196 feature ranks, score=-0.080079\n",
      "Finished fold with 43 / 196 feature ranks, score=-0.080150\n",
      "Finished fold with 44 / 196 feature ranks, score=-0.080552\n",
      "Finished fold with 45 / 196 feature ranks, score=-0.079942\n",
      "Finished fold with 46 / 196 feature ranks, score=-0.079885\n",
      "Finished fold with 47 / 196 feature ranks, score=-0.079672\n",
      "Finished fold with 48 / 196 feature ranks, score=-0.080128\n",
      "Finished fold with 49 / 196 feature ranks, score=-0.079928\n",
      "Finished fold with 50 / 196 feature ranks, score=-0.079758\n",
      "Finished fold with 51 / 196 feature ranks, score=-0.079864\n",
      "Finished fold with 52 / 196 feature ranks, score=-0.079962\n",
      "Finished fold with 53 / 196 feature ranks, score=-0.079619\n",
      "Finished fold with 54 / 196 feature ranks, score=-0.080115\n",
      "Finished fold with 55 / 196 feature ranks, score=-0.078993\n",
      "Finished fold with 56 / 196 feature ranks, score=-0.079710\n",
      "Finished fold with 57 / 196 feature ranks, score=-0.080002\n",
      "Finished fold with 58 / 196 feature ranks, score=-0.080693\n",
      "Finished fold with 59 / 196 feature ranks, score=-0.080541\n",
      "Finished fold with 60 / 196 feature ranks, score=-0.080912\n",
      "Finished fold with 61 / 196 feature ranks, score=-0.083046\n",
      "Finished fold with 62 / 196 feature ranks, score=-0.082825\n",
      "Finished fold with 63 / 196 feature ranks, score=-0.083230\n",
      "Finished fold with 64 / 196 feature ranks, score=-0.083290\n",
      "Finished fold with 65 / 196 feature ranks, score=-0.083262\n",
      "Finished fold with 66 / 196 feature ranks, score=-0.083342\n",
      "Finished fold with 67 / 196 feature ranks, score=-0.083287\n",
      "Finished fold with 68 / 196 feature ranks, score=-0.083135\n",
      "Finished fold with 69 / 196 feature ranks, score=-0.083180\n",
      "Finished fold with 70 / 196 feature ranks, score=-0.083166\n",
      "Finished fold with 71 / 196 feature ranks, score=-0.082933\n",
      "Finished fold with 72 / 196 feature ranks, score=-0.082971\n",
      "Finished fold with 73 / 196 feature ranks, score=-0.082911\n",
      "Finished fold with 74 / 196 feature ranks, score=-0.085717\n",
      "Finished fold with 75 / 196 feature ranks, score=-0.085447\n",
      "Finished fold with 76 / 196 feature ranks, score=-0.085345\n",
      "Finished fold with 77 / 196 feature ranks, score=-0.085390\n",
      "Finished fold with 78 / 196 feature ranks, score=-0.085380\n",
      "Finished fold with 79 / 196 feature ranks, score=-0.085487\n",
      "Finished fold with 80 / 196 feature ranks, score=-0.085442\n",
      "Finished fold with 81 / 196 feature ranks, score=-0.085892\n",
      "Finished fold with 82 / 196 feature ranks, score=-0.085902\n",
      "Finished fold with 83 / 196 feature ranks, score=-0.085788\n",
      "Finished fold with 84 / 196 feature ranks, score=-0.085548\n",
      "Finished fold with 85 / 196 feature ranks, score=-0.085497\n",
      "Finished fold with 86 / 196 feature ranks, score=-0.085472\n",
      "Finished fold with 87 / 196 feature ranks, score=-0.085357\n",
      "Finished fold with 88 / 196 feature ranks, score=-0.085397\n",
      "Finished fold with 89 / 196 feature ranks, score=-0.085968\n",
      "Finished fold with 90 / 196 feature ranks, score=-0.085967\n",
      "Finished fold with 91 / 196 feature ranks, score=-0.086340\n",
      "Finished fold with 92 / 196 feature ranks, score=-0.086269\n",
      "Finished fold with 93 / 196 feature ranks, score=-0.086348\n",
      "Finished fold with 94 / 196 feature ranks, score=-0.086360\n",
      "Finished fold with 95 / 196 feature ranks, score=-0.086331\n",
      "Finished fold with 96 / 196 feature ranks, score=-0.086328\n",
      "Finished fold with 97 / 196 feature ranks, score=-0.086304\n",
      "Finished fold with 98 / 196 feature ranks, score=-0.086174\n",
      "Finished fold with 99 / 196 feature ranks, score=-0.086199\n",
      "Finished fold with 100 / 196 feature ranks, score=-0.086187\n",
      "Finished fold with 101 / 196 feature ranks, score=-0.086305\n",
      "Finished fold with 102 / 196 feature ranks, score=-0.086316\n",
      "Finished fold with 103 / 196 feature ranks, score=-0.086280\n",
      "Finished fold with 104 / 196 feature ranks, score=-0.085419\n",
      "Finished fold with 105 / 196 feature ranks, score=-0.085567\n",
      "Finished fold with 106 / 196 feature ranks, score=-0.085454\n",
      "Finished fold with 107 / 196 feature ranks, score=-0.085389\n",
      "Finished fold with 108 / 196 feature ranks, score=-0.085587\n",
      "Finished fold with 109 / 196 feature ranks, score=-0.085547\n",
      "Finished fold with 110 / 196 feature ranks, score=-0.085545\n",
      "Finished fold with 111 / 196 feature ranks, score=-0.085582\n",
      "Finished fold with 112 / 196 feature ranks, score=-0.085507\n",
      "Finished fold with 113 / 196 feature ranks, score=-0.086544\n",
      "Finished fold with 114 / 196 feature ranks, score=-0.086529\n",
      "Finished fold with 115 / 196 feature ranks, score=-0.086755\n",
      "Finished fold with 116 / 196 feature ranks, score=-0.086813\n",
      "Finished fold with 117 / 196 feature ranks, score=-0.086836\n",
      "Finished fold with 118 / 196 feature ranks, score=-0.086862\n",
      "Finished fold with 119 / 196 feature ranks, score=-0.086828\n",
      "Finished fold with 120 / 196 feature ranks, score=-0.086889\n",
      "Finished fold with 121 / 196 feature ranks, score=-0.086923\n",
      "Finished fold with 122 / 196 feature ranks, score=-0.086664\n",
      "Finished fold with 123 / 196 feature ranks, score=-0.086550\n",
      "Finished fold with 124 / 196 feature ranks, score=-0.086568\n",
      "Finished fold with 125 / 196 feature ranks, score=-0.086591\n",
      "Finished fold with 126 / 196 feature ranks, score=-0.086627\n",
      "Finished fold with 127 / 196 feature ranks, score=-0.086556\n",
      "Finished fold with 128 / 196 feature ranks, score=-0.086771\n",
      "Finished fold with 129 / 196 feature ranks, score=-0.085988\n",
      "Finished fold with 130 / 196 feature ranks, score=-0.085949\n",
      "Finished fold with 131 / 196 feature ranks, score=-0.086004\n",
      "Finished fold with 132 / 196 feature ranks, score=-0.089538\n",
      "Finished fold with 133 / 196 feature ranks, score=-0.089563\n",
      "Finished fold with 134 / 196 feature ranks, score=-0.089513\n",
      "Finished fold with 135 / 196 feature ranks, score=-0.089496\n",
      "Finished fold with 136 / 196 feature ranks, score=-0.089502\n",
      "Finished fold with 137 / 196 feature ranks, score=-0.089514\n",
      "Finished fold with 138 / 196 feature ranks, score=-0.089536\n",
      "Finished fold with 139 / 196 feature ranks, score=-0.089500\n",
      "Finished fold with 140 / 196 feature ranks, score=-0.089508\n",
      "Finished fold with 141 / 196 feature ranks, score=-0.089592\n",
      "Finished fold with 142 / 196 feature ranks, score=-0.089589\n",
      "Finished fold with 143 / 196 feature ranks, score=-0.089613\n",
      "Finished fold with 144 / 196 feature ranks, score=-0.089585\n",
      "Finished fold with 145 / 196 feature ranks, score=-0.089565\n",
      "Finished fold with 146 / 196 feature ranks, score=-0.089548\n",
      "Finished fold with 147 / 196 feature ranks, score=-0.089751\n",
      "Finished fold with 148 / 196 feature ranks, score=-0.089599\n",
      "Finished fold with 149 / 196 feature ranks, score=-0.089638\n",
      "Finished fold with 150 / 196 feature ranks, score=-0.089513\n",
      "Finished fold with 151 / 196 feature ranks, score=-0.089706\n",
      "Finished fold with 152 / 196 feature ranks, score=-0.089720\n",
      "Finished fold with 153 / 196 feature ranks, score=-0.089709\n",
      "Finished fold with 154 / 196 feature ranks, score=-0.089695\n",
      "Finished fold with 155 / 196 feature ranks, score=-0.089785\n",
      "Finished fold with 156 / 196 feature ranks, score=-0.089801\n",
      "Finished fold with 157 / 196 feature ranks, score=-0.089719\n",
      "Finished fold with 158 / 196 feature ranks, score=-0.089671\n",
      "Finished fold with 159 / 196 feature ranks, score=-0.089728\n",
      "Finished fold with 160 / 196 feature ranks, score=-0.089730\n",
      "Finished fold with 161 / 196 feature ranks, score=-0.089702\n",
      "Finished fold with 162 / 196 feature ranks, score=-0.089726\n",
      "Finished fold with 163 / 196 feature ranks, score=-0.089698\n",
      "Finished fold with 164 / 196 feature ranks, score=-0.089747\n",
      "Finished fold with 165 / 196 feature ranks, score=-0.089760\n",
      "Finished fold with 166 / 196 feature ranks, score=-0.089760\n",
      "Finished fold with 167 / 196 feature ranks, score=-0.089760\n",
      "Finished fold with 168 / 196 feature ranks, score=-0.089760\n",
      "Finished fold with 169 / 196 feature ranks, score=-0.089760\n",
      "Finished fold with 170 / 196 feature ranks, score=-0.089760\n",
      "Finished fold with 171 / 196 feature ranks, score=-0.089760\n",
      "Finished fold with 172 / 196 feature ranks, score=-0.089760\n",
      "Finished fold with 173 / 196 feature ranks, score=-0.089760\n",
      "Finished fold with 174 / 196 feature ranks, score=-0.089760\n",
      "Finished fold with 175 / 196 feature ranks, score=-0.089760\n",
      "Finished fold with 176 / 196 feature ranks, score=-0.089760\n",
      "Finished fold with 177 / 196 feature ranks, score=-0.089760\n",
      "Finished fold with 178 / 196 feature ranks, score=-0.089760\n",
      "Finished fold with 179 / 196 feature ranks, score=-0.089760\n",
      "Finished fold with 180 / 196 feature ranks, score=-0.089760\n",
      "Finished fold with 181 / 196 feature ranks, score=-0.089760\n",
      "Finished fold with 182 / 196 feature ranks, score=-0.089760\n",
      "Finished fold with 183 / 196 feature ranks, score=-0.089760\n",
      "Finished fold with 184 / 196 feature ranks, score=-0.089760\n",
      "Finished fold with 185 / 196 feature ranks, score=-0.089760\n",
      "Finished fold with 186 / 196 feature ranks, score=-0.089760\n",
      "Finished fold with 187 / 196 feature ranks, score=-0.089760\n",
      "Finished fold with 188 / 196 feature ranks, score=-0.089760\n",
      "Finished fold with 189 / 196 feature ranks, score=-0.089760\n",
      "Finished fold with 190 / 196 feature ranks, score=-0.089760\n",
      "Finished fold with 191 / 196 feature ranks, score=-0.089760\n",
      "Finished fold with 192 / 196 feature ranks, score=-0.089760\n",
      "Finished fold with 193 / 196 feature ranks, score=-0.089760\n",
      "Finished fold with 194 / 196 feature ranks, score=-0.089760\n",
      "Finished fold with 195 / 196 feature ranks, score=-0.089760\n",
      "Finished fold with 196 / 196 feature ranks, score=-0.089760\n",
      "Finished fold with 1 / 196 feature ranks, score=-0.047746\n",
      "Finished fold with 2 / 196 feature ranks, score=-0.073732\n",
      "Finished fold with 3 / 196 feature ranks, score=-0.079165\n",
      "Finished fold with 4 / 196 feature ranks, score=-0.081620\n",
      "Finished fold with 5 / 196 feature ranks, score=-0.086130\n",
      "Finished fold with 6 / 196 feature ranks, score=-0.090074\n",
      "Finished fold with 7 / 196 feature ranks, score=-0.089310\n",
      "Finished fold with 8 / 196 feature ranks, score=-0.088683\n",
      "Finished fold with 9 / 196 feature ranks, score=-0.092349\n",
      "Finished fold with 10 / 196 feature ranks, score=-0.091470\n",
      "Finished fold with 11 / 196 feature ranks, score=-0.093695\n",
      "Finished fold with 12 / 196 feature ranks, score=-0.096875\n",
      "Finished fold with 13 / 196 feature ranks, score=-0.100481\n",
      "Finished fold with 14 / 196 feature ranks, score=-0.100850\n",
      "Finished fold with 15 / 196 feature ranks, score=-0.102026\n",
      "Finished fold with 16 / 196 feature ranks, score=-0.102738\n",
      "Finished fold with 17 / 196 feature ranks, score=-0.104817\n",
      "Finished fold with 18 / 196 feature ranks, score=-0.103865\n",
      "Finished fold with 19 / 196 feature ranks, score=-0.104748\n",
      "Finished fold with 20 / 196 feature ranks, score=-0.104329\n",
      "Finished fold with 21 / 196 feature ranks, score=-0.104141\n",
      "Finished fold with 22 / 196 feature ranks, score=-0.103064\n",
      "Finished fold with 23 / 196 feature ranks, score=-0.103053\n",
      "Finished fold with 24 / 196 feature ranks, score=-0.102860\n",
      "Finished fold with 25 / 196 feature ranks, score=-0.103333\n",
      "Finished fold with 26 / 196 feature ranks, score=-0.103612\n",
      "Finished fold with 27 / 196 feature ranks, score=-0.103377\n",
      "Finished fold with 28 / 196 feature ranks, score=-0.103451\n",
      "Finished fold with 29 / 196 feature ranks, score=-0.108476\n",
      "Finished fold with 30 / 196 feature ranks, score=-0.108368\n",
      "Finished fold with 31 / 196 feature ranks, score=-0.109305\n",
      "Finished fold with 32 / 196 feature ranks, score=-0.109612\n",
      "Finished fold with 33 / 196 feature ranks, score=-0.111401\n",
      "Finished fold with 34 / 196 feature ranks, score=-0.111165\n",
      "Finished fold with 35 / 196 feature ranks, score=-0.111100\n",
      "Finished fold with 36 / 196 feature ranks, score=-0.109767\n",
      "Finished fold with 37 / 196 feature ranks, score=-0.110633\n",
      "Finished fold with 38 / 196 feature ranks, score=-0.114093\n",
      "Finished fold with 39 / 196 feature ranks, score=-0.113677\n",
      "Finished fold with 40 / 196 feature ranks, score=-0.113336\n",
      "Finished fold with 41 / 196 feature ranks, score=-0.112544\n",
      "Finished fold with 42 / 196 feature ranks, score=-0.112867\n",
      "Finished fold with 43 / 196 feature ranks, score=-0.117020\n",
      "Finished fold with 44 / 196 feature ranks, score=-0.117863\n",
      "Finished fold with 45 / 196 feature ranks, score=-0.117845\n",
      "Finished fold with 46 / 196 feature ranks, score=-0.119455\n",
      "Finished fold with 47 / 196 feature ranks, score=-0.119017\n",
      "Finished fold with 48 / 196 feature ranks, score=-0.118314\n",
      "Finished fold with 49 / 196 feature ranks, score=-0.116856\n",
      "Finished fold with 50 / 196 feature ranks, score=-0.117896\n",
      "Finished fold with 51 / 196 feature ranks, score=-0.119695\n",
      "Finished fold with 52 / 196 feature ranks, score=-0.119651\n",
      "Finished fold with 53 / 196 feature ranks, score=-0.119735\n",
      "Finished fold with 54 / 196 feature ranks, score=-0.123194\n",
      "Finished fold with 55 / 196 feature ranks, score=-0.122879\n",
      "Finished fold with 56 / 196 feature ranks, score=-0.122084\n",
      "Finished fold with 57 / 196 feature ranks, score=-0.122346\n",
      "Finished fold with 58 / 196 feature ranks, score=-0.122362\n",
      "Finished fold with 59 / 196 feature ranks, score=-0.121844\n",
      "Finished fold with 60 / 196 feature ranks, score=-0.122389\n",
      "Finished fold with 61 / 196 feature ranks, score=-0.122041\n",
      "Finished fold with 62 / 196 feature ranks, score=-0.122226\n",
      "Finished fold with 63 / 196 feature ranks, score=-0.125214\n",
      "Finished fold with 64 / 196 feature ranks, score=-0.125699\n",
      "Finished fold with 65 / 196 feature ranks, score=-0.125624\n",
      "Finished fold with 66 / 196 feature ranks, score=-0.125795\n",
      "Finished fold with 67 / 196 feature ranks, score=-0.125524\n",
      "Finished fold with 68 / 196 feature ranks, score=-0.125484\n",
      "Finished fold with 69 / 196 feature ranks, score=-0.125778\n",
      "Finished fold with 70 / 196 feature ranks, score=-0.125554\n",
      "Finished fold with 71 / 196 feature ranks, score=-0.125591\n",
      "Finished fold with 72 / 196 feature ranks, score=-0.125615\n",
      "Finished fold with 73 / 196 feature ranks, score=-0.125436\n",
      "Finished fold with 74 / 196 feature ranks, score=-0.125141\n",
      "Finished fold with 75 / 196 feature ranks, score=-0.125142\n",
      "Finished fold with 76 / 196 feature ranks, score=-0.125015\n",
      "Finished fold with 77 / 196 feature ranks, score=-0.124813\n",
      "Finished fold with 78 / 196 feature ranks, score=-0.124810\n",
      "Finished fold with 79 / 196 feature ranks, score=-0.124782\n",
      "Finished fold with 80 / 196 feature ranks, score=-0.124664\n",
      "Finished fold with 81 / 196 feature ranks, score=-0.124760\n",
      "Finished fold with 82 / 196 feature ranks, score=-0.124653\n",
      "Finished fold with 83 / 196 feature ranks, score=-0.125598\n",
      "Finished fold with 84 / 196 feature ranks, score=-0.125760\n",
      "Finished fold with 85 / 196 feature ranks, score=-0.125845\n",
      "Finished fold with 86 / 196 feature ranks, score=-0.125818\n",
      "Finished fold with 87 / 196 feature ranks, score=-0.125797\n",
      "Finished fold with 88 / 196 feature ranks, score=-0.125815\n",
      "Finished fold with 89 / 196 feature ranks, score=-0.126063\n",
      "Finished fold with 90 / 196 feature ranks, score=-0.126002\n",
      "Finished fold with 91 / 196 feature ranks, score=-0.125885\n",
      "Finished fold with 92 / 196 feature ranks, score=-0.125926\n",
      "Finished fold with 93 / 196 feature ranks, score=-0.125801\n",
      "Finished fold with 94 / 196 feature ranks, score=-0.125792\n",
      "Finished fold with 95 / 196 feature ranks, score=-0.125858\n",
      "Finished fold with 96 / 196 feature ranks, score=-0.125870\n",
      "Finished fold with 97 / 196 feature ranks, score=-0.125876\n",
      "Finished fold with 98 / 196 feature ranks, score=-0.125874\n",
      "Finished fold with 99 / 196 feature ranks, score=-0.124347\n",
      "Finished fold with 100 / 196 feature ranks, score=-0.124345\n",
      "Finished fold with 101 / 196 feature ranks, score=-0.124259\n",
      "Finished fold with 102 / 196 feature ranks, score=-0.124348\n",
      "Finished fold with 103 / 196 feature ranks, score=-0.124366\n",
      "Finished fold with 104 / 196 feature ranks, score=-0.124308\n",
      "Finished fold with 105 / 196 feature ranks, score=-0.124309\n",
      "Finished fold with 106 / 196 feature ranks, score=-0.124160\n",
      "Finished fold with 107 / 196 feature ranks, score=-0.124426\n",
      "Finished fold with 108 / 196 feature ranks, score=-0.124286\n",
      "Finished fold with 109 / 196 feature ranks, score=-0.124191\n",
      "Finished fold with 110 / 196 feature ranks, score=-0.124379\n",
      "Finished fold with 111 / 196 feature ranks, score=-0.125142\n",
      "Finished fold with 112 / 196 feature ranks, score=-0.125209\n",
      "Finished fold with 113 / 196 feature ranks, score=-0.125019\n",
      "Finished fold with 114 / 196 feature ranks, score=-0.124956\n",
      "Finished fold with 115 / 196 feature ranks, score=-0.124983\n",
      "Finished fold with 116 / 196 feature ranks, score=-0.124992\n",
      "Finished fold with 117 / 196 feature ranks, score=-0.125056\n",
      "Finished fold with 118 / 196 feature ranks, score=-0.124503\n",
      "Finished fold with 119 / 196 feature ranks, score=-0.124443\n",
      "Finished fold with 120 / 196 feature ranks, score=-0.124510\n",
      "Finished fold with 121 / 196 feature ranks, score=-0.124544\n",
      "Finished fold with 122 / 196 feature ranks, score=-0.124478\n",
      "Finished fold with 123 / 196 feature ranks, score=-0.124115\n",
      "Finished fold with 124 / 196 feature ranks, score=-0.124274\n",
      "Finished fold with 125 / 196 feature ranks, score=-0.124262\n",
      "Finished fold with 126 / 196 feature ranks, score=-0.124263\n",
      "Finished fold with 127 / 196 feature ranks, score=-0.125133\n",
      "Finished fold with 128 / 196 feature ranks, score=-0.125188\n",
      "Finished fold with 129 / 196 feature ranks, score=-0.125180\n",
      "Finished fold with 130 / 196 feature ranks, score=-0.125220\n",
      "Finished fold with 131 / 196 feature ranks, score=-0.125234\n",
      "Finished fold with 132 / 196 feature ranks, score=-0.125263\n",
      "Finished fold with 133 / 196 feature ranks, score=-0.125107\n",
      "Finished fold with 134 / 196 feature ranks, score=-0.125144\n",
      "Finished fold with 135 / 196 feature ranks, score=-0.125091\n",
      "Finished fold with 136 / 196 feature ranks, score=-0.125050\n",
      "Finished fold with 137 / 196 feature ranks, score=-0.124800\n",
      "Finished fold with 138 / 196 feature ranks, score=-0.124785\n",
      "Finished fold with 139 / 196 feature ranks, score=-0.124794\n",
      "Finished fold with 140 / 196 feature ranks, score=-0.124768\n",
      "Finished fold with 141 / 196 feature ranks, score=-0.124767\n",
      "Finished fold with 142 / 196 feature ranks, score=-0.124802\n",
      "Finished fold with 143 / 196 feature ranks, score=-0.124788\n",
      "Finished fold with 144 / 196 feature ranks, score=-0.124767\n",
      "Finished fold with 145 / 196 feature ranks, score=-0.124788\n",
      "Finished fold with 146 / 196 feature ranks, score=-0.125423\n",
      "Finished fold with 147 / 196 feature ranks, score=-0.125432\n",
      "Finished fold with 148 / 196 feature ranks, score=-0.125471\n",
      "Finished fold with 149 / 196 feature ranks, score=-0.125465\n",
      "Finished fold with 150 / 196 feature ranks, score=-0.125508\n",
      "Finished fold with 151 / 196 feature ranks, score=-0.125536\n",
      "Finished fold with 152 / 196 feature ranks, score=-0.125492\n",
      "Finished fold with 153 / 196 feature ranks, score=-0.125463\n",
      "Finished fold with 154 / 196 feature ranks, score=-0.125560\n",
      "Finished fold with 155 / 196 feature ranks, score=-0.125579\n",
      "Finished fold with 156 / 196 feature ranks, score=-0.125559\n",
      "Finished fold with 157 / 196 feature ranks, score=-0.125944\n",
      "Finished fold with 158 / 196 feature ranks, score=-0.126006\n",
      "Finished fold with 159 / 196 feature ranks, score=-0.125976\n",
      "Finished fold with 160 / 196 feature ranks, score=-0.125921\n",
      "Finished fold with 161 / 196 feature ranks, score=-0.125969\n",
      "Finished fold with 162 / 196 feature ranks, score=-0.125950\n",
      "Finished fold with 163 / 196 feature ranks, score=-0.125944\n",
      "Finished fold with 164 / 196 feature ranks, score=-0.126006\n",
      "Finished fold with 165 / 196 feature ranks, score=-0.126008\n",
      "Finished fold with 166 / 196 feature ranks, score=-0.126008\n",
      "Finished fold with 167 / 196 feature ranks, score=-0.126008\n",
      "Finished fold with 168 / 196 feature ranks, score=-0.126008\n",
      "Finished fold with 169 / 196 feature ranks, score=-0.126008\n",
      "Finished fold with 170 / 196 feature ranks, score=-0.126008\n",
      "Finished fold with 171 / 196 feature ranks, score=-0.126008\n",
      "Finished fold with 172 / 196 feature ranks, score=-0.126008\n",
      "Finished fold with 173 / 196 feature ranks, score=-0.126008\n",
      "Finished fold with 174 / 196 feature ranks, score=-0.126008\n",
      "Finished fold with 175 / 196 feature ranks, score=-0.126008\n",
      "Finished fold with 176 / 196 feature ranks, score=-0.126008\n",
      "Finished fold with 177 / 196 feature ranks, score=-0.126008\n",
      "Finished fold with 178 / 196 feature ranks, score=-0.126008\n",
      "Finished fold with 179 / 196 feature ranks, score=-0.126008\n",
      "Finished fold with 180 / 196 feature ranks, score=-0.126008\n",
      "Finished fold with 181 / 196 feature ranks, score=-0.126008\n",
      "Finished fold with 182 / 196 feature ranks, score=-0.126008\n",
      "Finished fold with 183 / 196 feature ranks, score=-0.126008\n",
      "Finished fold with 184 / 196 feature ranks, score=-0.126008\n",
      "Finished fold with 185 / 196 feature ranks, score=-0.126008\n",
      "Finished fold with 186 / 196 feature ranks, score=-0.126008\n",
      "Finished fold with 187 / 196 feature ranks, score=-0.126008\n",
      "Finished fold with 188 / 196 feature ranks, score=-0.126008\n",
      "Finished fold with 189 / 196 feature ranks, score=-0.126008\n",
      "Finished fold with 190 / 196 feature ranks, score=-0.126008\n",
      "Finished fold with 191 / 196 feature ranks, score=-0.126008\n",
      "Finished fold with 192 / 196 feature ranks, score=-0.126008\n",
      "Finished fold with 193 / 196 feature ranks, score=-0.126008\n",
      "Finished fold with 194 / 196 feature ranks, score=-0.126008\n",
      "Finished fold with 195 / 196 feature ranks, score=-0.126008\n",
      "Finished fold with 196 / 196 feature ranks, score=-0.126008\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RFECV(cv=None,\n",
       "   estimator=SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma=0.0,\n",
       "  kernel='linear', max_iter=-1, shrinking=True, tol=0.001, verbose=False),\n",
       "   estimator_params=None,\n",
       "   scoring=make_scorer(mape, greater_is_better=False), step=1, verbose=1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfecv = RFECV(SVR(kernel='linear'), scoring=mape_scorer, verbose=1)\n",
    "rfecv.fit(all_data[training_idx,1:], targets_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal number of features : 2\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhEAAAFmCAYAAADTUcj2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa0b998f1d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Optimal number of features : %d\" % rfecv.n_features_)\n",
    "\n",
    "# Plot number of features VS. cross-validation scores\n",
    "plt.figure()\n",
    "plt.xlabel(\"Number of features selected\")\n",
    "plt.ylabel(\"Cross validation score (nb of correct classifications)\")\n",
    "plt.plot(range(1, len(rfecv.grid_scores_) + 1), rfecv.grid_scores_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.04677718, -0.0463842 , -0.04847145, -0.05602871, -0.05793618,\n",
       "       -0.05940965, -0.0595427 , -0.05983012, -0.06139581, -0.06162718,\n",
       "       -0.0632519 , -0.06413817, -0.06560256, -0.06695819, -0.06867878,\n",
       "       -0.06953843, -0.07087136, -0.07127539, -0.07156835, -0.07226712,\n",
       "       -0.07209719, -0.07160421, -0.0723123 , -0.07247552, -0.07275393,\n",
       "       -0.07268955, -0.07290023, -0.07322926, -0.07524419, -0.07499315,\n",
       "       -0.07592997, -0.07660848, -0.0768    , -0.07693355, -0.07664574,\n",
       "       -0.07739242, -0.07805055, -0.0797456 , -0.07962716, -0.07953964,\n",
       "       -0.07886915, -0.07899783, -0.08032182, -0.0809052 , -0.08068995,\n",
       "       -0.08136233, -0.08101355, -0.08091666, -0.08084969, -0.08096843,\n",
       "       -0.08157906, -0.08153594, -0.0814434 , -0.08240028, -0.08177684,\n",
       "       -0.08180287, -0.08197788, -0.08244309, -0.08221784, -0.08258792,\n",
       "       -0.08312232, -0.0830877 , -0.08417801, -0.08434437, -0.08468859,\n",
       "       -0.0847665 , -0.08464703, -0.08456632, -0.08469146, -0.08460094,\n",
       "       -0.08453735, -0.08461658, -0.08470292, -0.08550774, -0.08543043,\n",
       "       -0.08538143, -0.085211  , -0.08516519, -0.08516855, -0.0850091 ,\n",
       "       -0.08523646, -0.08522083, -0.08561975, -0.08561481, -0.08565244,\n",
       "       -0.0856245 , -0.08557821, -0.08560036, -0.08588481, -0.08586673,\n",
       "       -0.08593205, -0.0859236 , -0.08592749, -0.08591108, -0.08597191,\n",
       "       -0.08595829, -0.08592818, -0.08589804, -0.085434  , -0.0853276 ,\n",
       "       -0.08533657, -0.08536868, -0.08536959, -0.08505463, -0.0851101 ,\n",
       "       -0.08501343, -0.08507668, -0.08504564, -0.08502179, -0.0851104 ,\n",
       "       -0.08539028, -0.08538548, -0.08578059, -0.08576635, -0.08585009,\n",
       "       -0.08588586, -0.08591006, -0.08571777, -0.08572201, -0.08579149,\n",
       "       -0.08585875, -0.08567884, -0.08550361, -0.08558753, -0.08554096,\n",
       "       -0.08553836, -0.08581871, -0.08591098, -0.0856218 , -0.08564961,\n",
       "       -0.08566354, -0.08686795, -0.08716781, -0.08724958, -0.08719433,\n",
       "       -0.08717919, -0.08710233, -0.08706931, -0.08706717, -0.087128  ,\n",
       "       -0.08711206, -0.0871526 , -0.08710708, -0.08708953, -0.08707417,\n",
       "       -0.08727503, -0.08735992, -0.08730699, -0.08733471, -0.0870757 ,\n",
       "       -0.08720953, -0.08717917, -0.08716114, -0.08719835, -0.08720956,\n",
       "       -0.0871756 , -0.08732029, -0.08747618, -0.08747797, -0.08745445,\n",
       "       -0.08747043, -0.08746194, -0.08744829, -0.08748541, -0.08748321,\n",
       "       -0.08748321, -0.08748321, -0.08748321, -0.08748321, -0.08748321,\n",
       "       -0.08748321, -0.08748321, -0.08748321, -0.08748321, -0.08748321,\n",
       "       -0.08748321, -0.08748321, -0.08748321, -0.08748321, -0.08748321,\n",
       "       -0.08748321, -0.08748321, -0.08748321, -0.08748321, -0.08748321,\n",
       "       -0.08748321, -0.08748321, -0.08748321, -0.08748321, -0.08748321,\n",
       "       -0.08748321, -0.08748321, -0.08748321, -0.08748321, -0.08748321,\n",
       "       -0.08748321])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfecv.grid_scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[195 194 193 192 191 190 189 188  72 176  50 175 174 173 170 169 178 177\n",
      "  43 181  24 168 167 165 179 180 172 171  35 182  23 166 183 185 186 187\n",
      "   1 184   4  33  20  29  52  44 113  10   5  19   9  13  77  21  49  91\n",
      " 146  22   1  14   6  15   2   7 160 144 155 114 148 161 125 154 116  17\n",
      "  60  99 153 140  37 136 142  85 137  71 126  83 150  26   3 158  95 124\n",
      "  55 162 110  38 118 138  76  25  74 147  87 127 156 115  63 128 133  79\n",
      "  69  45 151  54 141  59  89 157  16 122  61 132 120 134  30  42 149  82\n",
      "  57 103  64  12  94  58  80 164  27  98 130 104  39 145 117 163  96 129\n",
      "  32 123  66  31  18  67 105  41  86  70  62  34  53  78 135 106 109  46\n",
      " 108 112  90  51  92   8  81  73  28  47  88  97 107  84  40  36 139  48\n",
      " 159  75  93  56 143  68 111 100 119 101  11 102  65 121 152 131]\n",
      "[False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      "  True False False False False False False False False False False False\n",
      " False False False False False False False False  True False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False]\n"
     ]
    }
   ],
   "source": [
    "print rfecv.ranking_\n",
    "print rfecv.get_support()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Initial Bagging Algo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if os.path.isfile(EST_PICKLE_FILENAME1):\n",
    "  bagging_est = pickle.load(open(EST_PICKLE_FILENAME1, 'r'))\n",
    "else:\n",
    "  steps = [\n",
    "    ('impute', Imputer()),\n",
    "    # Remember that gap, the first variable, was removed, thus categorical_features\n",
    "    # should start at index 0.\n",
    "    ('one_hot', OneHotEncoder(categorical_features=[0, 1, 2, 3], sparse=False,\n",
    "                             n_values=[7, 10, 10, 10])),\n",
    "    ('scale', StandardScaler()),\n",
    "    ('estimate', GradientBoostingRegressor(n_estimators=n_features, learning_rate=0.5))\n",
    "\n",
    "  ]\n",
    "\n",
    "  est = Pipeline(steps)\n",
    "\n",
    "  steps_bagging = [\n",
    "    ('impute', Imputer()),\n",
    "    # Remember that gap, the first variable, was removed, thus categorical_features\n",
    "    # should start at index 0.\n",
    "    ('one_hot', OneHotEncoder(categorical_features=[0, 1, 2, 3], sparse=False,\n",
    "                             n_values=[7, 10, 10, 10])),\n",
    "    ('scale', StandardScaler()),\n",
    "    ('estimate', BaggingRegressor(\n",
    "        GradientBoostingRegressor(\n",
    "          n_estimators=n_features, learning_rate=0.5,\n",
    "          verbose=1\n",
    "        )))\n",
    "\n",
    "  ]\n",
    "\n",
    "  bagging_est = Pipeline(steps_bagging)\n",
    "  bagging_est.fit(data_train, targets_train)\n",
    "  pickle.dump(bagging_est, open(EST_PICKLE_FILENAME1, \"w\") )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test data's prediction MAPE score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_predictions = bagging_est.predict(data_test)\n",
    "print(mape(targets_test, test_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "steps_bagging = [\n",
    "  ('impute', Imputer()),\n",
    "  # Remember that gap, the first variable, was removed, thus categorical_features\n",
    "  # should start at index 0.\n",
    "  ('one_hot', OneHotEncoder(categorical_features=[0, 1, 2, 3], sparse=False,\n",
    "                           n_values=[7, 10, 10, 10])),\n",
    "  ('scale', StandardScaler()),\n",
    "  ('estimate', BaggingRegressor(\n",
    "      GradientBoostingRegressor(\n",
    "        n_estimators=n_features, learning_rate=0.5,\n",
    "        verbose=1\n",
    "      )))\n",
    "\n",
    "]\n",
    "\n",
    "params = {\n",
    "  'estimate__learning_rate': [0.1, 0.5, 1, 10],\n",
    "  'estimate__n_estimators': [i for i in range(110, n_features, 20)],\n",
    "#   'estimate__loss': ['linear', 'square', 'exponential']\n",
    "}\n",
    "\n",
    "search_params = RandomizedSearchCV(\n",
    "  estimator=est,\n",
    "  param_distributions=params,\n",
    "  cv=5,\n",
    "  scoring=mape_scorer,\n",
    "  n_jobs=2,\n",
    "  verbose=1\n",
    ")\n",
    "\n",
    "search_params.fit(data_train_original, targets_train)\n",
    "print(search_params.grid_scores_)\n",
    "print(search_params.best_params_)\n",
    "print(search_params.best_score_)\n",
    "search_params.best_estimator_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
