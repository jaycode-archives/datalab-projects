{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from tables import *\n",
    "import pdb\n",
    "import numpy as np\n",
    "import gcp.bigquery as bq\n",
    "import gcp.storage as storage\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import Imputer, MinMaxScaler, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "try:\n",
    "   import cPickle as pickle\n",
    "except:\n",
    "   import pickle\n",
    "EST_PICKLE_FILENAME = 'GradientBoostingRegressor_grid_best.pkl'\n",
    "\n",
    "seed = 13\n",
    "np.random.seed(seed)\n",
    "\n",
    "# Put all categorical data first for easier implementation of One Hot Encoding.\n",
    "fields_str = \"\"\"\n",
    "gap\tday_in_week\tweather_1_slots_ago\tweather_2_slots_ago\tweather_3_slots_ago\tbusy_time\t\n",
    "tj_level1_1_slots_ago\ttj_level2_1_slots_ago\ttj_level3_1_slots_ago\ttj_level4_1_slots_ago\t\n",
    "tj_level1_2_slots_ago\ttj_level2_2_slots_ago\ttj_level3_2_slots_ago\ttj_level4_2_slots_ago\t\n",
    "tj_level1_3_slots_ago\ttj_level2_3_slots_ago\ttj_level3_3_slots_ago\ttj_level4_3_slots_ago\t\n",
    "temperature_1_slots_ago\tpm25_1_slots_ago\t\n",
    "temperature_2_slots_ago\tpm25_2_slots_ago\t\n",
    "temperature_3_slots_ago\tpm25_3_slots_ago\t\n",
    "gap_1_slots_ago\tsum_price_1_slots_ago\t\n",
    "gap_2_slots_ago\tsum_price_2_slots_ago\t\n",
    "gap_3_slots_ago\tsum_price_3_slots_ago\t\n",
    "f1\tf11\tf11_1\tf11_2\tf11_3\tf11_4\tf11_5\tf11_6\tf11_7\t\n",
    "f11_8\tf13_4\tf13_8\tf14\tf14_1\tf14_10\tf14_2\tf14_3\tf14_6\tf14_8\tf15\tf15_1\t\n",
    "f15_2\tf15_3\tf15_4\tf15_6\tf15_7\tf15_8\tf16\tf16_1\tf16_10\tf16_11\tf16_12\tf16_3\t\n",
    "f16_4\tf16_6\tf17\tf17_2\tf17_3\tf17_4\tf17_5\tf19\tf19_1\tf19_2\tf19_3\tf19_4\tf1_1\t\n",
    "f1_10\tf1_11\tf1_2\tf1_3\tf1_4\tf1_5\tf1_6\tf1_7\tf1_8\tf20\tf20_1\tf20_2\t\n",
    "f20_4\tf20_5\tf20_6\tf20_7\tf20_8\tf20_9\tf21_1\tf21_2\tf22\tf22_1\tf22_2\tf22_3\t\n",
    "f22_4\tf22_5\tf23\tf23_1\tf23_2\tf23_3\tf23_4\tf23_5\tf23_6\tf24\tf24_1\tf24_2\tf24_3\t\n",
    "f25\tf25_1\tf25_3\tf25_7\tf25_8\tf25_9\tf2_1\tf2_10\tf2_11\tf2_12\tf2_13\tf2_2\t\n",
    "f2_4\tf2_5\tf2_6\tf2_7\tf2_8\tf3_1\tf3_2\tf3_3\tf4\tf4_1\tf4_10\tf4_11\t\n",
    "f4_13\tf4_14\tf4_16\tf4_17\tf4_18\tf4_2\tf4_3\tf4_5\tf4_6\tf4_7\tf4_8\tf4_9\t\n",
    "f5\tf5_1\tf5_3\tf5_4\tf6\tf6_1\tf6_2\tf6_4\tf7\tf8\tf8_1\tf8_2\tf8_3\tf8_4\t\n",
    "f8_5\n",
    "\"\"\"\n",
    "fields = map(lambda x: x.strip(), fields_str.split('\\t'))\n",
    "features = fields[1:]\n",
    "\n",
    "# Use this instead of len(features) since this variable can change\n",
    "# e.g. when one hot encoding is used and/or new features are added.\n",
    "n_features = len(features)\n",
    "\n",
    "datafile_path = 'xjk_pytable.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fileh = open_file(datafile_path, mode = 'w')\n",
    "train = fileh.create_group('/', 'train', 'Training tables')\n",
    "tabledef = {}\n",
    "for field in fields:\n",
    "  tabledef[field] = Float64Col()\n",
    "gaps = fileh.create_table(train, 'gaps', tabledef)\n",
    "fileh.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print ', '.join(fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%sql --module q_all\n",
    "\n",
    "SELECT gap, day_in_week, weather_1_slots_ago, weather_2_slots_ago, weather_3_slots_ago,\n",
    "  IF(timeofday_slot >= 50 AND timeofday_slot <= 53, 1, 0) AS busy_time,\n",
    "  tj_level1_1_slots_ago, tj_level2_1_slots_ago, tj_level3_1_slots_ago, tj_level4_1_slots_ago,\n",
    "  tj_level1_2_slots_ago, tj_level2_2_slots_ago, tj_level3_2_slots_ago, tj_level4_2_slots_ago,\n",
    "  tj_level1_3_slots_ago, tj_level2_3_slots_ago, tj_level3_3_slots_ago, tj_level4_3_slots_ago,\n",
    "  temperature_1_slots_ago, pm25_1_slots_ago, temperature_2_slots_ago, pm25_2_slots_ago,\n",
    "  temperature_3_slots_ago, pm25_3_slots_ago, gap_1_slots_ago, sum_price_1_slots_ago,\n",
    "  gap_2_slots_ago, sum_price_2_slots_ago, gap_3_slots_ago, sum_price_3_slots_ago, f1, f11, f11_1,\n",
    "  f11_2, f11_3, f11_4, f11_5, f11_6, f11_7, f11_8, f13_4, f13_8, f14, f14_1, f14_10, f14_2, f14_3,\n",
    "  f14_6, f14_8, f15, f15_1, f15_2, f15_3, f15_4, f15_6, f15_7, f15_8, f16, f16_1, f16_10, f16_11,\n",
    "  f16_12, f16_3, f16_4, f16_6, f17, f17_2, f17_3, f17_4, f17_5, f19, f19_1, f19_2, f19_3, f19_4,\n",
    "  f1_1, f1_10, f1_11, f1_2, f1_3, f1_4, f1_5, f1_6, f1_7, f1_8, f20, f20_1, f20_2, f20_4, f20_5,\n",
    "  f20_6, f20_7, f20_8, f20_9, f21_1, f21_2, f22, f22_1, f22_2, f22_3, f22_4, f22_5, f23, f23_1,\n",
    "  f23_2, f23_3, f23_4, f23_5, f23_6, f24, f24_1, f24_2, f24_3, f25, f25_1, f25_3, f25_7, f25_8,\n",
    "  f25_9, f2_1, f2_10, f2_11, f2_12, f2_13, f2_2, f2_4, f2_5, f2_6, f2_7, f2_8, f3_1, f3_2, f3_3,\n",
    "  f4, f4_1, f4_10, f4_11, f4_13, f4_14, f4_16, f4_17, f4_18, f4_2, f4_3, f4_5, f4_6, f4_7, f4_8,\n",
    "  f4_9, f5, f5_1, f5_3, f5_4, f6, f6_1, f6_2, f6_4, f7, f8, f8_1, f8_2, f8_3, f8_4, f8_5\n",
    "FROM [datalab-projects-1331:xjk_algo_comp.gaps]\n",
    "WHERE gap > 0\n",
    "LIMIT 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%timeit -n 1 -r 1\n",
    "\n",
    "# query = bq.Query(q_all)\n",
    "# tableresult = query.results()\n",
    "\n",
    "# all_data = np.zeros((tableresult.length, len(fields)))\n",
    "# print 'there are {} rows'.format(tableresult.length)\n",
    "# for rcounter, row in enumerate(tableresult):\n",
    "#   all_data[rcounter] = row.values()\n",
    "# #   for fcounter, field in enumerate(fields):\n",
    "# #     all_data[rcounter, fcounter] = row[field]\n",
    "#   if rcounter % 5000 == 0:\n",
    "#     print 'processed {} rows'.format(rcounter)\n",
    "# all_data_original = np.copy(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%timeit -n 1 -r 1\n",
    "\n",
    "query = bq.Query(q_all)\n",
    "tableresult = query.results()\n",
    "\n",
    "all_data = np.zeros((tableresult.length, len(fields)))\n",
    "print 'there are {} rows'.format(tableresult.length)\n",
    "for rcounter, row in enumerate(tableresult):\n",
    "#   all_data[rcounter] = row.values()\n",
    "  for fcounter, field in enumerate(fields):\n",
    "    all_data[rcounter, fcounter] = row[field]\n",
    "  if rcounter % 5000 == 0:\n",
    "    print 'processed {} rows'.format(rcounter)\n",
    "all_data_original = np.copy(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fileh = open_file(datafile_path, mode = 'r+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "/train/gaps (Table(0,)) ''\n",
       "  description := {\n",
       "  \"busy_time\": Float64Col(shape=(), dflt=0.0, pos=0),\n",
       "  \"day_in_week\": Float64Col(shape=(), dflt=0.0, pos=1),\n",
       "  \"f1\": Float64Col(shape=(), dflt=0.0, pos=2),\n",
       "  \"f11\": Float64Col(shape=(), dflt=0.0, pos=3),\n",
       "  \"f11_1\": Float64Col(shape=(), dflt=0.0, pos=4),\n",
       "  \"f11_2\": Float64Col(shape=(), dflt=0.0, pos=5),\n",
       "  \"f11_3\": Float64Col(shape=(), dflt=0.0, pos=6),\n",
       "  \"f11_4\": Float64Col(shape=(), dflt=0.0, pos=7),\n",
       "  \"f11_5\": Float64Col(shape=(), dflt=0.0, pos=8),\n",
       "  \"f11_6\": Float64Col(shape=(), dflt=0.0, pos=9),\n",
       "  \"f11_7\": Float64Col(shape=(), dflt=0.0, pos=10),\n",
       "  \"f11_8\": Float64Col(shape=(), dflt=0.0, pos=11),\n",
       "  \"f13_4\": Float64Col(shape=(), dflt=0.0, pos=12),\n",
       "  \"f13_8\": Float64Col(shape=(), dflt=0.0, pos=13),\n",
       "  \"f14\": Float64Col(shape=(), dflt=0.0, pos=14),\n",
       "  \"f14_1\": Float64Col(shape=(), dflt=0.0, pos=15),\n",
       "  \"f14_10\": Float64Col(shape=(), dflt=0.0, pos=16),\n",
       "  \"f14_2\": Float64Col(shape=(), dflt=0.0, pos=17),\n",
       "  \"f14_3\": Float64Col(shape=(), dflt=0.0, pos=18),\n",
       "  \"f14_6\": Float64Col(shape=(), dflt=0.0, pos=19),\n",
       "  \"f14_8\": Float64Col(shape=(), dflt=0.0, pos=20),\n",
       "  \"f15\": Float64Col(shape=(), dflt=0.0, pos=21),\n",
       "  \"f15_1\": Float64Col(shape=(), dflt=0.0, pos=22),\n",
       "  \"f15_2\": Float64Col(shape=(), dflt=0.0, pos=23),\n",
       "  \"f15_3\": Float64Col(shape=(), dflt=0.0, pos=24),\n",
       "  \"f15_4\": Float64Col(shape=(), dflt=0.0, pos=25),\n",
       "  \"f15_6\": Float64Col(shape=(), dflt=0.0, pos=26),\n",
       "  \"f15_7\": Float64Col(shape=(), dflt=0.0, pos=27),\n",
       "  \"f15_8\": Float64Col(shape=(), dflt=0.0, pos=28),\n",
       "  \"f16\": Float64Col(shape=(), dflt=0.0, pos=29),\n",
       "  \"f16_1\": Float64Col(shape=(), dflt=0.0, pos=30),\n",
       "  \"f16_10\": Float64Col(shape=(), dflt=0.0, pos=31),\n",
       "  \"f16_11\": Float64Col(shape=(), dflt=0.0, pos=32),\n",
       "  \"f16_12\": Float64Col(shape=(), dflt=0.0, pos=33),\n",
       "  \"f16_3\": Float64Col(shape=(), dflt=0.0, pos=34),\n",
       "  \"f16_4\": Float64Col(shape=(), dflt=0.0, pos=35),\n",
       "  \"f16_6\": Float64Col(shape=(), dflt=0.0, pos=36),\n",
       "  \"f17\": Float64Col(shape=(), dflt=0.0, pos=37),\n",
       "  \"f17_2\": Float64Col(shape=(), dflt=0.0, pos=38),\n",
       "  \"f17_3\": Float64Col(shape=(), dflt=0.0, pos=39),\n",
       "  \"f17_4\": Float64Col(shape=(), dflt=0.0, pos=40),\n",
       "  \"f17_5\": Float64Col(shape=(), dflt=0.0, pos=41),\n",
       "  \"f19\": Float64Col(shape=(), dflt=0.0, pos=42),\n",
       "  \"f19_1\": Float64Col(shape=(), dflt=0.0, pos=43),\n",
       "  \"f19_2\": Float64Col(shape=(), dflt=0.0, pos=44),\n",
       "  \"f19_3\": Float64Col(shape=(), dflt=0.0, pos=45),\n",
       "  \"f19_4\": Float64Col(shape=(), dflt=0.0, pos=46),\n",
       "  \"f1_1\": Float64Col(shape=(), dflt=0.0, pos=47),\n",
       "  \"f1_10\": Float64Col(shape=(), dflt=0.0, pos=48),\n",
       "  \"f1_11\": Float64Col(shape=(), dflt=0.0, pos=49),\n",
       "  \"f1_2\": Float64Col(shape=(), dflt=0.0, pos=50),\n",
       "  \"f1_3\": Float64Col(shape=(), dflt=0.0, pos=51),\n",
       "  \"f1_4\": Float64Col(shape=(), dflt=0.0, pos=52),\n",
       "  \"f1_5\": Float64Col(shape=(), dflt=0.0, pos=53),\n",
       "  \"f1_6\": Float64Col(shape=(), dflt=0.0, pos=54),\n",
       "  \"f1_7\": Float64Col(shape=(), dflt=0.0, pos=55),\n",
       "  \"f1_8\": Float64Col(shape=(), dflt=0.0, pos=56),\n",
       "  \"f20\": Float64Col(shape=(), dflt=0.0, pos=57),\n",
       "  \"f20_1\": Float64Col(shape=(), dflt=0.0, pos=58),\n",
       "  \"f20_2\": Float64Col(shape=(), dflt=0.0, pos=59),\n",
       "  \"f20_4\": Float64Col(shape=(), dflt=0.0, pos=60),\n",
       "  \"f20_5\": Float64Col(shape=(), dflt=0.0, pos=61),\n",
       "  \"f20_6\": Float64Col(shape=(), dflt=0.0, pos=62),\n",
       "  \"f20_7\": Float64Col(shape=(), dflt=0.0, pos=63),\n",
       "  \"f20_8\": Float64Col(shape=(), dflt=0.0, pos=64),\n",
       "  \"f20_9\": Float64Col(shape=(), dflt=0.0, pos=65),\n",
       "  \"f21_1\": Float64Col(shape=(), dflt=0.0, pos=66),\n",
       "  \"f21_2\": Float64Col(shape=(), dflt=0.0, pos=67),\n",
       "  \"f22\": Float64Col(shape=(), dflt=0.0, pos=68),\n",
       "  \"f22_1\": Float64Col(shape=(), dflt=0.0, pos=69),\n",
       "  \"f22_2\": Float64Col(shape=(), dflt=0.0, pos=70),\n",
       "  \"f22_3\": Float64Col(shape=(), dflt=0.0, pos=71),\n",
       "  \"f22_4\": Float64Col(shape=(), dflt=0.0, pos=72),\n",
       "  \"f22_5\": Float64Col(shape=(), dflt=0.0, pos=73),\n",
       "  \"f23\": Float64Col(shape=(), dflt=0.0, pos=74),\n",
       "  \"f23_1\": Float64Col(shape=(), dflt=0.0, pos=75),\n",
       "  \"f23_2\": Float64Col(shape=(), dflt=0.0, pos=76),\n",
       "  \"f23_3\": Float64Col(shape=(), dflt=0.0, pos=77),\n",
       "  \"f23_4\": Float64Col(shape=(), dflt=0.0, pos=78),\n",
       "  \"f23_5\": Float64Col(shape=(), dflt=0.0, pos=79),\n",
       "  \"f23_6\": Float64Col(shape=(), dflt=0.0, pos=80),\n",
       "  \"f24\": Float64Col(shape=(), dflt=0.0, pos=81),\n",
       "  \"f24_1\": Float64Col(shape=(), dflt=0.0, pos=82),\n",
       "  \"f24_2\": Float64Col(shape=(), dflt=0.0, pos=83),\n",
       "  \"f24_3\": Float64Col(shape=(), dflt=0.0, pos=84),\n",
       "  \"f25\": Float64Col(shape=(), dflt=0.0, pos=85),\n",
       "  \"f25_1\": Float64Col(shape=(), dflt=0.0, pos=86),\n",
       "  \"f25_3\": Float64Col(shape=(), dflt=0.0, pos=87),\n",
       "  \"f25_7\": Float64Col(shape=(), dflt=0.0, pos=88),\n",
       "  \"f25_8\": Float64Col(shape=(), dflt=0.0, pos=89),\n",
       "  \"f25_9\": Float64Col(shape=(), dflt=0.0, pos=90),\n",
       "  \"f2_1\": Float64Col(shape=(), dflt=0.0, pos=91),\n",
       "  \"f2_10\": Float64Col(shape=(), dflt=0.0, pos=92),\n",
       "  \"f2_11\": Float64Col(shape=(), dflt=0.0, pos=93),\n",
       "  \"f2_12\": Float64Col(shape=(), dflt=0.0, pos=94),\n",
       "  \"f2_13\": Float64Col(shape=(), dflt=0.0, pos=95),\n",
       "  \"f2_2\": Float64Col(shape=(), dflt=0.0, pos=96),\n",
       "  \"f2_4\": Float64Col(shape=(), dflt=0.0, pos=97),\n",
       "  \"f2_5\": Float64Col(shape=(), dflt=0.0, pos=98),\n",
       "  \"f2_6\": Float64Col(shape=(), dflt=0.0, pos=99),\n",
       "  \"f2_7\": Float64Col(shape=(), dflt=0.0, pos=100),\n",
       "  \"f2_8\": Float64Col(shape=(), dflt=0.0, pos=101),\n",
       "  \"f3_1\": Float64Col(shape=(), dflt=0.0, pos=102),\n",
       "  \"f3_2\": Float64Col(shape=(), dflt=0.0, pos=103),\n",
       "  \"f3_3\": Float64Col(shape=(), dflt=0.0, pos=104),\n",
       "  \"f4\": Float64Col(shape=(), dflt=0.0, pos=105),\n",
       "  \"f4_1\": Float64Col(shape=(), dflt=0.0, pos=106),\n",
       "  \"f4_10\": Float64Col(shape=(), dflt=0.0, pos=107),\n",
       "  \"f4_11\": Float64Col(shape=(), dflt=0.0, pos=108),\n",
       "  \"f4_13\": Float64Col(shape=(), dflt=0.0, pos=109),\n",
       "  \"f4_14\": Float64Col(shape=(), dflt=0.0, pos=110),\n",
       "  \"f4_16\": Float64Col(shape=(), dflt=0.0, pos=111),\n",
       "  \"f4_17\": Float64Col(shape=(), dflt=0.0, pos=112),\n",
       "  \"f4_18\": Float64Col(shape=(), dflt=0.0, pos=113),\n",
       "  \"f4_2\": Float64Col(shape=(), dflt=0.0, pos=114),\n",
       "  \"f4_3\": Float64Col(shape=(), dflt=0.0, pos=115),\n",
       "  \"f4_5\": Float64Col(shape=(), dflt=0.0, pos=116),\n",
       "  \"f4_6\": Float64Col(shape=(), dflt=0.0, pos=117),\n",
       "  \"f4_7\": Float64Col(shape=(), dflt=0.0, pos=118),\n",
       "  \"f4_8\": Float64Col(shape=(), dflt=0.0, pos=119),\n",
       "  \"f4_9\": Float64Col(shape=(), dflt=0.0, pos=120),\n",
       "  \"f5\": Float64Col(shape=(), dflt=0.0, pos=121),\n",
       "  \"f5_1\": Float64Col(shape=(), dflt=0.0, pos=122),\n",
       "  \"f5_3\": Float64Col(shape=(), dflt=0.0, pos=123),\n",
       "  \"f5_4\": Float64Col(shape=(), dflt=0.0, pos=124),\n",
       "  \"f6\": Float64Col(shape=(), dflt=0.0, pos=125),\n",
       "  \"f6_1\": Float64Col(shape=(), dflt=0.0, pos=126),\n",
       "  \"f6_2\": Float64Col(shape=(), dflt=0.0, pos=127),\n",
       "  \"f6_4\": Float64Col(shape=(), dflt=0.0, pos=128),\n",
       "  \"f7\": Float64Col(shape=(), dflt=0.0, pos=129),\n",
       "  \"f8\": Float64Col(shape=(), dflt=0.0, pos=130),\n",
       "  \"f8_1\": Float64Col(shape=(), dflt=0.0, pos=131),\n",
       "  \"f8_2\": Float64Col(shape=(), dflt=0.0, pos=132),\n",
       "  \"f8_3\": Float64Col(shape=(), dflt=0.0, pos=133),\n",
       "  \"f8_4\": Float64Col(shape=(), dflt=0.0, pos=134),\n",
       "  \"f8_5\": Float64Col(shape=(), dflt=0.0, pos=135),\n",
       "  \"gap\": Float64Col(shape=(), dflt=0.0, pos=136),\n",
       "  \"gap_1_slots_ago\": Float64Col(shape=(), dflt=0.0, pos=137),\n",
       "  \"gap_2_slots_ago\": Float64Col(shape=(), dflt=0.0, pos=138),\n",
       "  \"gap_3_slots_ago\": Float64Col(shape=(), dflt=0.0, pos=139),\n",
       "  \"pm25_1_slots_ago\": Float64Col(shape=(), dflt=0.0, pos=140),\n",
       "  \"pm25_2_slots_ago\": Float64Col(shape=(), dflt=0.0, pos=141),\n",
       "  \"pm25_3_slots_ago\": Float64Col(shape=(), dflt=0.0, pos=142),\n",
       "  \"sum_price_1_slots_ago\": Float64Col(shape=(), dflt=0.0, pos=143),\n",
       "  \"sum_price_2_slots_ago\": Float64Col(shape=(), dflt=0.0, pos=144),\n",
       "  \"sum_price_3_slots_ago\": Float64Col(shape=(), dflt=0.0, pos=145),\n",
       "  \"temperature_1_slots_ago\": Float64Col(shape=(), dflt=0.0, pos=146),\n",
       "  \"temperature_2_slots_ago\": Float64Col(shape=(), dflt=0.0, pos=147),\n",
       "  \"temperature_3_slots_ago\": Float64Col(shape=(), dflt=0.0, pos=148),\n",
       "  \"tj_level1_1_slots_ago\": Float64Col(shape=(), dflt=0.0, pos=149),\n",
       "  \"tj_level1_2_slots_ago\": Float64Col(shape=(), dflt=0.0, pos=150),\n",
       "  \"tj_level1_3_slots_ago\": Float64Col(shape=(), dflt=0.0, pos=151),\n",
       "  \"tj_level2_1_slots_ago\": Float64Col(shape=(), dflt=0.0, pos=152),\n",
       "  \"tj_level2_2_slots_ago\": Float64Col(shape=(), dflt=0.0, pos=153),\n",
       "  \"tj_level2_3_slots_ago\": Float64Col(shape=(), dflt=0.0, pos=154),\n",
       "  \"tj_level3_1_slots_ago\": Float64Col(shape=(), dflt=0.0, pos=155),\n",
       "  \"tj_level3_2_slots_ago\": Float64Col(shape=(), dflt=0.0, pos=156),\n",
       "  \"tj_level3_3_slots_ago\": Float64Col(shape=(), dflt=0.0, pos=157),\n",
       "  \"tj_level4_1_slots_ago\": Float64Col(shape=(), dflt=0.0, pos=158),\n",
       "  \"tj_level4_2_slots_ago\": Float64Col(shape=(), dflt=0.0, pos=159),\n",
       "  \"tj_level4_3_slots_ago\": Float64Col(shape=(), dflt=0.0, pos=160),\n",
       "  \"weather_1_slots_ago\": Float64Col(shape=(), dflt=0.0, pos=161),\n",
       "  \"weather_2_slots_ago\": Float64Col(shape=(), dflt=0.0, pos=162),\n",
       "  \"weather_3_slots_ago\": Float64Col(shape=(), dflt=0.0, pos=163)}\n",
       "  byteorder := 'little'\n",
       "  chunkshape := (99,)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fileh.root.train.gaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%timeit -n 1 -r 1\n",
    "\n",
    "fileh = open_file(datafile_path, mode = 'rw')\n",
    "file\n",
    "\n",
    "if table exists:\n",
    "  \n",
    "else:\n",
    "  query = bq.Query(q_all)\n",
    "  tableresult = query.results()\n",
    "\n",
    "  all_data = np.zeros((tableresult.length, len(fields)))\n",
    "  print 'there are {} rows'.format(tableresult.length)\n",
    "  for rcounter, row in enumerate(tableresult):\n",
    "  #   all_data[rcounter] = row.values()\n",
    "    for fcounter, field in enumerate(fields):\n",
    "      all_data[rcounter, fcounter] = row[field]\n",
    "    if rcounter % 5000 == 0:\n",
    "      print 'processed {} rows'.format(rcounter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(len(fields))\n",
    "print(len(row.values()))\n",
    "print(row.keys())\n",
    "for key in row.keys():\n",
    "  print \"checking\", key\n",
    "  if key not in fields:\n",
    "    print \"does not exist\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This chunk does further wrangling to dataset to produce training and test sets.\n",
    "\n",
    "# Useful code to check NaN and Inf values. This is needed since these values would\n",
    "# cause \"Input contains NaN, infinity or a value too large for dtype('float32')\n",
    "# errors when left unchecked.\n",
    "print \"Checkinf for NaN and Inf\"\n",
    "print \"np.nan=\", np.where(np.isnan(all_data_original))\n",
    "print \"is.inf=\", np.where(np.isinf(all_data_original))\n",
    "print \"np.max=\", np.max(abs(all_data_original))\n",
    "\n",
    "# Impute all NaN with numbers (not sure what to replace inf yet)\n",
    "all_data[np.isnan(all_data_original)] = 0\n",
    "# all_data[np.isinf(all_data)] = 0\n",
    "\n",
    "# See that NaN and Inf values replaced\n",
    "print \"Checkinf for NaN and Inf\"\n",
    "print \"np.nan=\", np.where(np.isnan(all_data))\n",
    "print \"is.inf=\", np.where(np.isinf(all_data))\n",
    "print \"np.max=\", np.max(abs(all_data))\n",
    "\n",
    "# Split the data into train and test sets.\n",
    "data_size = all_data.shape[0]\n",
    "training_size = data_size * 80/100\n",
    "indices = np.random.permutation(data_size)\n",
    "training_idx, test_idx = indices[:training_size], indices[training_size:]\n",
    "all_data_train, all_data_test = all_data[training_idx,:], all_data[test_idx,:]\n",
    "\n",
    "data_train = all_data_train[:,1:]\n",
    "targets_train = all_data_train[:,0]\n",
    "data_test = all_data_test[:,1:]\n",
    "targets_test = all_data_test[:,0]\n",
    "data_train_original = np.copy(data_train)\n",
    "data_test_original = np.copy(data_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration - Find NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This is how to get position of NaNs\n",
    "\n",
    "nulls = np.isnan(all_data_original)\n",
    "nullspos = np.column_stack(np.where(nulls==True))\n",
    "nullspos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = [[np.NaN, 1, 2, 3],\n",
    "     [1, 2, 3, np.NaN]]\n",
    "xn = np.isnan(x)\n",
    "xnp = np.column_stack(np.where(xn==True))\n",
    "xnp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from operator import itemgetter\n",
    "print \"total data points:\", (all_data_original.shape[0] * all_data_original.shape[1])\n",
    "print \"number of missing values:\", nullspos.shape[0]\n",
    "missing_features = itemgetter(*np.unique(nullspos[:,1]).tolist())(fields)\n",
    "missing_features_table = pd.DataFrame(columns=['id', 'field', 'missing data points'])\n",
    "\n",
    "for id, field in enumerate(fields):\n",
    "  total_missing = len(np.where(nullspos[:,1]==id)[0])\n",
    "  if total_missing > 0:\n",
    "    missing_features_table = missing_features_table.append({\n",
    "        'id': id,\n",
    "        'field': field,\n",
    "        'missing data points': total_missing\n",
    "      }, ignore_index=True)\n",
    "missing_features_table['missing data points'] = \\\n",
    "  missing_features_table['missing data points'].astype('int64')\n",
    "missing_features_table['id'] = \\\n",
    "  missing_features_table['id'].astype('int64')\n",
    "missing_features_table.sort_values(['missing data points', 'id'], ascending=[False, True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "matplotlib.rcParams['figure.figsize'] = (15.0, 9.0)\n",
    "def rand_jitter(arr):\n",
    "    stdev = .005*(max(arr)-min(arr))\n",
    "    return arr + np.random.randn(len(arr)) * stdev\n",
    "_ = plt.scatter(nullspos[:,0], rand_jitter(nullspos[:,1]), s=0.5)\n",
    "_ = plt.title('Missing Data Points')\n",
    "_ = plt.ylabel('Feature ID')\n",
    "_ = plt.xlabel('Observation ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT COUNT(*) AS count FROM [datalab-projects-1331:xjk_algo_comp.gaps]\n",
    "WHERE IS_NAN(sum_price_1_slots_ago) = true\n",
    "AND gap > 0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
