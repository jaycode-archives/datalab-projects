{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pdb\n",
    "import numpy as np\n",
    "import gcp.bigquery as bq\n",
    "import gcp.storage as storage\n",
    "from sklearn.pipeline import Pipeline\n",
    "try:\n",
    "   import cPickle as pickle\n",
    "except:\n",
    "   import pickle\n",
    "EST_PICKLE_FILENAME = 'baseline_final_estimator.pkl'\n",
    "\n",
    "# First feature HAS to be 'district_id' for MAPE calculation.\n",
    "fields_str = \"\"\"\n",
    "district_id\ttimeofday_slot\tday_in_week\tis_sunday\tsum_price\tavg_price\tpoi1\tpoi2\tpoi3\n",
    "\tpoi4\tpoi5\ttraffic_tj_level1\ttraffic_tj_level2\ttraffic_tj_level3\ttraffic_tj_level4\n",
    "\tweather\tweather_pm25\tweather_temperature\tgap\n",
    "\"\"\"\n",
    "fields = map(lambda x: x.strip(), fields_str.split('\\t'))\n",
    "features = fields[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scorer Creation (MAPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mape(X, predictions, y):\n",
    "  num_timeslots = 43\n",
    "  num_districts = 66\n",
    "  if len(y.shape) == 1:\n",
    "    y = np.asmatrix(y)\n",
    "  if len(predictions.shape) == 1:\n",
    "    predictions = np.asmatrix(predictions)\n",
    "  Xy = np.concatenate((X, y.T, predictions.T), axis=1)\n",
    "  districts = np.unique(X[:,0])\n",
    "  district_scores = np.zeros(len(districts))\n",
    "  for counter, key in enumerate(districts):\n",
    "    group = np.compress((Xy[:,0] == key).flat, Xy, axis=0)\n",
    "    district_scores[counter] = np.sum(np.absolute(\n",
    "        (group[:,-2] -\n",
    "         group[:,-1])/\n",
    "        group[:,-2]\n",
    "      )) / num_timeslots\n",
    "  return np.sum(district_scores) / num_districts\n",
    "\n",
    "def mape_scorer(estimator, X, y):\n",
    "  predictions = estimator.predict(X)\n",
    "  return -mape(X, predictions, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing MAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "est = LogisticRegression()\n",
    "X = np.array([[1, 1], [1, 2], [2, 3], [2, 4]])\n",
    "predictions = np.array([1, 2, 3, 4])\n",
    "y = np.array([1, 2, 3, 4])\n",
    "\n",
    "# Should return 0.0\n",
    "mape(X, predictions, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%sql --module q_all\n",
    "\n",
    "SELECT *, HASH(CAST(district_id AS STRING) +timeslot) AS hash_value,\n",
    "  IF(ABS(HASH(CAST(district_id AS STRING) + timeslot)) % 2 == 1, 'True', 'False')\n",
    "    AS included_in_sample\n",
    "FROM [datalab-projects-1331:xjk_algo_comp.future_gaps_final1]\n",
    "WHERE gap > 0\n",
    "\n",
    "# The above query randomizes its outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "query = bq.Query(q_all)\n",
    "tableresult = query.results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 102680 rows\n",
      "there are 102680 rows\n",
      "there are 102680 rows\n",
      "processed 0 rows\n",
      "processed 0 rows\n",
      "processed 0 rows\n",
      "processed 5000 rows\n",
      "processed 5000 rows\n",
      "processed 5000 rows\n",
      "processed 10000 rows\n",
      "processed 10000 rows\n",
      "processed 10000 rows\n",
      "processed 15000 rows\n",
      "processed 15000 rows\n",
      "processed 15000 rows\n",
      "processed 20000 rows\n",
      "processed 20000 rows\n",
      "processed 20000 rows\n",
      "processed 25000 rows\n",
      "processed 25000 rows\n",
      "processed 25000 rows\n",
      "processed 30000 rows\n",
      "processed 30000 rows\n",
      "processed 30000 rows\n",
      "processed 35000 rows\n",
      "processed 35000 rows\n",
      "processed 35000 rows\n",
      "processed 40000 rows\n",
      "processed 40000 rows\n",
      "processed 40000 rows\n",
      "processed 45000 rows\n",
      "processed 45000 rows\n",
      "processed 45000 rows\n",
      "processed 50000 rows\n",
      "processed 50000 rows\n",
      "processed 50000 rows\n",
      "processed 55000 rows\n",
      "processed 55000 rows\n",
      "processed 55000 rows\n",
      "processed 60000 rows\n",
      "processed 60000 rows\n",
      "processed 60000 rows\n",
      "processed 65000 rows\n",
      "processed 65000 rows\n",
      "processed 65000 rows\n",
      "processed 70000 rows\n",
      "processed 70000 rows\n",
      "processed 70000 rows\n",
      "processed 75000 rows\n",
      "processed 75000 rows\n",
      "processed 75000 rows\n",
      "processed 80000 rows\n",
      "processed 80000 rows\n",
      "processed 80000 rows\n",
      "processed 85000 rows\n",
      "processed 85000 rows\n",
      "processed 85000 rows\n",
      "processed 90000 rows\n",
      "processed 90000 rows\n",
      "processed 90000 rows\n",
      "processed 95000 rows\n",
      "processed 95000 rows\n",
      "processed 95000 rows\n",
      "processed 100000 rows\n",
      "processed 100000 rows\n",
      "processed 100000 rows\n"
     ]
    }
   ],
   "source": [
    "all_data = np.zeros((tableresult.length, len(fields)))\n",
    "print 'there are {} rows'.format(tableresult.length)\n",
    "for rcounter, row in enumerate(tableresult):\n",
    "  for fcounter, field in enumerate(fields):\n",
    "    all_data[rcounter, fcounter] = row[field]\n",
    "  if rcounter % 5000 == 0:\n",
    "    print 'processed {} rows'.format(rcounter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'2016-01-22-46','2016-01-22-58','2016-01-22-70','2016-01-22-82','2016-01-22-94','2016-01-22-106','2016-01-22-118','2016-01-22-130','2016-01-22-142','2016-01-24-58','2016-01-24-70','2016-01-24-82','2016-01-24-94','2016-01-24-106','2016-01-24-118','2016-01-24-130','2016-01-24-142','2016-01-26-46','2016-01-26-58','2016-01-26-70','2016-01-26-82','2016-01-26-94','2016-01-26-106','2016-01-26-118','2016-01-26-130','2016-01-26-142','2016-01-28-58','2016-01-28-70','2016-01-28-82','2016-01-28-94','2016-01-28-106','2016-01-28-118','2016-01-28-130','2016-01-28-142','2016-01-30-46','2016-01-30-58','2016-01-30-70','2016-01-30-82','2016-01-30-94','2016-01-30-106','2016-01-30-118','2016-01-30-130','2016-01-30-142'\n"
     ]
    }
   ],
   "source": [
    "# Get timeslots to test from GCS\n",
    "item = storage.Item('datalab-projects-1331-datalab','data/timeslots_to_test.txt')\n",
    "timeslots_to_test = item.read_from().strip().split('\\n')\n",
    "tquery = ','.join(map(lambda x: \"'{}'\".format(x), timeslots_to_test))\n",
    "print(tquery)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%sql --module q_all_t\n",
    "\n",
    "SELECT *\n",
    "FROM [datalab-projects-1331:xjk_algo_comp_test.future_gaps_final1]\n",
    "WHERE gap > 0 AND timeslot NOT IN ('2016-01-22-46','2016-01-22-58','2016-01-22-70','2016-01-22-82',\n",
    "    '2016-01-22-94','2016-01-22-106','2016-01-22-118','2016-01-22-130','2016-01-22-142',\n",
    "    '2016-01-24-58','2016-01-24-70','2016-01-24-82','2016-01-24-94','2016-01-24-106',\n",
    "    '2016-01-24-118','2016-01-24-130','2016-01-24-142','2016-01-26-46','2016-01-26-58',\n",
    "    '2016-01-26-70','2016-01-26-82','2016-01-26-94','2016-01-26-106','2016-01-26-118',\n",
    "    '2016-01-26-130','2016-01-26-142','2016-01-28-58','2016-01-28-70','2016-01-28-82',\n",
    "    '2016-01-28-94','2016-01-28-106','2016-01-28-118','2016-01-28-130','2016-01-28-142',\n",
    "    '2016-01-30-46','2016-01-30-58','2016-01-30-70','2016-01-30-82','2016-01-30-94',\n",
    "    '2016-01-30-106','2016-01-30-118','2016-01-30-130','2016-01-30-142')\n",
    "ORDER BY timeslot, district_id\n",
    "\n",
    "# Test dataset - used to check if estimator can generalize well to new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "query_t = bq.Query(q_all_t)\n",
    "tableresult_t = query_t.results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 3509 rows\n",
      "there are 3509 rows\n",
      "there are 3509 rows\n",
      "processed 0 rows\n",
      "processed 1000 rows\n",
      "processed 0 rows\n",
      "processed 1000 rows\n",
      "processed 0 rows\n",
      "processed 1000 rows\n",
      "processed 2000 rows\n",
      "processed 2000 rows\n",
      "processed 2000 rows\n",
      "processed 3000 rows\n",
      "processed 3000 rows\n",
      "processed 3000 rows\n"
     ]
    }
   ],
   "source": [
    "all_data_t = np.zeros((tableresult_t.length, len(fields)))\n",
    "print 'there are {} rows'.format(tableresult_t.length)\n",
    "for rcounter, row in enumerate(tableresult_t):\n",
    "  for fcounter, field in enumerate(fields):\n",
    "    all_data_t[rcounter, fcounter] = row[field]\n",
    "  if rcounter % 1000 == 0:\n",
    "    print 'processed {} rows'.format(rcounter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building and Testing Algorithm(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkinf for NaN and Inf\n",
      "np.nan= (array([     2,      2,      2, ..., 102679, 102679, 102679]), array([15, 16, 17, ..., 15, 16, 17]))\n",
      "is.inf= (array([], dtype=int64), array([], dtype=int64))\n",
      "np.max= nan\n",
      "Checkinf for NaN and Inf\n",
      "np.nan= (array([     2,      2,      2, ..., 102679, 102679, 102679]), array([15, 16, 17, ..., 15, 16, 17]))\n",
      "is.inf= (array([], dtype=int64), array([], dtype=int64))\n",
      "np.max= nan\n"
     ]
    }
   ],
   "source": [
    "# Useful code to check NaN and Inf values. This is needed since these values would\n",
    "# cause \"Input contains NaN, infinity or a value too large for dtype('float32')\n",
    "# errors when left unchecked.\n",
    "print \"Checkinf for NaN and Inf\"\n",
    "print \"np.nan=\", np.where(np.isnan(all_data))\n",
    "print \"is.inf=\", np.where(np.isinf(all_data))\n",
    "print \"np.max=\", np.max(abs(all_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_data[np.isnan(all_data)] = 0\n",
    "all_data_t[np.isnan(all_data_t)] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkinf for NaN and Inf\n",
      "np.nan= (array([], dtype=int64), array([], dtype=int64))\n",
      "is.inf= (array([], dtype=int64), array([], dtype=int64))\n",
      "np.max= 708222.866131\n",
      "Checkinf for NaN and Inf\n",
      "np.nan= (array([], dtype=int64), array([], dtype=int64))\n",
      "is.inf= (array([], dtype=int64), array([], dtype=int64))\n",
      "np.max= 708222.866131\n",
      "Checkinf for NaN and Inf\n",
      "np.nan= (array([], dtype=int64), array([], dtype=int64))\n",
      "is.inf= (array([], dtype=int64), array([], dtype=int64))\n",
      "np.max= 708222.866131\n"
     ]
    }
   ],
   "source": [
    "# Useful code to check NaN and Inf values. This is needed since these values would\n",
    "# cause \"Input contains NaN, infinity or a value too large for dtype('float32')\n",
    "# errors when left unchecked.\n",
    "print \"Checkinf for NaN and Inf\"\n",
    "print \"np.nan=\", np.where(np.isnan(all_data))\n",
    "print \"is.inf=\", np.where(np.isinf(all_data))\n",
    "print \"np.max=\", np.max(abs(all_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 42 candidates, totalling 210 fits\n",
      "Fitting 5 folds for each of 42 candidates, totalling 210 fits\n",
      "Fitting 5 folds for each of 42 candidates, totalling 210 fits\n",
      "An unexpected error occurred while tokenizing input\n",
      "The following traceback may be corrupted or invalid\n",
      "The error message is: ('EOF in multi-line statement', (2, 0))\n",
      "\n",
      "An unexpected error occurred while tokenizing input\n",
      "The following traceback may be corrupted or invalid\n",
      "The error message is: ('EOF in multi-line statement', (2, 0))\n",
      "\n",
      "An unexpected error occurred while tokenizing input\n",
      "The following traceback may be corrupted or invalid\n",
      "The error message is: ('EOF in multi-line statement', (2, 0))\n",
      "\n",
      "An unexpected error occurred while tokenizing input\n",
      "The following traceback may be corrupted or invalid\n",
      "The error message is: ('EOF in multi-line statement', (2, 0))\n",
      "\n",
      "An unexpected error occurred while tokenizing input\n",
      "The following traceback may be corrupted or invalid\n",
      "The error message is: ('EOF in multi-line statement', (2, 0))\n",
      "\n",
      "An unexpected error occurred while tokenizing input\n",
      "The following traceback may be corrupted or invalid\n",
      "The error message is: ('EOF in multi-line statement', (2, 0))\n",
      "\n",
      "An unexpected error occurred while tokenizing input\n",
      "The following traceback may be corrupted or invalid\n",
      "The error message is: ('EOF in multi-line statement', (2, 0))\n",
      "\n",
      "An unexpected error occurred while tokenizing input\n",
      "The following traceback may be corrupted or invalid\n",
      "The error message is: ('EOF in multi-line statement', (2, 0))\n",
      "\n",
      "An unexpected error occurred while tokenizing input\n",
      "The following traceback may be corrupted or invalid\n",
      "The error message is: ('EOF in multi-line statement', (2, 0))\n",
      "\n"
     ]
    },
    {
     "ename": "JoblibValueError",
     "evalue": "JoblibValueError\n___________________________________________________________________________\nMultiprocessing exception:\n    ...........................................................................\n/usr/lib/python2.7/runpy.py in _run_module_as_main(mod_name='ipykernel.__main__', alter_argv=1)\n    157     pkg_name = mod_name.rpartition('.')[0]\n    158     main_globals = sys.modules[\"__main__\"].__dict__\n    159     if alter_argv:\n    160         sys.argv[0] = fname\n    161     return _run_code(code, main_globals, None,\n--> 162                      \"__main__\", fname, loader, pkg_name)\n        fname = '/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py'\n        loader = <pkgutil.ImpLoader instance>\n        pkg_name = 'ipykernel'\n    163 \n    164 def run_module(mod_name, init_globals=None,\n    165                run_name=None, alter_sys=False):\n    166     \"\"\"Execute a module's code without importing it\n\n...........................................................................\n/usr/lib/python2.7/runpy.py in _run_code(code=<code object <module> at 0x7f99f453b330, file \"/...2.7/dist-packages/ipykernel/__main__.py\", line 1>, run_globals={'__builtins__': <module '__builtin__' (built-in)>, '__doc__': None, '__file__': '/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py', '__loader__': <pkgutil.ImpLoader instance>, '__name__': '__main__', '__package__': 'ipykernel', 'app': <module 'ipykernel.kernelapp' from '/usr/local/lib/python2.7/dist-packages/ipykernel/kernelapp.pyc'>}, init_globals=None, mod_name='__main__', mod_fname='/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py', mod_loader=<pkgutil.ImpLoader instance>, pkg_name='ipykernel')\n     67         run_globals.update(init_globals)\n     68     run_globals.update(__name__ = mod_name,\n     69                        __file__ = mod_fname,\n     70                        __loader__ = mod_loader,\n     71                        __package__ = pkg_name)\n---> 72     exec code in run_globals\n        code = <code object <module> at 0x7f99f453b330, file \"/...2.7/dist-packages/ipykernel/__main__.py\", line 1>\n        run_globals = {'__builtins__': <module '__builtin__' (built-in)>, '__doc__': None, '__file__': '/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py', '__loader__': <pkgutil.ImpLoader instance>, '__name__': '__main__', '__package__': 'ipykernel', 'app': <module 'ipykernel.kernelapp' from '/usr/local/lib/python2.7/dist-packages/ipykernel/kernelapp.pyc'>}\n     73     return run_globals\n     74 \n     75 def _run_module_code(code, init_globals=None,\n     76                     mod_name=None, mod_fname=None,\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py in <module>()\n      1 \n      2 \n----> 3 \n      4 if __name__ == '__main__':\n      5     from ipykernel import kernelapp as app\n      6     app.launch_new_instance()\n      7 \n      8 \n      9 \n     10 \n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/traitlets/config/application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    591         \n    592         If a global instance already exists, this reinitializes and starts it\n    593         \"\"\"\n    594         app = cls.instance(**kwargs)\n    595         app.initialize(argv)\n--> 596         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    597 \n    598 #-----------------------------------------------------------------------------\n    599 # utility functions, for convenience\n    600 #-----------------------------------------------------------------------------\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/ipykernel/kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    437         \n    438         if self.poller is not None:\n    439             self.poller.start()\n    440         self.kernel.start()\n    441         try:\n--> 442             ioloop.IOLoop.instance().start()\n    443         except KeyboardInterrupt:\n    444             pass\n    445 \n    446 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/zmq/eventloop/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    157             PollIOLoop.configure(ZMQIOLoop)\n    158         return PollIOLoop.current(*args, **kwargs)\n    159     \n    160     def start(self):\n    161         try:\n--> 162             super(ZMQIOLoop, self).start()\n        self.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    163         except ZMQError as e:\n    164             if e.errno == ETERM:\n    165                 # quietly return on ETERM\n    166                 pass\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/tornado/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    878                 self._events.update(event_pairs)\n    879                 while self._events:\n    880                     fd, events = self._events.popitem()\n    881                     try:\n    882                         fd_obj, handler_func = self._handlers[fd]\n--> 883                         handler_func(fd_obj, events)\n        handler_func = <function null_wrapper>\n        fd_obj = <zmq.sugar.socket.Socket object>\n        events = 1\n    884                     except (OSError, IOError) as e:\n    885                         if errno_from_exception(e) == errno.EPIPE:\n    886                             # Happens when the client closes the connection\n    887                             pass\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/tornado/stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    270         # Fast path when there are no active contexts.\n    271         def null_wrapper(*args, **kwargs):\n    272             try:\n    273                 current_state = _state.contexts\n    274                 _state.contexts = cap_contexts[0]\n--> 275                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    276             finally:\n    277                 _state.contexts = current_state\n    278         null_wrapper._wrapped = True\n    279         return null_wrapper\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    435             # dispatch events:\n    436             if events & IOLoop.ERROR:\n    437                 gen_log.error(\"got POLLERR event on ZMQStream, which doesn't make sense\")\n    438                 return\n    439             if events & IOLoop.READ:\n--> 440                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    441                 if not self.socket:\n    442                     return\n    443             if events & IOLoop.WRITE:\n    444                 self._handle_send()\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    467                 gen_log.error(\"RECV Error: %s\"%zmq.strerror(e.errno))\n    468         else:\n    469             if self._recv_callback:\n    470                 callback = self._recv_callback\n    471                 # self._recv_callback = None\n--> 472                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    473                 \n    474         # self.update_state()\n    475         \n    476 \n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    409         close our socket.\"\"\"\n    410         try:\n    411             # Use a NullContext to ensure that all StackContexts are run\n    412             # inside our blanket exception handler rather than outside.\n    413             with stack_context.NullContext():\n--> 414                 callback(*args, **kwargs)\n        callback = <function null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    415         except:\n    416             gen_log.error(\"Uncaught exception, closing connection.\",\n    417                           exc_info=True)\n    418             # Close the socket on an uncaught exception from a user callback\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/tornado/stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    270         # Fast path when there are no active contexts.\n    271         def null_wrapper(*args, **kwargs):\n    272             try:\n    273                 current_state = _state.contexts\n    274                 _state.contexts = cap_contexts[0]\n--> 275                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    276             finally:\n    277                 _state.contexts = current_state\n    278         null_wrapper._wrapped = True\n    279         return null_wrapper\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    271         if self.control_stream:\n    272             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    273 \n    274         def make_dispatcher(stream):\n    275             def dispatcher(msg):\n--> 276                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    277             return dispatcher\n    278 \n    279         for s in self.shell_streams:\n    280             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {u'allow_stdin': True, u'code': u'from sklearn.feature_selection import SelectKB...rams.best_score_)\\nsearch_params.best_estimator_', u'silent': False, u'stop_on_error': True, u'store_history': True, u'user_expressions': {}}, 'header': {'date': '2016-06-12T12:52:44.380983', u'msg_id': u'51BC7D2045F34C1DBFB596E8921EC318', u'msg_type': u'execute_request', u'session': u'CEF40C66C22B4B51AB5041666FFC5A00', u'username': u'username', u'version': u'5.0'}, 'metadata': {}, 'msg_id': u'51BC7D2045F34C1DBFB596E8921EC318', 'msg_type': u'execute_request', 'parent_header': {}})\n    223             self.log.error(\"UNKNOWN MESSAGE TYPE: %r\", msg_type)\n    224         else:\n    225             self.log.debug(\"%s: %s\", msg_type, msg)\n    226             self.pre_handler_hook()\n    227             try:\n--> 228                 handler(stream, idents, msg)\n        handler = <bound method IPythonKernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = ['CEF40C66C22B4B51AB5041666FFC5A00']\n        msg = {'buffers': [], 'content': {u'allow_stdin': True, u'code': u'from sklearn.feature_selection import SelectKB...rams.best_score_)\\nsearch_params.best_estimator_', u'silent': False, u'stop_on_error': True, u'store_history': True, u'user_expressions': {}}, 'header': {'date': '2016-06-12T12:52:44.380983', u'msg_id': u'51BC7D2045F34C1DBFB596E8921EC318', u'msg_type': u'execute_request', u'session': u'CEF40C66C22B4B51AB5041666FFC5A00', u'username': u'username', u'version': u'5.0'}, 'metadata': {}, 'msg_id': u'51BC7D2045F34C1DBFB596E8921EC318', 'msg_type': u'execute_request', 'parent_header': {}}\n    229             except Exception:\n    230                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    231             finally:\n    232                 self.post_handler_hook()\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=['CEF40C66C22B4B51AB5041666FFC5A00'], parent={'buffers': [], 'content': {u'allow_stdin': True, u'code': u'from sklearn.feature_selection import SelectKB...rams.best_score_)\\nsearch_params.best_estimator_', u'silent': False, u'stop_on_error': True, u'store_history': True, u'user_expressions': {}}, 'header': {'date': '2016-06-12T12:52:44.380983', u'msg_id': u'51BC7D2045F34C1DBFB596E8921EC318', u'msg_type': u'execute_request', u'session': u'CEF40C66C22B4B51AB5041666FFC5A00', u'username': u'username', u'version': u'5.0'}, 'metadata': {}, 'msg_id': u'51BC7D2045F34C1DBFB596E8921EC318', 'msg_type': u'execute_request', 'parent_header': {}})\n    386         if not silent:\n    387             self.execution_count += 1\n    388             self._publish_execute_input(code, parent, self.execution_count)\n    389 \n    390         reply_content = self.do_execute(code, silent, store_history,\n--> 391                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    392 \n    393         # Flush output before sending the reply.\n    394         sys.stdout.flush()\n    395         sys.stderr.flush()\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/ipykernel/ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code=u'from sklearn.feature_selection import SelectKB...rams.best_score_)\\nsearch_params.best_estimator_', silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    194 \n    195         reply_content = {}\n    196         # FIXME: the shell calls the exception handler itself.\n    197         shell._reply_content = None\n    198         try:\n--> 199             shell.run_cell(code, store_history=store_history, silent=silent)\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = u'from sklearn.feature_selection import SelectKB...rams.best_score_)\\nsearch_params.best_estimator_'\n        store_history = True\n        silent = False\n    200         except:\n    201             status = u'error'\n    202             # FIXME: this code right now isn't being used yet by default,\n    203             # because the run_cell() call above directly fires off exception\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell=u'from sklearn.feature_selection import SelectKB...rams.best_score_)\\nsearch_params.best_estimator_', store_history=True, silent=False, shell_futures=True)\n   2718                 self.displayhook.exec_result = result\n   2719 \n   2720                 # Execute the user code\n   2721                 interactivity = \"none\" if silent else self.ast_node_interactivity\n   2722                 self.run_ast_nodes(code_ast.body, cell_name,\n-> 2723                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler instance>\n   2724 \n   2725                 # Reset this so later displayed values do not modify the\n   2726                 # ExecutionResult\n   2727                 self.displayhook.exec_result = None\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.ImportFrom object>, <_ast.ImportFrom object>, <_ast.ImportFrom object>, <_ast.ImportFrom object>, <_ast.ImportFrom object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Expr object>, <_ast.Print object>, <_ast.Print object>, <_ast.Print object>, <_ast.Expr object>], cell_name='<ipython-input-31-77a67d18d2e5>', interactivity='last', compiler=<IPython.core.compilerop.CachingCompiler instance>, result=<IPython.core.interactiveshell.ExecutionResult object>)\n   2820 \n   2821         try:\n   2822             for i, node in enumerate(to_run_exec):\n   2823                 mod = ast.Module([node])\n   2824                 code = compiler(mod, cell_name, \"exec\")\n-> 2825                 if self.run_code(code, result):\n        self.run_code = <bound method ZMQInteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x7f99bfbd0a30, file \"<ipython-input-31-77a67d18d2e5>\", line 50>\n        result = <IPython.core.interactiveshell.ExecutionResult object>\n   2826                     return True\n   2827 \n   2828             for i, node in enumerate(to_run_interactive):\n   2829                 mod = ast.Interactive([node])\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x7f99bfbd0a30, file \"<ipython-input-31-77a67d18d2e5>\", line 50>, result=<IPython.core.interactiveshell.ExecutionResult object>)\n   2880         outflag = 1  # happens in more places, so it's easier as default\n   2881         try:\n   2882             try:\n   2883                 self.hooks.pre_run_code_hook()\n   2884                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2885                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x7f99bfbd0a30, file \"<ipython-input-31-77a67d18d2e5>\", line 50>\n        self.user_global_ns = {'AdaBoostRegressor': <class 'sklearn.ensemble.weight_boosting.AdaBoostRegressor'>, 'DecisionTreeRegressor': <class 'sklearn.tree.tree.DecisionTreeRegressor'>, 'EST_PICKLE_FILENAME': 'baseline_final_estimator.pkl', 'GridSearchCV': <class 'sklearn.grid_search.GridSearchCV'>, 'Imputer': <class 'sklearn.preprocessing.imputation.Imputer'>, 'In': ['', u'import pdb\\nimport numpy as np\\nimport gcp.big...ields_str.split(\\'\\\\t\\'))\\nfeatures = fields[1:]', u'def mape(X, predictions, y):\\n  num_timeslots ...or.predict(X)\\n  return -mape(X, predictions, y)', u'from sklearn.linear_model import LogisticRegre...\\n\\n# Should return 0.0\\nmape(X, predictions, y)', u'get_ipython().run_cell_magic(u\\'sql\\', u\\'--mo...\\n\\\\n# The above query randomizes its outputs.\")', u'query = bq.Query(q_all)\\ntableresult = query.results()', u\"all_data = np.zeros((tableresult.length, len(f...\\n    print 'processed {} rows'.format(rcounter)\", u'import pdb\\nimport numpy as np\\nimport gcp.big...ields_str.split(\\'\\\\t\\'))\\nfeatures = fields[1:]', u'def mape(X, predictions, y):\\n  num_timeslots ...or.predict(X)\\n  return -mape(X, predictions, y)', u'from sklearn.linear_model import LogisticRegre...\\n\\n# Should return 0.0\\nmape(X, predictions, y)', u'get_ipython().run_cell_magic(u\\'sql\\', u\\'--mo...\\n\\\\n# The above query randomizes its outputs.\")', u'query = bq.Query(q_all)\\ntableresult = query.results()', u\"all_data = np.zeros((tableresult.length, len(f...\\n    print 'processed {} rows'.format(rcounter)\", u'# Get timeslots to test from GCS\\nitem = stora...'\".format(x), timeslots_to_test))\\nprint(tquery)', u'get_ipython().run_cell_magic(u\\'sql\\', u\\'--mo... if estimator can generalize well to new data.\")', u'query_t = bq.Query(q_all_t)\\ntableresult_t = query_t.results()', u\"all_data_t = np.zeros((tableresult_t.length, l...\\n    print 'processed {} rows'.format(rcounter)\", u'# Useful code to check NaN and Inf values. Thi...l_data))\\nprint \"np.max=\", np.max(abs(all_data))', u'all_data[np.isnan(all_data)] = 0\\nall_data_t[np.isnan(all_data_t)] = 0', u'# Useful code to check NaN and Inf values. Thi...l_data))\\nprint \"np.max=\", np.max(abs(all_data))', ...], 'LogisticRegression': <class 'sklearn.linear_model.logistic.LogisticRegression'>, 'Out': {3: 0.0, 9: 0.0, 20: Pipeline(steps=[('estimate', DecisionTreeRegress...random_state=None,\n           splitter='best'))]), 24: Pipeline(steps=[('estimate', RandomForestRegress...=None,\n           verbose=0, warm_start=False))]), 27: Pipeline(steps=[('estimate', RandomForestRegress...=None,\n           verbose=0, warm_start=False))])}, 'Pipeline': <class 'sklearn.pipeline.Pipeline'>, 'RandomForestRegressor': <class 'sklearn.ensemble.forest.RandomForestRegressor'>, ...}\n        self.user_ns = {'AdaBoostRegressor': <class 'sklearn.ensemble.weight_boosting.AdaBoostRegressor'>, 'DecisionTreeRegressor': <class 'sklearn.tree.tree.DecisionTreeRegressor'>, 'EST_PICKLE_FILENAME': 'baseline_final_estimator.pkl', 'GridSearchCV': <class 'sklearn.grid_search.GridSearchCV'>, 'Imputer': <class 'sklearn.preprocessing.imputation.Imputer'>, 'In': ['', u'import pdb\\nimport numpy as np\\nimport gcp.big...ields_str.split(\\'\\\\t\\'))\\nfeatures = fields[1:]', u'def mape(X, predictions, y):\\n  num_timeslots ...or.predict(X)\\n  return -mape(X, predictions, y)', u'from sklearn.linear_model import LogisticRegre...\\n\\n# Should return 0.0\\nmape(X, predictions, y)', u'get_ipython().run_cell_magic(u\\'sql\\', u\\'--mo...\\n\\\\n# The above query randomizes its outputs.\")', u'query = bq.Query(q_all)\\ntableresult = query.results()', u\"all_data = np.zeros((tableresult.length, len(f...\\n    print 'processed {} rows'.format(rcounter)\", u'import pdb\\nimport numpy as np\\nimport gcp.big...ields_str.split(\\'\\\\t\\'))\\nfeatures = fields[1:]', u'def mape(X, predictions, y):\\n  num_timeslots ...or.predict(X)\\n  return -mape(X, predictions, y)', u'from sklearn.linear_model import LogisticRegre...\\n\\n# Should return 0.0\\nmape(X, predictions, y)', u'get_ipython().run_cell_magic(u\\'sql\\', u\\'--mo...\\n\\\\n# The above query randomizes its outputs.\")', u'query = bq.Query(q_all)\\ntableresult = query.results()', u\"all_data = np.zeros((tableresult.length, len(f...\\n    print 'processed {} rows'.format(rcounter)\", u'# Get timeslots to test from GCS\\nitem = stora...'\".format(x), timeslots_to_test))\\nprint(tquery)', u'get_ipython().run_cell_magic(u\\'sql\\', u\\'--mo... if estimator can generalize well to new data.\")', u'query_t = bq.Query(q_all_t)\\ntableresult_t = query_t.results()', u\"all_data_t = np.zeros((tableresult_t.length, l...\\n    print 'processed {} rows'.format(rcounter)\", u'# Useful code to check NaN and Inf values. Thi...l_data))\\nprint \"np.max=\", np.max(abs(all_data))', u'all_data[np.isnan(all_data)] = 0\\nall_data_t[np.isnan(all_data_t)] = 0', u'# Useful code to check NaN and Inf values. Thi...l_data))\\nprint \"np.max=\", np.max(abs(all_data))', ...], 'LogisticRegression': <class 'sklearn.linear_model.logistic.LogisticRegression'>, 'Out': {3: 0.0, 9: 0.0, 20: Pipeline(steps=[('estimate', DecisionTreeRegress...random_state=None,\n           splitter='best'))]), 24: Pipeline(steps=[('estimate', RandomForestRegress...=None,\n           verbose=0, warm_start=False))]), 27: Pipeline(steps=[('estimate', RandomForestRegress...=None,\n           verbose=0, warm_start=False))])}, 'Pipeline': <class 'sklearn.pipeline.Pipeline'>, 'RandomForestRegressor': <class 'sklearn.ensemble.forest.RandomForestRegressor'>, ...}\n   2886             finally:\n   2887                 # Reset our crash handler in place\n   2888                 sys.excepthook = old_excepthook\n   2889         except SystemExit as e:\n\n...........................................................................\n/content/TeguhWPurwanto@gmail.com/Xiaojukeji Algorithm Competition/<ipython-input-31-77a67d18d2e5> in <module>()\n     45   scoring=mape_scorer,\n     46   n_jobs=2,\n     47   verbose=1\n     48 )\n     49 \n---> 50 search_params.fit(data_train, targets_train)\n     51 print(search_params.grid_scores_)\n     52 print(search_params.best_params_)\n     53 print(search_params.best_score_)\n     54 search_params.best_estimator_\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/sklearn/grid_search.py in fit(self=GridSearchCV(cv=5, error_score='raise',\n       e...nction mape_scorer at 0x7f99d626d398>, verbose=1), X=array([[  17.,    3.,    0., ...,  106.,    1., ...[  56.,    5.,    0., ...,    0.,    0.,    4.]]), y=array([ 46.,  32.,  33., ...,   9.,  34.,  42.]))\n    727         y : array-like, shape = [n_samples] or [n_samples, n_output], optional\n    728             Target relative to X for classification or regression;\n    729             None for unsupervised learning.\n    730 \n    731         \"\"\"\n--> 732         return self._fit(X, y, ParameterGrid(self.param_grid))\n        self._fit = <bound method GridSearchCV._fit of GridSearchCV(...ction mape_scorer at 0x7f99d626d398>, verbose=1)>\n        X = array([[  17.,    3.,    0., ...,  106.,    1., ...[  56.,    5.,    0., ...,    0.,    0.,    4.]])\n        y = array([ 46.,  32.,  33., ...,   9.,  34.,  42.])\n        self.param_grid = {'estimate__n_estimators': [5, 10, 20, 50, 60, 80], 'estimate_learning_rate': [0.1, 0.3, 0.7, 1, 3, 5, 10]}\n    733 \n    734 \n    735 class RandomizedSearchCV(BaseSearchCV):\n    736     \"\"\"Randomized search on hyper parameters.\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/sklearn/grid_search.py in _fit(self=GridSearchCV(cv=5, error_score='raise',\n       e...nction mape_scorer at 0x7f99d626d398>, verbose=1), X=array([[  17.,    3.,    0., ...,  106.,    1., ...[  56.,    5.,    0., ...,    0.,    0.,    4.]]), y=array([ 46.,  32.,  33., ...,   9.,  34.,  42.]), parameter_iterable=<sklearn.grid_search.ParameterGrid object>)\n    500         )(\n    501             delayed(_fit_and_score)(clone(base_estimator), X, y, self.scorer_,\n    502                                     train, test, self.verbose, parameters,\n    503                                     self.fit_params, return_parameters=True,\n    504                                     error_score=self.error_score)\n--> 505                 for parameters in parameter_iterable\n        parameters = undefined\n        parameter_iterable = <sklearn.grid_search.ParameterGrid object>\n    506                 for train, test in cv)\n    507 \n    508         # Out is a list of triplet: score, estimator, n_test_samples\n    509         n_fits = len(out)\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=2), iterable=<itertools.islice object>)\n    661             if pre_dispatch == \"all\" or n_jobs == 1:\n    662                 # The iterable was consumed all at once by the above for loop.\n    663                 # No need to wait for async callbacks to trigger to\n    664                 # consumption.\n    665                 self._iterating = False\n--> 666             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=2)>\n    667             # Make sure that we get a last message telling us we are done\n    668             elapsed_time = time.time() - self._start_time\n    669             self._print('Done %3i out of %3i | elapsed: %s finished',\n    670                         (len(self._output),\n\n    ---------------------------------------------------------------------------\n    Sub-process traceback:\n    ---------------------------------------------------------------------------\n    ValueError                                         Sun Jun 12 12:52:44 2016\nPID: 4116                                     Python 2.7.9: /usr/bin/python\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/sklearn/cross_validation.pyc in _fit_and_score(estimator=Pipeline(steps=[('estimate', AdaBoostRegressor(b...,\n         n_estimators=50, random_state=None))]), X=array([[  17.,    3.,    0., ...,  106.,    1., ...[  56.,    5.,    0., ...,    0.,    0.,    4.]]), y=array([ 46.,  32.,  33., ...,   9.,  34.,  42.]), scorer=<function mape_scorer>, train=array([ 20536,  20537,  20538, ..., 102677, 102678, 102679]), test=array([    0,     1,     2, ..., 20533, 20534, 20535]), verbose=1, parameters={'estimate__n_estimators': 5, 'estimate_learning_rate': 0.1}, fit_params={}, return_train_score=False, return_parameters=True, error_score='raise')\n   1443     fit_params = fit_params if fit_params is not None else {}\n   1444     fit_params = dict([(k, _index_param_value(X, v, train))\n   1445                       for k, v in fit_params.items()])\n   1446 \n   1447     if parameters is not None:\n-> 1448         estimator.set_params(**parameters)\n   1449 \n   1450     start_time = time.time()\n   1451 \n   1452     X_train, y_train = _safe_split(estimator, X, y, train)\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/sklearn/base.pyc in set_params(self=Pipeline(steps=[('estimate', AdaBoostRegressor(b...,\n         n_estimators=50, random_state=None))]), **params={'estimate__n_estimators': 5, 'estimate_learning_rate': 0.1})\n    251                 sub_object.set_params(**{sub_name: value})\n    252             else:\n    253                 # simple objects case\n    254                 if not key in valid_params:\n    255                     raise ValueError('Invalid parameter %s ' 'for estimator %s'\n--> 256                                      % (key, self.__class__.__name__))\n    257                 setattr(self, key, value)\n    258         return self\n    259 \n    260     def __repr__(self):\n\nValueError: Invalid parameter estimate_learning_rate for estimator Pipeline\n___________________________________________________________________________",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m\u001b[0m",
      "\u001b[1;31mJoblibValueError\u001b[0mTraceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-77a67d18d2e5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     48\u001b[0m )\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 50\u001b[1;33m \u001b[0msearch_params\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     51\u001b[0m \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msearch_params\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrid_scores_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msearch_params\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/sklearn/grid_search.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    730\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    731\u001b[0m         \"\"\"\n\u001b[1;32m--> 732\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    733\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    734\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/sklearn/grid_search.pyc\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, parameter_iterable)\u001b[0m\n\u001b[0;32m    503\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_parameters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    504\u001b[0m                                     error_score=self.error_score)\n\u001b[1;32m--> 505\u001b[1;33m                 \u001b[1;32mfor\u001b[0m \u001b[0mparameters\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mparameter_iterable\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    506\u001b[0m                 for train, test in cv)\n\u001b[0;32m    507\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    664\u001b[0m                 \u001b[1;31m# consumption.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    665\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 666\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    667\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    668\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    547\u001b[0m                         \u001b[1;31m# Convert this to a JoblibException\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    548\u001b[0m                         \u001b[0mexception_type\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_mk_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexception\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0metype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 549\u001b[1;33m                         \u001b[1;32mraise\u001b[0m \u001b[0mexception_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreport\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    550\u001b[0m                     \u001b[1;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    551\u001b[0m                 \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mJoblibValueError\u001b[0m: JoblibValueError\n___________________________________________________________________________\nMultiprocessing exception:\n    ...........................................................................\n/usr/lib/python2.7/runpy.py in _run_module_as_main(mod_name='ipykernel.__main__', alter_argv=1)\n    157     pkg_name = mod_name.rpartition('.')[0]\n    158     main_globals = sys.modules[\"__main__\"].__dict__\n    159     if alter_argv:\n    160         sys.argv[0] = fname\n    161     return _run_code(code, main_globals, None,\n--> 162                      \"__main__\", fname, loader, pkg_name)\n        fname = '/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py'\n        loader = <pkgutil.ImpLoader instance>\n        pkg_name = 'ipykernel'\n    163 \n    164 def run_module(mod_name, init_globals=None,\n    165                run_name=None, alter_sys=False):\n    166     \"\"\"Execute a module's code without importing it\n\n...........................................................................\n/usr/lib/python2.7/runpy.py in _run_code(code=<code object <module> at 0x7f99f453b330, file \"/...2.7/dist-packages/ipykernel/__main__.py\", line 1>, run_globals={'__builtins__': <module '__builtin__' (built-in)>, '__doc__': None, '__file__': '/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py', '__loader__': <pkgutil.ImpLoader instance>, '__name__': '__main__', '__package__': 'ipykernel', 'app': <module 'ipykernel.kernelapp' from '/usr/local/lib/python2.7/dist-packages/ipykernel/kernelapp.pyc'>}, init_globals=None, mod_name='__main__', mod_fname='/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py', mod_loader=<pkgutil.ImpLoader instance>, pkg_name='ipykernel')\n     67         run_globals.update(init_globals)\n     68     run_globals.update(__name__ = mod_name,\n     69                        __file__ = mod_fname,\n     70                        __loader__ = mod_loader,\n     71                        __package__ = pkg_name)\n---> 72     exec code in run_globals\n        code = <code object <module> at 0x7f99f453b330, file \"/...2.7/dist-packages/ipykernel/__main__.py\", line 1>\n        run_globals = {'__builtins__': <module '__builtin__' (built-in)>, '__doc__': None, '__file__': '/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py', '__loader__': <pkgutil.ImpLoader instance>, '__name__': '__main__', '__package__': 'ipykernel', 'app': <module 'ipykernel.kernelapp' from '/usr/local/lib/python2.7/dist-packages/ipykernel/kernelapp.pyc'>}\n     73     return run_globals\n     74 \n     75 def _run_module_code(code, init_globals=None,\n     76                     mod_name=None, mod_fname=None,\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py in <module>()\n      1 \n      2 \n----> 3 \n      4 if __name__ == '__main__':\n      5     from ipykernel import kernelapp as app\n      6     app.launch_new_instance()\n      7 \n      8 \n      9 \n     10 \n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/traitlets/config/application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    591         \n    592         If a global instance already exists, this reinitializes and starts it\n    593         \"\"\"\n    594         app = cls.instance(**kwargs)\n    595         app.initialize(argv)\n--> 596         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    597 \n    598 #-----------------------------------------------------------------------------\n    599 # utility functions, for convenience\n    600 #-----------------------------------------------------------------------------\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/ipykernel/kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    437         \n    438         if self.poller is not None:\n    439             self.poller.start()\n    440         self.kernel.start()\n    441         try:\n--> 442             ioloop.IOLoop.instance().start()\n    443         except KeyboardInterrupt:\n    444             pass\n    445 \n    446 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/zmq/eventloop/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    157             PollIOLoop.configure(ZMQIOLoop)\n    158         return PollIOLoop.current(*args, **kwargs)\n    159     \n    160     def start(self):\n    161         try:\n--> 162             super(ZMQIOLoop, self).start()\n        self.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    163         except ZMQError as e:\n    164             if e.errno == ETERM:\n    165                 # quietly return on ETERM\n    166                 pass\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/tornado/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    878                 self._events.update(event_pairs)\n    879                 while self._events:\n    880                     fd, events = self._events.popitem()\n    881                     try:\n    882                         fd_obj, handler_func = self._handlers[fd]\n--> 883                         handler_func(fd_obj, events)\n        handler_func = <function null_wrapper>\n        fd_obj = <zmq.sugar.socket.Socket object>\n        events = 1\n    884                     except (OSError, IOError) as e:\n    885                         if errno_from_exception(e) == errno.EPIPE:\n    886                             # Happens when the client closes the connection\n    887                             pass\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/tornado/stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    270         # Fast path when there are no active contexts.\n    271         def null_wrapper(*args, **kwargs):\n    272             try:\n    273                 current_state = _state.contexts\n    274                 _state.contexts = cap_contexts[0]\n--> 275                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    276             finally:\n    277                 _state.contexts = current_state\n    278         null_wrapper._wrapped = True\n    279         return null_wrapper\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    435             # dispatch events:\n    436             if events & IOLoop.ERROR:\n    437                 gen_log.error(\"got POLLERR event on ZMQStream, which doesn't make sense\")\n    438                 return\n    439             if events & IOLoop.READ:\n--> 440                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    441                 if not self.socket:\n    442                     return\n    443             if events & IOLoop.WRITE:\n    444                 self._handle_send()\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    467                 gen_log.error(\"RECV Error: %s\"%zmq.strerror(e.errno))\n    468         else:\n    469             if self._recv_callback:\n    470                 callback = self._recv_callback\n    471                 # self._recv_callback = None\n--> 472                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    473                 \n    474         # self.update_state()\n    475         \n    476 \n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    409         close our socket.\"\"\"\n    410         try:\n    411             # Use a NullContext to ensure that all StackContexts are run\n    412             # inside our blanket exception handler rather than outside.\n    413             with stack_context.NullContext():\n--> 414                 callback(*args, **kwargs)\n        callback = <function null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    415         except:\n    416             gen_log.error(\"Uncaught exception, closing connection.\",\n    417                           exc_info=True)\n    418             # Close the socket on an uncaught exception from a user callback\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/tornado/stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    270         # Fast path when there are no active contexts.\n    271         def null_wrapper(*args, **kwargs):\n    272             try:\n    273                 current_state = _state.contexts\n    274                 _state.contexts = cap_contexts[0]\n--> 275                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    276             finally:\n    277                 _state.contexts = current_state\n    278         null_wrapper._wrapped = True\n    279         return null_wrapper\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    271         if self.control_stream:\n    272             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    273 \n    274         def make_dispatcher(stream):\n    275             def dispatcher(msg):\n--> 276                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    277             return dispatcher\n    278 \n    279         for s in self.shell_streams:\n    280             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {u'allow_stdin': True, u'code': u'from sklearn.feature_selection import SelectKB...rams.best_score_)\\nsearch_params.best_estimator_', u'silent': False, u'stop_on_error': True, u'store_history': True, u'user_expressions': {}}, 'header': {'date': '2016-06-12T12:52:44.380983', u'msg_id': u'51BC7D2045F34C1DBFB596E8921EC318', u'msg_type': u'execute_request', u'session': u'CEF40C66C22B4B51AB5041666FFC5A00', u'username': u'username', u'version': u'5.0'}, 'metadata': {}, 'msg_id': u'51BC7D2045F34C1DBFB596E8921EC318', 'msg_type': u'execute_request', 'parent_header': {}})\n    223             self.log.error(\"UNKNOWN MESSAGE TYPE: %r\", msg_type)\n    224         else:\n    225             self.log.debug(\"%s: %s\", msg_type, msg)\n    226             self.pre_handler_hook()\n    227             try:\n--> 228                 handler(stream, idents, msg)\n        handler = <bound method IPythonKernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = ['CEF40C66C22B4B51AB5041666FFC5A00']\n        msg = {'buffers': [], 'content': {u'allow_stdin': True, u'code': u'from sklearn.feature_selection import SelectKB...rams.best_score_)\\nsearch_params.best_estimator_', u'silent': False, u'stop_on_error': True, u'store_history': True, u'user_expressions': {}}, 'header': {'date': '2016-06-12T12:52:44.380983', u'msg_id': u'51BC7D2045F34C1DBFB596E8921EC318', u'msg_type': u'execute_request', u'session': u'CEF40C66C22B4B51AB5041666FFC5A00', u'username': u'username', u'version': u'5.0'}, 'metadata': {}, 'msg_id': u'51BC7D2045F34C1DBFB596E8921EC318', 'msg_type': u'execute_request', 'parent_header': {}}\n    229             except Exception:\n    230                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    231             finally:\n    232                 self.post_handler_hook()\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=['CEF40C66C22B4B51AB5041666FFC5A00'], parent={'buffers': [], 'content': {u'allow_stdin': True, u'code': u'from sklearn.feature_selection import SelectKB...rams.best_score_)\\nsearch_params.best_estimator_', u'silent': False, u'stop_on_error': True, u'store_history': True, u'user_expressions': {}}, 'header': {'date': '2016-06-12T12:52:44.380983', u'msg_id': u'51BC7D2045F34C1DBFB596E8921EC318', u'msg_type': u'execute_request', u'session': u'CEF40C66C22B4B51AB5041666FFC5A00', u'username': u'username', u'version': u'5.0'}, 'metadata': {}, 'msg_id': u'51BC7D2045F34C1DBFB596E8921EC318', 'msg_type': u'execute_request', 'parent_header': {}})\n    386         if not silent:\n    387             self.execution_count += 1\n    388             self._publish_execute_input(code, parent, self.execution_count)\n    389 \n    390         reply_content = self.do_execute(code, silent, store_history,\n--> 391                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    392 \n    393         # Flush output before sending the reply.\n    394         sys.stdout.flush()\n    395         sys.stderr.flush()\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/ipykernel/ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code=u'from sklearn.feature_selection import SelectKB...rams.best_score_)\\nsearch_params.best_estimator_', silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    194 \n    195         reply_content = {}\n    196         # FIXME: the shell calls the exception handler itself.\n    197         shell._reply_content = None\n    198         try:\n--> 199             shell.run_cell(code, store_history=store_history, silent=silent)\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = u'from sklearn.feature_selection import SelectKB...rams.best_score_)\\nsearch_params.best_estimator_'\n        store_history = True\n        silent = False\n    200         except:\n    201             status = u'error'\n    202             # FIXME: this code right now isn't being used yet by default,\n    203             # because the run_cell() call above directly fires off exception\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell=u'from sklearn.feature_selection import SelectKB...rams.best_score_)\\nsearch_params.best_estimator_', store_history=True, silent=False, shell_futures=True)\n   2718                 self.displayhook.exec_result = result\n   2719 \n   2720                 # Execute the user code\n   2721                 interactivity = \"none\" if silent else self.ast_node_interactivity\n   2722                 self.run_ast_nodes(code_ast.body, cell_name,\n-> 2723                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler instance>\n   2724 \n   2725                 # Reset this so later displayed values do not modify the\n   2726                 # ExecutionResult\n   2727                 self.displayhook.exec_result = None\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.ImportFrom object>, <_ast.ImportFrom object>, <_ast.ImportFrom object>, <_ast.ImportFrom object>, <_ast.ImportFrom object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Expr object>, <_ast.Print object>, <_ast.Print object>, <_ast.Print object>, <_ast.Expr object>], cell_name='<ipython-input-31-77a67d18d2e5>', interactivity='last', compiler=<IPython.core.compilerop.CachingCompiler instance>, result=<IPython.core.interactiveshell.ExecutionResult object>)\n   2820 \n   2821         try:\n   2822             for i, node in enumerate(to_run_exec):\n   2823                 mod = ast.Module([node])\n   2824                 code = compiler(mod, cell_name, \"exec\")\n-> 2825                 if self.run_code(code, result):\n        self.run_code = <bound method ZMQInteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x7f99bfbd0a30, file \"<ipython-input-31-77a67d18d2e5>\", line 50>\n        result = <IPython.core.interactiveshell.ExecutionResult object>\n   2826                     return True\n   2827 \n   2828             for i, node in enumerate(to_run_interactive):\n   2829                 mod = ast.Interactive([node])\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x7f99bfbd0a30, file \"<ipython-input-31-77a67d18d2e5>\", line 50>, result=<IPython.core.interactiveshell.ExecutionResult object>)\n   2880         outflag = 1  # happens in more places, so it's easier as default\n   2881         try:\n   2882             try:\n   2883                 self.hooks.pre_run_code_hook()\n   2884                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2885                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x7f99bfbd0a30, file \"<ipython-input-31-77a67d18d2e5>\", line 50>\n        self.user_global_ns = {'AdaBoostRegressor': <class 'sklearn.ensemble.weight_boosting.AdaBoostRegressor'>, 'DecisionTreeRegressor': <class 'sklearn.tree.tree.DecisionTreeRegressor'>, 'EST_PICKLE_FILENAME': 'baseline_final_estimator.pkl', 'GridSearchCV': <class 'sklearn.grid_search.GridSearchCV'>, 'Imputer': <class 'sklearn.preprocessing.imputation.Imputer'>, 'In': ['', u'import pdb\\nimport numpy as np\\nimport gcp.big...ields_str.split(\\'\\\\t\\'))\\nfeatures = fields[1:]', u'def mape(X, predictions, y):\\n  num_timeslots ...or.predict(X)\\n  return -mape(X, predictions, y)', u'from sklearn.linear_model import LogisticRegre...\\n\\n# Should return 0.0\\nmape(X, predictions, y)', u'get_ipython().run_cell_magic(u\\'sql\\', u\\'--mo...\\n\\\\n# The above query randomizes its outputs.\")', u'query = bq.Query(q_all)\\ntableresult = query.results()', u\"all_data = np.zeros((tableresult.length, len(f...\\n    print 'processed {} rows'.format(rcounter)\", u'import pdb\\nimport numpy as np\\nimport gcp.big...ields_str.split(\\'\\\\t\\'))\\nfeatures = fields[1:]', u'def mape(X, predictions, y):\\n  num_timeslots ...or.predict(X)\\n  return -mape(X, predictions, y)', u'from sklearn.linear_model import LogisticRegre...\\n\\n# Should return 0.0\\nmape(X, predictions, y)', u'get_ipython().run_cell_magic(u\\'sql\\', u\\'--mo...\\n\\\\n# The above query randomizes its outputs.\")', u'query = bq.Query(q_all)\\ntableresult = query.results()', u\"all_data = np.zeros((tableresult.length, len(f...\\n    print 'processed {} rows'.format(rcounter)\", u'# Get timeslots to test from GCS\\nitem = stora...'\".format(x), timeslots_to_test))\\nprint(tquery)', u'get_ipython().run_cell_magic(u\\'sql\\', u\\'--mo... if estimator can generalize well to new data.\")', u'query_t = bq.Query(q_all_t)\\ntableresult_t = query_t.results()', u\"all_data_t = np.zeros((tableresult_t.length, l...\\n    print 'processed {} rows'.format(rcounter)\", u'# Useful code to check NaN and Inf values. Thi...l_data))\\nprint \"np.max=\", np.max(abs(all_data))', u'all_data[np.isnan(all_data)] = 0\\nall_data_t[np.isnan(all_data_t)] = 0', u'# Useful code to check NaN and Inf values. Thi...l_data))\\nprint \"np.max=\", np.max(abs(all_data))', ...], 'LogisticRegression': <class 'sklearn.linear_model.logistic.LogisticRegression'>, 'Out': {3: 0.0, 9: 0.0, 20: Pipeline(steps=[('estimate', DecisionTreeRegress...random_state=None,\n           splitter='best'))]), 24: Pipeline(steps=[('estimate', RandomForestRegress...=None,\n           verbose=0, warm_start=False))]), 27: Pipeline(steps=[('estimate', RandomForestRegress...=None,\n           verbose=0, warm_start=False))])}, 'Pipeline': <class 'sklearn.pipeline.Pipeline'>, 'RandomForestRegressor': <class 'sklearn.ensemble.forest.RandomForestRegressor'>, ...}\n        self.user_ns = {'AdaBoostRegressor': <class 'sklearn.ensemble.weight_boosting.AdaBoostRegressor'>, 'DecisionTreeRegressor': <class 'sklearn.tree.tree.DecisionTreeRegressor'>, 'EST_PICKLE_FILENAME': 'baseline_final_estimator.pkl', 'GridSearchCV': <class 'sklearn.grid_search.GridSearchCV'>, 'Imputer': <class 'sklearn.preprocessing.imputation.Imputer'>, 'In': ['', u'import pdb\\nimport numpy as np\\nimport gcp.big...ields_str.split(\\'\\\\t\\'))\\nfeatures = fields[1:]', u'def mape(X, predictions, y):\\n  num_timeslots ...or.predict(X)\\n  return -mape(X, predictions, y)', u'from sklearn.linear_model import LogisticRegre...\\n\\n# Should return 0.0\\nmape(X, predictions, y)', u'get_ipython().run_cell_magic(u\\'sql\\', u\\'--mo...\\n\\\\n# The above query randomizes its outputs.\")', u'query = bq.Query(q_all)\\ntableresult = query.results()', u\"all_data = np.zeros((tableresult.length, len(f...\\n    print 'processed {} rows'.format(rcounter)\", u'import pdb\\nimport numpy as np\\nimport gcp.big...ields_str.split(\\'\\\\t\\'))\\nfeatures = fields[1:]', u'def mape(X, predictions, y):\\n  num_timeslots ...or.predict(X)\\n  return -mape(X, predictions, y)', u'from sklearn.linear_model import LogisticRegre...\\n\\n# Should return 0.0\\nmape(X, predictions, y)', u'get_ipython().run_cell_magic(u\\'sql\\', u\\'--mo...\\n\\\\n# The above query randomizes its outputs.\")', u'query = bq.Query(q_all)\\ntableresult = query.results()', u\"all_data = np.zeros((tableresult.length, len(f...\\n    print 'processed {} rows'.format(rcounter)\", u'# Get timeslots to test from GCS\\nitem = stora...'\".format(x), timeslots_to_test))\\nprint(tquery)', u'get_ipython().run_cell_magic(u\\'sql\\', u\\'--mo... if estimator can generalize well to new data.\")', u'query_t = bq.Query(q_all_t)\\ntableresult_t = query_t.results()', u\"all_data_t = np.zeros((tableresult_t.length, l...\\n    print 'processed {} rows'.format(rcounter)\", u'# Useful code to check NaN and Inf values. Thi...l_data))\\nprint \"np.max=\", np.max(abs(all_data))', u'all_data[np.isnan(all_data)] = 0\\nall_data_t[np.isnan(all_data_t)] = 0', u'# Useful code to check NaN and Inf values. Thi...l_data))\\nprint \"np.max=\", np.max(abs(all_data))', ...], 'LogisticRegression': <class 'sklearn.linear_model.logistic.LogisticRegression'>, 'Out': {3: 0.0, 9: 0.0, 20: Pipeline(steps=[('estimate', DecisionTreeRegress...random_state=None,\n           splitter='best'))]), 24: Pipeline(steps=[('estimate', RandomForestRegress...=None,\n           verbose=0, warm_start=False))]), 27: Pipeline(steps=[('estimate', RandomForestRegress...=None,\n           verbose=0, warm_start=False))])}, 'Pipeline': <class 'sklearn.pipeline.Pipeline'>, 'RandomForestRegressor': <class 'sklearn.ensemble.forest.RandomForestRegressor'>, ...}\n   2886             finally:\n   2887                 # Reset our crash handler in place\n   2888                 sys.excepthook = old_excepthook\n   2889         except SystemExit as e:\n\n...........................................................................\n/content/TeguhWPurwanto@gmail.com/Xiaojukeji Algorithm Competition/<ipython-input-31-77a67d18d2e5> in <module>()\n     45   scoring=mape_scorer,\n     46   n_jobs=2,\n     47   verbose=1\n     48 )\n     49 \n---> 50 search_params.fit(data_train, targets_train)\n     51 print(search_params.grid_scores_)\n     52 print(search_params.best_params_)\n     53 print(search_params.best_score_)\n     54 search_params.best_estimator_\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/sklearn/grid_search.py in fit(self=GridSearchCV(cv=5, error_score='raise',\n       e...nction mape_scorer at 0x7f99d626d398>, verbose=1), X=array([[  17.,    3.,    0., ...,  106.,    1., ...[  56.,    5.,    0., ...,    0.,    0.,    4.]]), y=array([ 46.,  32.,  33., ...,   9.,  34.,  42.]))\n    727         y : array-like, shape = [n_samples] or [n_samples, n_output], optional\n    728             Target relative to X for classification or regression;\n    729             None for unsupervised learning.\n    730 \n    731         \"\"\"\n--> 732         return self._fit(X, y, ParameterGrid(self.param_grid))\n        self._fit = <bound method GridSearchCV._fit of GridSearchCV(...ction mape_scorer at 0x7f99d626d398>, verbose=1)>\n        X = array([[  17.,    3.,    0., ...,  106.,    1., ...[  56.,    5.,    0., ...,    0.,    0.,    4.]])\n        y = array([ 46.,  32.,  33., ...,   9.,  34.,  42.])\n        self.param_grid = {'estimate__n_estimators': [5, 10, 20, 50, 60, 80], 'estimate_learning_rate': [0.1, 0.3, 0.7, 1, 3, 5, 10]}\n    733 \n    734 \n    735 class RandomizedSearchCV(BaseSearchCV):\n    736     \"\"\"Randomized search on hyper parameters.\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/sklearn/grid_search.py in _fit(self=GridSearchCV(cv=5, error_score='raise',\n       e...nction mape_scorer at 0x7f99d626d398>, verbose=1), X=array([[  17.,    3.,    0., ...,  106.,    1., ...[  56.,    5.,    0., ...,    0.,    0.,    4.]]), y=array([ 46.,  32.,  33., ...,   9.,  34.,  42.]), parameter_iterable=<sklearn.grid_search.ParameterGrid object>)\n    500         )(\n    501             delayed(_fit_and_score)(clone(base_estimator), X, y, self.scorer_,\n    502                                     train, test, self.verbose, parameters,\n    503                                     self.fit_params, return_parameters=True,\n    504                                     error_score=self.error_score)\n--> 505                 for parameters in parameter_iterable\n        parameters = undefined\n        parameter_iterable = <sklearn.grid_search.ParameterGrid object>\n    506                 for train, test in cv)\n    507 \n    508         # Out is a list of triplet: score, estimator, n_test_samples\n    509         n_fits = len(out)\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=2), iterable=<itertools.islice object>)\n    661             if pre_dispatch == \"all\" or n_jobs == 1:\n    662                 # The iterable was consumed all at once by the above for loop.\n    663                 # No need to wait for async callbacks to trigger to\n    664                 # consumption.\n    665                 self._iterating = False\n--> 666             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=2)>\n    667             # Make sure that we get a last message telling us we are done\n    668             elapsed_time = time.time() - self._start_time\n    669             self._print('Done %3i out of %3i | elapsed: %s finished',\n    670                         (len(self._output),\n\n    ---------------------------------------------------------------------------\n    Sub-process traceback:\n    ---------------------------------------------------------------------------\n    ValueError                                         Sun Jun 12 12:52:44 2016\nPID: 4116                                     Python 2.7.9: /usr/bin/python\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/sklearn/cross_validation.pyc in _fit_and_score(estimator=Pipeline(steps=[('estimate', AdaBoostRegressor(b...,\n         n_estimators=50, random_state=None))]), X=array([[  17.,    3.,    0., ...,  106.,    1., ...[  56.,    5.,    0., ...,    0.,    0.,    4.]]), y=array([ 46.,  32.,  33., ...,   9.,  34.,  42.]), scorer=<function mape_scorer>, train=array([ 20536,  20537,  20538, ..., 102677, 102678, 102679]), test=array([    0,     1,     2, ..., 20533, 20534, 20535]), verbose=1, parameters={'estimate__n_estimators': 5, 'estimate_learning_rate': 0.1}, fit_params={}, return_train_score=False, return_parameters=True, error_score='raise')\n   1443     fit_params = fit_params if fit_params is not None else {}\n   1444     fit_params = dict([(k, _index_param_value(X, v, train))\n   1445                       for k, v in fit_params.items()])\n   1446 \n   1447     if parameters is not None:\n-> 1448         estimator.set_params(**parameters)\n   1449 \n   1450     start_time = time.time()\n   1451 \n   1452     X_train, y_train = _safe_split(estimator, X, y, train)\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/sklearn/base.pyc in set_params(self=Pipeline(steps=[('estimate', AdaBoostRegressor(b...,\n         n_estimators=50, random_state=None))]), **params={'estimate__n_estimators': 5, 'estimate_learning_rate': 0.1})\n    251                 sub_object.set_params(**{sub_name: value})\n    252             else:\n    253                 # simple objects case\n    254                 if not key in valid_params:\n    255                     raise ValueError('Invalid parameter %s ' 'for estimator %s'\n--> 256                                      % (key, self.__class__.__name__))\n    257                 setattr(self, key, value)\n    258         return self\n    259 \n    260     def __repr__(self):\n\nValueError: Invalid parameter estimate_learning_rate for estimator Pipeline\n___________________________________________________________________________"
     ]
    },
    {
     "ename": "JoblibValueError",
     "evalue": "JoblibValueError\n___________________________________________________________________________\nMultiprocessing exception:\n    ...........................................................................\n/usr/lib/python2.7/runpy.py in _run_module_as_main(mod_name='ipykernel.__main__', alter_argv=1)\n    157     pkg_name = mod_name.rpartition('.')[0]\n    158     main_globals = sys.modules[\"__main__\"].__dict__\n    159     if alter_argv:\n    160         sys.argv[0] = fname\n    161     return _run_code(code, main_globals, None,\n--> 162                      \"__main__\", fname, loader, pkg_name)\n        fname = '/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py'\n        loader = <pkgutil.ImpLoader instance>\n        pkg_name = 'ipykernel'\n    163 \n    164 def run_module(mod_name, init_globals=None,\n    165                run_name=None, alter_sys=False):\n    166     \"\"\"Execute a module's code without importing it\n\n...........................................................................\n/usr/lib/python2.7/runpy.py in _run_code(code=<code object <module> at 0x7f99f453b330, file \"/...2.7/dist-packages/ipykernel/__main__.py\", line 1>, run_globals={'__builtins__': <module '__builtin__' (built-in)>, '__doc__': None, '__file__': '/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py', '__loader__': <pkgutil.ImpLoader instance>, '__name__': '__main__', '__package__': 'ipykernel', 'app': <module 'ipykernel.kernelapp' from '/usr/local/lib/python2.7/dist-packages/ipykernel/kernelapp.pyc'>}, init_globals=None, mod_name='__main__', mod_fname='/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py', mod_loader=<pkgutil.ImpLoader instance>, pkg_name='ipykernel')\n     67         run_globals.update(init_globals)\n     68     run_globals.update(__name__ = mod_name,\n     69                        __file__ = mod_fname,\n     70                        __loader__ = mod_loader,\n     71                        __package__ = pkg_name)\n---> 72     exec code in run_globals\n        code = <code object <module> at 0x7f99f453b330, file \"/...2.7/dist-packages/ipykernel/__main__.py\", line 1>\n        run_globals = {'__builtins__': <module '__builtin__' (built-in)>, '__doc__': None, '__file__': '/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py', '__loader__': <pkgutil.ImpLoader instance>, '__name__': '__main__', '__package__': 'ipykernel', 'app': <module 'ipykernel.kernelapp' from '/usr/local/lib/python2.7/dist-packages/ipykernel/kernelapp.pyc'>}\n     73     return run_globals\n     74 \n     75 def _run_module_code(code, init_globals=None,\n     76                     mod_name=None, mod_fname=None,\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py in <module>()\n      1 \n      2 \n----> 3 \n      4 if __name__ == '__main__':\n      5     from ipykernel import kernelapp as app\n      6     app.launch_new_instance()\n      7 \n      8 \n      9 \n     10 \n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/traitlets/config/application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    591         \n    592         If a global instance already exists, this reinitializes and starts it\n    593         \"\"\"\n    594         app = cls.instance(**kwargs)\n    595         app.initialize(argv)\n--> 596         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    597 \n    598 #-----------------------------------------------------------------------------\n    599 # utility functions, for convenience\n    600 #-----------------------------------------------------------------------------\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/ipykernel/kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    437         \n    438         if self.poller is not None:\n    439             self.poller.start()\n    440         self.kernel.start()\n    441         try:\n--> 442             ioloop.IOLoop.instance().start()\n    443         except KeyboardInterrupt:\n    444             pass\n    445 \n    446 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/zmq/eventloop/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    157             PollIOLoop.configure(ZMQIOLoop)\n    158         return PollIOLoop.current(*args, **kwargs)\n    159     \n    160     def start(self):\n    161         try:\n--> 162             super(ZMQIOLoop, self).start()\n        self.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    163         except ZMQError as e:\n    164             if e.errno == ETERM:\n    165                 # quietly return on ETERM\n    166                 pass\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/tornado/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    878                 self._events.update(event_pairs)\n    879                 while self._events:\n    880                     fd, events = self._events.popitem()\n    881                     try:\n    882                         fd_obj, handler_func = self._handlers[fd]\n--> 883                         handler_func(fd_obj, events)\n        handler_func = <function null_wrapper>\n        fd_obj = <zmq.sugar.socket.Socket object>\n        events = 1\n    884                     except (OSError, IOError) as e:\n    885                         if errno_from_exception(e) == errno.EPIPE:\n    886                             # Happens when the client closes the connection\n    887                             pass\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/tornado/stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    270         # Fast path when there are no active contexts.\n    271         def null_wrapper(*args, **kwargs):\n    272             try:\n    273                 current_state = _state.contexts\n    274                 _state.contexts = cap_contexts[0]\n--> 275                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    276             finally:\n    277                 _state.contexts = current_state\n    278         null_wrapper._wrapped = True\n    279         return null_wrapper\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    435             # dispatch events:\n    436             if events & IOLoop.ERROR:\n    437                 gen_log.error(\"got POLLERR event on ZMQStream, which doesn't make sense\")\n    438                 return\n    439             if events & IOLoop.READ:\n--> 440                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    441                 if not self.socket:\n    442                     return\n    443             if events & IOLoop.WRITE:\n    444                 self._handle_send()\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    467                 gen_log.error(\"RECV Error: %s\"%zmq.strerror(e.errno))\n    468         else:\n    469             if self._recv_callback:\n    470                 callback = self._recv_callback\n    471                 # self._recv_callback = None\n--> 472                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    473                 \n    474         # self.update_state()\n    475         \n    476 \n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    409         close our socket.\"\"\"\n    410         try:\n    411             # Use a NullContext to ensure that all StackContexts are run\n    412             # inside our blanket exception handler rather than outside.\n    413             with stack_context.NullContext():\n--> 414                 callback(*args, **kwargs)\n        callback = <function null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    415         except:\n    416             gen_log.error(\"Uncaught exception, closing connection.\",\n    417                           exc_info=True)\n    418             # Close the socket on an uncaught exception from a user callback\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/tornado/stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    270         # Fast path when there are no active contexts.\n    271         def null_wrapper(*args, **kwargs):\n    272             try:\n    273                 current_state = _state.contexts\n    274                 _state.contexts = cap_contexts[0]\n--> 275                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    276             finally:\n    277                 _state.contexts = current_state\n    278         null_wrapper._wrapped = True\n    279         return null_wrapper\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    271         if self.control_stream:\n    272             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    273 \n    274         def make_dispatcher(stream):\n    275             def dispatcher(msg):\n--> 276                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    277             return dispatcher\n    278 \n    279         for s in self.shell_streams:\n    280             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {u'allow_stdin': True, u'code': u'from sklearn.feature_selection import SelectKB...rams.best_score_)\\nsearch_params.best_estimator_', u'silent': False, u'stop_on_error': True, u'store_history': True, u'user_expressions': {}}, 'header': {'date': '2016-06-12T12:52:44.380983', u'msg_id': u'51BC7D2045F34C1DBFB596E8921EC318', u'msg_type': u'execute_request', u'session': u'CEF40C66C22B4B51AB5041666FFC5A00', u'username': u'username', u'version': u'5.0'}, 'metadata': {}, 'msg_id': u'51BC7D2045F34C1DBFB596E8921EC318', 'msg_type': u'execute_request', 'parent_header': {}})\n    223             self.log.error(\"UNKNOWN MESSAGE TYPE: %r\", msg_type)\n    224         else:\n    225             self.log.debug(\"%s: %s\", msg_type, msg)\n    226             self.pre_handler_hook()\n    227             try:\n--> 228                 handler(stream, idents, msg)\n        handler = <bound method IPythonKernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = ['CEF40C66C22B4B51AB5041666FFC5A00']\n        msg = {'buffers': [], 'content': {u'allow_stdin': True, u'code': u'from sklearn.feature_selection import SelectKB...rams.best_score_)\\nsearch_params.best_estimator_', u'silent': False, u'stop_on_error': True, u'store_history': True, u'user_expressions': {}}, 'header': {'date': '2016-06-12T12:52:44.380983', u'msg_id': u'51BC7D2045F34C1DBFB596E8921EC318', u'msg_type': u'execute_request', u'session': u'CEF40C66C22B4B51AB5041666FFC5A00', u'username': u'username', u'version': u'5.0'}, 'metadata': {}, 'msg_id': u'51BC7D2045F34C1DBFB596E8921EC318', 'msg_type': u'execute_request', 'parent_header': {}}\n    229             except Exception:\n    230                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    231             finally:\n    232                 self.post_handler_hook()\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=['CEF40C66C22B4B51AB5041666FFC5A00'], parent={'buffers': [], 'content': {u'allow_stdin': True, u'code': u'from sklearn.feature_selection import SelectKB...rams.best_score_)\\nsearch_params.best_estimator_', u'silent': False, u'stop_on_error': True, u'store_history': True, u'user_expressions': {}}, 'header': {'date': '2016-06-12T12:52:44.380983', u'msg_id': u'51BC7D2045F34C1DBFB596E8921EC318', u'msg_type': u'execute_request', u'session': u'CEF40C66C22B4B51AB5041666FFC5A00', u'username': u'username', u'version': u'5.0'}, 'metadata': {}, 'msg_id': u'51BC7D2045F34C1DBFB596E8921EC318', 'msg_type': u'execute_request', 'parent_header': {}})\n    386         if not silent:\n    387             self.execution_count += 1\n    388             self._publish_execute_input(code, parent, self.execution_count)\n    389 \n    390         reply_content = self.do_execute(code, silent, store_history,\n--> 391                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    392 \n    393         # Flush output before sending the reply.\n    394         sys.stdout.flush()\n    395         sys.stderr.flush()\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/ipykernel/ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code=u'from sklearn.feature_selection import SelectKB...rams.best_score_)\\nsearch_params.best_estimator_', silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    194 \n    195         reply_content = {}\n    196         # FIXME: the shell calls the exception handler itself.\n    197         shell._reply_content = None\n    198         try:\n--> 199             shell.run_cell(code, store_history=store_history, silent=silent)\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = u'from sklearn.feature_selection import SelectKB...rams.best_score_)\\nsearch_params.best_estimator_'\n        store_history = True\n        silent = False\n    200         except:\n    201             status = u'error'\n    202             # FIXME: this code right now isn't being used yet by default,\n    203             # because the run_cell() call above directly fires off exception\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell=u'from sklearn.feature_selection import SelectKB...rams.best_score_)\\nsearch_params.best_estimator_', store_history=True, silent=False, shell_futures=True)\n   2718                 self.displayhook.exec_result = result\n   2719 \n   2720                 # Execute the user code\n   2721                 interactivity = \"none\" if silent else self.ast_node_interactivity\n   2722                 self.run_ast_nodes(code_ast.body, cell_name,\n-> 2723                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler instance>\n   2724 \n   2725                 # Reset this so later displayed values do not modify the\n   2726                 # ExecutionResult\n   2727                 self.displayhook.exec_result = None\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.ImportFrom object>, <_ast.ImportFrom object>, <_ast.ImportFrom object>, <_ast.ImportFrom object>, <_ast.ImportFrom object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Expr object>, <_ast.Print object>, <_ast.Print object>, <_ast.Print object>, <_ast.Expr object>], cell_name='<ipython-input-31-77a67d18d2e5>', interactivity='last', compiler=<IPython.core.compilerop.CachingCompiler instance>, result=<IPython.core.interactiveshell.ExecutionResult object>)\n   2820 \n   2821         try:\n   2822             for i, node in enumerate(to_run_exec):\n   2823                 mod = ast.Module([node])\n   2824                 code = compiler(mod, cell_name, \"exec\")\n-> 2825                 if self.run_code(code, result):\n        self.run_code = <bound method ZMQInteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x7f99bfbd0a30, file \"<ipython-input-31-77a67d18d2e5>\", line 50>\n        result = <IPython.core.interactiveshell.ExecutionResult object>\n   2826                     return True\n   2827 \n   2828             for i, node in enumerate(to_run_interactive):\n   2829                 mod = ast.Interactive([node])\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x7f99bfbd0a30, file \"<ipython-input-31-77a67d18d2e5>\", line 50>, result=<IPython.core.interactiveshell.ExecutionResult object>)\n   2880         outflag = 1  # happens in more places, so it's easier as default\n   2881         try:\n   2882             try:\n   2883                 self.hooks.pre_run_code_hook()\n   2884                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2885                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x7f99bfbd0a30, file \"<ipython-input-31-77a67d18d2e5>\", line 50>\n        self.user_global_ns = {'AdaBoostRegressor': <class 'sklearn.ensemble.weight_boosting.AdaBoostRegressor'>, 'DecisionTreeRegressor': <class 'sklearn.tree.tree.DecisionTreeRegressor'>, 'EST_PICKLE_FILENAME': 'baseline_final_estimator.pkl', 'GridSearchCV': <class 'sklearn.grid_search.GridSearchCV'>, 'Imputer': <class 'sklearn.preprocessing.imputation.Imputer'>, 'In': ['', u'import pdb\\nimport numpy as np\\nimport gcp.big...ields_str.split(\\'\\\\t\\'))\\nfeatures = fields[1:]', u'def mape(X, predictions, y):\\n  num_timeslots ...or.predict(X)\\n  return -mape(X, predictions, y)', u'from sklearn.linear_model import LogisticRegre...\\n\\n# Should return 0.0\\nmape(X, predictions, y)', u'get_ipython().run_cell_magic(u\\'sql\\', u\\'--mo...\\n\\\\n# The above query randomizes its outputs.\")', u'query = bq.Query(q_all)\\ntableresult = query.results()', u\"all_data = np.zeros((tableresult.length, len(f...\\n    print 'processed {} rows'.format(rcounter)\", u'import pdb\\nimport numpy as np\\nimport gcp.big...ields_str.split(\\'\\\\t\\'))\\nfeatures = fields[1:]', u'def mape(X, predictions, y):\\n  num_timeslots ...or.predict(X)\\n  return -mape(X, predictions, y)', u'from sklearn.linear_model import LogisticRegre...\\n\\n# Should return 0.0\\nmape(X, predictions, y)', u'get_ipython().run_cell_magic(u\\'sql\\', u\\'--mo...\\n\\\\n# The above query randomizes its outputs.\")', u'query = bq.Query(q_all)\\ntableresult = query.results()', u\"all_data = np.zeros((tableresult.length, len(f...\\n    print 'processed {} rows'.format(rcounter)\", u'# Get timeslots to test from GCS\\nitem = stora...'\".format(x), timeslots_to_test))\\nprint(tquery)', u'get_ipython().run_cell_magic(u\\'sql\\', u\\'--mo... if estimator can generalize well to new data.\")', u'query_t = bq.Query(q_all_t)\\ntableresult_t = query_t.results()', u\"all_data_t = np.zeros((tableresult_t.length, l...\\n    print 'processed {} rows'.format(rcounter)\", u'# Useful code to check NaN and Inf values. Thi...l_data))\\nprint \"np.max=\", np.max(abs(all_data))', u'all_data[np.isnan(all_data)] = 0\\nall_data_t[np.isnan(all_data_t)] = 0', u'# Useful code to check NaN and Inf values. Thi...l_data))\\nprint \"np.max=\", np.max(abs(all_data))', ...], 'LogisticRegression': <class 'sklearn.linear_model.logistic.LogisticRegression'>, 'Out': {3: 0.0, 9: 0.0, 20: Pipeline(steps=[('estimate', DecisionTreeRegress...random_state=None,\n           splitter='best'))]), 24: Pipeline(steps=[('estimate', RandomForestRegress...=None,\n           verbose=0, warm_start=False))]), 27: Pipeline(steps=[('estimate', RandomForestRegress...=None,\n           verbose=0, warm_start=False))])}, 'Pipeline': <class 'sklearn.pipeline.Pipeline'>, 'RandomForestRegressor': <class 'sklearn.ensemble.forest.RandomForestRegressor'>, ...}\n        self.user_ns = {'AdaBoostRegressor': <class 'sklearn.ensemble.weight_boosting.AdaBoostRegressor'>, 'DecisionTreeRegressor': <class 'sklearn.tree.tree.DecisionTreeRegressor'>, 'EST_PICKLE_FILENAME': 'baseline_final_estimator.pkl', 'GridSearchCV': <class 'sklearn.grid_search.GridSearchCV'>, 'Imputer': <class 'sklearn.preprocessing.imputation.Imputer'>, 'In': ['', u'import pdb\\nimport numpy as np\\nimport gcp.big...ields_str.split(\\'\\\\t\\'))\\nfeatures = fields[1:]', u'def mape(X, predictions, y):\\n  num_timeslots ...or.predict(X)\\n  return -mape(X, predictions, y)', u'from sklearn.linear_model import LogisticRegre...\\n\\n# Should return 0.0\\nmape(X, predictions, y)', u'get_ipython().run_cell_magic(u\\'sql\\', u\\'--mo...\\n\\\\n# The above query randomizes its outputs.\")', u'query = bq.Query(q_all)\\ntableresult = query.results()', u\"all_data = np.zeros((tableresult.length, len(f...\\n    print 'processed {} rows'.format(rcounter)\", u'import pdb\\nimport numpy as np\\nimport gcp.big...ields_str.split(\\'\\\\t\\'))\\nfeatures = fields[1:]', u'def mape(X, predictions, y):\\n  num_timeslots ...or.predict(X)\\n  return -mape(X, predictions, y)', u'from sklearn.linear_model import LogisticRegre...\\n\\n# Should return 0.0\\nmape(X, predictions, y)', u'get_ipython().run_cell_magic(u\\'sql\\', u\\'--mo...\\n\\\\n# The above query randomizes its outputs.\")', u'query = bq.Query(q_all)\\ntableresult = query.results()', u\"all_data = np.zeros((tableresult.length, len(f...\\n    print 'processed {} rows'.format(rcounter)\", u'# Get timeslots to test from GCS\\nitem = stora...'\".format(x), timeslots_to_test))\\nprint(tquery)', u'get_ipython().run_cell_magic(u\\'sql\\', u\\'--mo... if estimator can generalize well to new data.\")', u'query_t = bq.Query(q_all_t)\\ntableresult_t = query_t.results()', u\"all_data_t = np.zeros((tableresult_t.length, l...\\n    print 'processed {} rows'.format(rcounter)\", u'# Useful code to check NaN and Inf values. Thi...l_data))\\nprint \"np.max=\", np.max(abs(all_data))', u'all_data[np.isnan(all_data)] = 0\\nall_data_t[np.isnan(all_data_t)] = 0', u'# Useful code to check NaN and Inf values. Thi...l_data))\\nprint \"np.max=\", np.max(abs(all_data))', ...], 'LogisticRegression': <class 'sklearn.linear_model.logistic.LogisticRegression'>, 'Out': {3: 0.0, 9: 0.0, 20: Pipeline(steps=[('estimate', DecisionTreeRegress...random_state=None,\n           splitter='best'))]), 24: Pipeline(steps=[('estimate', RandomForestRegress...=None,\n           verbose=0, warm_start=False))]), 27: Pipeline(steps=[('estimate', RandomForestRegress...=None,\n           verbose=0, warm_start=False))])}, 'Pipeline': <class 'sklearn.pipeline.Pipeline'>, 'RandomForestRegressor': <class 'sklearn.ensemble.forest.RandomForestRegressor'>, ...}\n   2886             finally:\n   2887                 # Reset our crash handler in place\n   2888                 sys.excepthook = old_excepthook\n   2889         except SystemExit as e:\n\n...........................................................................\n/content/TeguhWPurwanto@gmail.com/Xiaojukeji Algorithm Competition/<ipython-input-31-77a67d18d2e5> in <module>()\n     45   scoring=mape_scorer,\n     46   n_jobs=2,\n     47   verbose=1\n     48 )\n     49 \n---> 50 search_params.fit(data_train, targets_train)\n     51 print(search_params.grid_scores_)\n     52 print(search_params.best_params_)\n     53 print(search_params.best_score_)\n     54 search_params.best_estimator_\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/sklearn/grid_search.py in fit(self=GridSearchCV(cv=5, error_score='raise',\n       e...nction mape_scorer at 0x7f99d626d398>, verbose=1), X=array([[  17.,    3.,    0., ...,  106.,    1., ...[  56.,    5.,    0., ...,    0.,    0.,    4.]]), y=array([ 46.,  32.,  33., ...,   9.,  34.,  42.]))\n    727         y : array-like, shape = [n_samples] or [n_samples, n_output], optional\n    728             Target relative to X for classification or regression;\n    729             None for unsupervised learning.\n    730 \n    731         \"\"\"\n--> 732         return self._fit(X, y, ParameterGrid(self.param_grid))\n        self._fit = <bound method GridSearchCV._fit of GridSearchCV(...ction mape_scorer at 0x7f99d626d398>, verbose=1)>\n        X = array([[  17.,    3.,    0., ...,  106.,    1., ...[  56.,    5.,    0., ...,    0.,    0.,    4.]])\n        y = array([ 46.,  32.,  33., ...,   9.,  34.,  42.])\n        self.param_grid = {'estimate__n_estimators': [5, 10, 20, 50, 60, 80], 'estimate_learning_rate': [0.1, 0.3, 0.7, 1, 3, 5, 10]}\n    733 \n    734 \n    735 class RandomizedSearchCV(BaseSearchCV):\n    736     \"\"\"Randomized search on hyper parameters.\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/sklearn/grid_search.py in _fit(self=GridSearchCV(cv=5, error_score='raise',\n       e...nction mape_scorer at 0x7f99d626d398>, verbose=1), X=array([[  17.,    3.,    0., ...,  106.,    1., ...[  56.,    5.,    0., ...,    0.,    0.,    4.]]), y=array([ 46.,  32.,  33., ...,   9.,  34.,  42.]), parameter_iterable=<sklearn.grid_search.ParameterGrid object>)\n    500         )(\n    501             delayed(_fit_and_score)(clone(base_estimator), X, y, self.scorer_,\n    502                                     train, test, self.verbose, parameters,\n    503                                     self.fit_params, return_parameters=True,\n    504                                     error_score=self.error_score)\n--> 505                 for parameters in parameter_iterable\n        parameters = undefined\n        parameter_iterable = <sklearn.grid_search.ParameterGrid object>\n    506                 for train, test in cv)\n    507 \n    508         # Out is a list of triplet: score, estimator, n_test_samples\n    509         n_fits = len(out)\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=2), iterable=<itertools.islice object>)\n    661             if pre_dispatch == \"all\" or n_jobs == 1:\n    662                 # The iterable was consumed all at once by the above for loop.\n    663                 # No need to wait for async callbacks to trigger to\n    664                 # consumption.\n    665                 self._iterating = False\n--> 666             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=2)>\n    667             # Make sure that we get a last message telling us we are done\n    668             elapsed_time = time.time() - self._start_time\n    669             self._print('Done %3i out of %3i | elapsed: %s finished',\n    670                         (len(self._output),\n\n    ---------------------------------------------------------------------------\n    Sub-process traceback:\n    ---------------------------------------------------------------------------\n    ValueError                                         Sun Jun 12 12:52:44 2016\nPID: 4116                                     Python 2.7.9: /usr/bin/python\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/sklearn/cross_validation.pyc in _fit_and_score(estimator=Pipeline(steps=[('estimate', AdaBoostRegressor(b...,\n         n_estimators=50, random_state=None))]), X=array([[  17.,    3.,    0., ...,  106.,    1., ...[  56.,    5.,    0., ...,    0.,    0.,    4.]]), y=array([ 46.,  32.,  33., ...,   9.,  34.,  42.]), scorer=<function mape_scorer>, train=array([ 20536,  20537,  20538, ..., 102677, 102678, 102679]), test=array([    0,     1,     2, ..., 20533, 20534, 20535]), verbose=1, parameters={'estimate__n_estimators': 5, 'estimate_learning_rate': 0.1}, fit_params={}, return_train_score=False, return_parameters=True, error_score='raise')\n   1443     fit_params = fit_params if fit_params is not None else {}\n   1444     fit_params = dict([(k, _index_param_value(X, v, train))\n   1445                       for k, v in fit_params.items()])\n   1446 \n   1447     if parameters is not None:\n-> 1448         estimator.set_params(**parameters)\n   1449 \n   1450     start_time = time.time()\n   1451 \n   1452     X_train, y_train = _safe_split(estimator, X, y, train)\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/sklearn/base.pyc in set_params(self=Pipeline(steps=[('estimate', AdaBoostRegressor(b...,\n         n_estimators=50, random_state=None))]), **params={'estimate__n_estimators': 5, 'estimate_learning_rate': 0.1})\n    251                 sub_object.set_params(**{sub_name: value})\n    252             else:\n    253                 # simple objects case\n    254                 if not key in valid_params:\n    255                     raise ValueError('Invalid parameter %s ' 'for estimator %s'\n--> 256                                      % (key, self.__class__.__name__))\n    257                 setattr(self, key, value)\n    258         return self\n    259 \n    260     def __repr__(self):\n\nValueError: Invalid parameter estimate_learning_rate for estimator Pipeline\n___________________________________________________________________________",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m\u001b[0m",
      "\u001b[1;31mJoblibValueError\u001b[0mTraceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-77a67d18d2e5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     48\u001b[0m )\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 50\u001b[1;33m \u001b[0msearch_params\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     51\u001b[0m \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msearch_params\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrid_scores_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msearch_params\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/sklearn/grid_search.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    730\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    731\u001b[0m         \"\"\"\n\u001b[1;32m--> 732\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    733\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    734\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/sklearn/grid_search.pyc\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, parameter_iterable)\u001b[0m\n\u001b[0;32m    503\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_parameters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    504\u001b[0m                                     error_score=self.error_score)\n\u001b[1;32m--> 505\u001b[1;33m                 \u001b[1;32mfor\u001b[0m \u001b[0mparameters\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mparameter_iterable\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    506\u001b[0m                 for train, test in cv)\n\u001b[0;32m    507\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    664\u001b[0m                 \u001b[1;31m# consumption.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    665\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 666\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    667\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    668\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    547\u001b[0m                         \u001b[1;31m# Convert this to a JoblibException\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    548\u001b[0m                         \u001b[0mexception_type\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_mk_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexception\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0metype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 549\u001b[1;33m                         \u001b[1;32mraise\u001b[0m \u001b[0mexception_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreport\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    550\u001b[0m                     \u001b[1;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    551\u001b[0m                 \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mJoblibValueError\u001b[0m: JoblibValueError\n___________________________________________________________________________\nMultiprocessing exception:\n    ...........................................................................\n/usr/lib/python2.7/runpy.py in _run_module_as_main(mod_name='ipykernel.__main__', alter_argv=1)\n    157     pkg_name = mod_name.rpartition('.')[0]\n    158     main_globals = sys.modules[\"__main__\"].__dict__\n    159     if alter_argv:\n    160         sys.argv[0] = fname\n    161     return _run_code(code, main_globals, None,\n--> 162                      \"__main__\", fname, loader, pkg_name)\n        fname = '/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py'\n        loader = <pkgutil.ImpLoader instance>\n        pkg_name = 'ipykernel'\n    163 \n    164 def run_module(mod_name, init_globals=None,\n    165                run_name=None, alter_sys=False):\n    166     \"\"\"Execute a module's code without importing it\n\n...........................................................................\n/usr/lib/python2.7/runpy.py in _run_code(code=<code object <module> at 0x7f99f453b330, file \"/...2.7/dist-packages/ipykernel/__main__.py\", line 1>, run_globals={'__builtins__': <module '__builtin__' (built-in)>, '__doc__': None, '__file__': '/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py', '__loader__': <pkgutil.ImpLoader instance>, '__name__': '__main__', '__package__': 'ipykernel', 'app': <module 'ipykernel.kernelapp' from '/usr/local/lib/python2.7/dist-packages/ipykernel/kernelapp.pyc'>}, init_globals=None, mod_name='__main__', mod_fname='/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py', mod_loader=<pkgutil.ImpLoader instance>, pkg_name='ipykernel')\n     67         run_globals.update(init_globals)\n     68     run_globals.update(__name__ = mod_name,\n     69                        __file__ = mod_fname,\n     70                        __loader__ = mod_loader,\n     71                        __package__ = pkg_name)\n---> 72     exec code in run_globals\n        code = <code object <module> at 0x7f99f453b330, file \"/...2.7/dist-packages/ipykernel/__main__.py\", line 1>\n        run_globals = {'__builtins__': <module '__builtin__' (built-in)>, '__doc__': None, '__file__': '/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py', '__loader__': <pkgutil.ImpLoader instance>, '__name__': '__main__', '__package__': 'ipykernel', 'app': <module 'ipykernel.kernelapp' from '/usr/local/lib/python2.7/dist-packages/ipykernel/kernelapp.pyc'>}\n     73     return run_globals\n     74 \n     75 def _run_module_code(code, init_globals=None,\n     76                     mod_name=None, mod_fname=None,\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py in <module>()\n      1 \n      2 \n----> 3 \n      4 if __name__ == '__main__':\n      5     from ipykernel import kernelapp as app\n      6     app.launch_new_instance()\n      7 \n      8 \n      9 \n     10 \n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/traitlets/config/application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    591         \n    592         If a global instance already exists, this reinitializes and starts it\n    593         \"\"\"\n    594         app = cls.instance(**kwargs)\n    595         app.initialize(argv)\n--> 596         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    597 \n    598 #-----------------------------------------------------------------------------\n    599 # utility functions, for convenience\n    600 #-----------------------------------------------------------------------------\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/ipykernel/kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    437         \n    438         if self.poller is not None:\n    439             self.poller.start()\n    440         self.kernel.start()\n    441         try:\n--> 442             ioloop.IOLoop.instance().start()\n    443         except KeyboardInterrupt:\n    444             pass\n    445 \n    446 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/zmq/eventloop/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    157             PollIOLoop.configure(ZMQIOLoop)\n    158         return PollIOLoop.current(*args, **kwargs)\n    159     \n    160     def start(self):\n    161         try:\n--> 162             super(ZMQIOLoop, self).start()\n        self.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    163         except ZMQError as e:\n    164             if e.errno == ETERM:\n    165                 # quietly return on ETERM\n    166                 pass\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/tornado/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    878                 self._events.update(event_pairs)\n    879                 while self._events:\n    880                     fd, events = self._events.popitem()\n    881                     try:\n    882                         fd_obj, handler_func = self._handlers[fd]\n--> 883                         handler_func(fd_obj, events)\n        handler_func = <function null_wrapper>\n        fd_obj = <zmq.sugar.socket.Socket object>\n        events = 1\n    884                     except (OSError, IOError) as e:\n    885                         if errno_from_exception(e) == errno.EPIPE:\n    886                             # Happens when the client closes the connection\n    887                             pass\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/tornado/stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    270         # Fast path when there are no active contexts.\n    271         def null_wrapper(*args, **kwargs):\n    272             try:\n    273                 current_state = _state.contexts\n    274                 _state.contexts = cap_contexts[0]\n--> 275                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    276             finally:\n    277                 _state.contexts = current_state\n    278         null_wrapper._wrapped = True\n    279         return null_wrapper\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    435             # dispatch events:\n    436             if events & IOLoop.ERROR:\n    437                 gen_log.error(\"got POLLERR event on ZMQStream, which doesn't make sense\")\n    438                 return\n    439             if events & IOLoop.READ:\n--> 440                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    441                 if not self.socket:\n    442                     return\n    443             if events & IOLoop.WRITE:\n    444                 self._handle_send()\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    467                 gen_log.error(\"RECV Error: %s\"%zmq.strerror(e.errno))\n    468         else:\n    469             if self._recv_callback:\n    470                 callback = self._recv_callback\n    471                 # self._recv_callback = None\n--> 472                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    473                 \n    474         # self.update_state()\n    475         \n    476 \n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    409         close our socket.\"\"\"\n    410         try:\n    411             # Use a NullContext to ensure that all StackContexts are run\n    412             # inside our blanket exception handler rather than outside.\n    413             with stack_context.NullContext():\n--> 414                 callback(*args, **kwargs)\n        callback = <function null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    415         except:\n    416             gen_log.error(\"Uncaught exception, closing connection.\",\n    417                           exc_info=True)\n    418             # Close the socket on an uncaught exception from a user callback\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/tornado/stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    270         # Fast path when there are no active contexts.\n    271         def null_wrapper(*args, **kwargs):\n    272             try:\n    273                 current_state = _state.contexts\n    274                 _state.contexts = cap_contexts[0]\n--> 275                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    276             finally:\n    277                 _state.contexts = current_state\n    278         null_wrapper._wrapped = True\n    279         return null_wrapper\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    271         if self.control_stream:\n    272             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    273 \n    274         def make_dispatcher(stream):\n    275             def dispatcher(msg):\n--> 276                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    277             return dispatcher\n    278 \n    279         for s in self.shell_streams:\n    280             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {u'allow_stdin': True, u'code': u'from sklearn.feature_selection import SelectKB...rams.best_score_)\\nsearch_params.best_estimator_', u'silent': False, u'stop_on_error': True, u'store_history': True, u'user_expressions': {}}, 'header': {'date': '2016-06-12T12:52:44.380983', u'msg_id': u'51BC7D2045F34C1DBFB596E8921EC318', u'msg_type': u'execute_request', u'session': u'CEF40C66C22B4B51AB5041666FFC5A00', u'username': u'username', u'version': u'5.0'}, 'metadata': {}, 'msg_id': u'51BC7D2045F34C1DBFB596E8921EC318', 'msg_type': u'execute_request', 'parent_header': {}})\n    223             self.log.error(\"UNKNOWN MESSAGE TYPE: %r\", msg_type)\n    224         else:\n    225             self.log.debug(\"%s: %s\", msg_type, msg)\n    226             self.pre_handler_hook()\n    227             try:\n--> 228                 handler(stream, idents, msg)\n        handler = <bound method IPythonKernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = ['CEF40C66C22B4B51AB5041666FFC5A00']\n        msg = {'buffers': [], 'content': {u'allow_stdin': True, u'code': u'from sklearn.feature_selection import SelectKB...rams.best_score_)\\nsearch_params.best_estimator_', u'silent': False, u'stop_on_error': True, u'store_history': True, u'user_expressions': {}}, 'header': {'date': '2016-06-12T12:52:44.380983', u'msg_id': u'51BC7D2045F34C1DBFB596E8921EC318', u'msg_type': u'execute_request', u'session': u'CEF40C66C22B4B51AB5041666FFC5A00', u'username': u'username', u'version': u'5.0'}, 'metadata': {}, 'msg_id': u'51BC7D2045F34C1DBFB596E8921EC318', 'msg_type': u'execute_request', 'parent_header': {}}\n    229             except Exception:\n    230                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    231             finally:\n    232                 self.post_handler_hook()\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=['CEF40C66C22B4B51AB5041666FFC5A00'], parent={'buffers': [], 'content': {u'allow_stdin': True, u'code': u'from sklearn.feature_selection import SelectKB...rams.best_score_)\\nsearch_params.best_estimator_', u'silent': False, u'stop_on_error': True, u'store_history': True, u'user_expressions': {}}, 'header': {'date': '2016-06-12T12:52:44.380983', u'msg_id': u'51BC7D2045F34C1DBFB596E8921EC318', u'msg_type': u'execute_request', u'session': u'CEF40C66C22B4B51AB5041666FFC5A00', u'username': u'username', u'version': u'5.0'}, 'metadata': {}, 'msg_id': u'51BC7D2045F34C1DBFB596E8921EC318', 'msg_type': u'execute_request', 'parent_header': {}})\n    386         if not silent:\n    387             self.execution_count += 1\n    388             self._publish_execute_input(code, parent, self.execution_count)\n    389 \n    390         reply_content = self.do_execute(code, silent, store_history,\n--> 391                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    392 \n    393         # Flush output before sending the reply.\n    394         sys.stdout.flush()\n    395         sys.stderr.flush()\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/ipykernel/ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code=u'from sklearn.feature_selection import SelectKB...rams.best_score_)\\nsearch_params.best_estimator_', silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    194 \n    195         reply_content = {}\n    196         # FIXME: the shell calls the exception handler itself.\n    197         shell._reply_content = None\n    198         try:\n--> 199             shell.run_cell(code, store_history=store_history, silent=silent)\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = u'from sklearn.feature_selection import SelectKB...rams.best_score_)\\nsearch_params.best_estimator_'\n        store_history = True\n        silent = False\n    200         except:\n    201             status = u'error'\n    202             # FIXME: this code right now isn't being used yet by default,\n    203             # because the run_cell() call above directly fires off exception\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell=u'from sklearn.feature_selection import SelectKB...rams.best_score_)\\nsearch_params.best_estimator_', store_history=True, silent=False, shell_futures=True)\n   2718                 self.displayhook.exec_result = result\n   2719 \n   2720                 # Execute the user code\n   2721                 interactivity = \"none\" if silent else self.ast_node_interactivity\n   2722                 self.run_ast_nodes(code_ast.body, cell_name,\n-> 2723                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler instance>\n   2724 \n   2725                 # Reset this so later displayed values do not modify the\n   2726                 # ExecutionResult\n   2727                 self.displayhook.exec_result = None\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.ImportFrom object>, <_ast.ImportFrom object>, <_ast.ImportFrom object>, <_ast.ImportFrom object>, <_ast.ImportFrom object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Expr object>, <_ast.Print object>, <_ast.Print object>, <_ast.Print object>, <_ast.Expr object>], cell_name='<ipython-input-31-77a67d18d2e5>', interactivity='last', compiler=<IPython.core.compilerop.CachingCompiler instance>, result=<IPython.core.interactiveshell.ExecutionResult object>)\n   2820 \n   2821         try:\n   2822             for i, node in enumerate(to_run_exec):\n   2823                 mod = ast.Module([node])\n   2824                 code = compiler(mod, cell_name, \"exec\")\n-> 2825                 if self.run_code(code, result):\n        self.run_code = <bound method ZMQInteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x7f99bfbd0a30, file \"<ipython-input-31-77a67d18d2e5>\", line 50>\n        result = <IPython.core.interactiveshell.ExecutionResult object>\n   2826                     return True\n   2827 \n   2828             for i, node in enumerate(to_run_interactive):\n   2829                 mod = ast.Interactive([node])\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x7f99bfbd0a30, file \"<ipython-input-31-77a67d18d2e5>\", line 50>, result=<IPython.core.interactiveshell.ExecutionResult object>)\n   2880         outflag = 1  # happens in more places, so it's easier as default\n   2881         try:\n   2882             try:\n   2883                 self.hooks.pre_run_code_hook()\n   2884                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2885                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x7f99bfbd0a30, file \"<ipython-input-31-77a67d18d2e5>\", line 50>\n        self.user_global_ns = {'AdaBoostRegressor': <class 'sklearn.ensemble.weight_boosting.AdaBoostRegressor'>, 'DecisionTreeRegressor': <class 'sklearn.tree.tree.DecisionTreeRegressor'>, 'EST_PICKLE_FILENAME': 'baseline_final_estimator.pkl', 'GridSearchCV': <class 'sklearn.grid_search.GridSearchCV'>, 'Imputer': <class 'sklearn.preprocessing.imputation.Imputer'>, 'In': ['', u'import pdb\\nimport numpy as np\\nimport gcp.big...ields_str.split(\\'\\\\t\\'))\\nfeatures = fields[1:]', u'def mape(X, predictions, y):\\n  num_timeslots ...or.predict(X)\\n  return -mape(X, predictions, y)', u'from sklearn.linear_model import LogisticRegre...\\n\\n# Should return 0.0\\nmape(X, predictions, y)', u'get_ipython().run_cell_magic(u\\'sql\\', u\\'--mo...\\n\\\\n# The above query randomizes its outputs.\")', u'query = bq.Query(q_all)\\ntableresult = query.results()', u\"all_data = np.zeros((tableresult.length, len(f...\\n    print 'processed {} rows'.format(rcounter)\", u'import pdb\\nimport numpy as np\\nimport gcp.big...ields_str.split(\\'\\\\t\\'))\\nfeatures = fields[1:]', u'def mape(X, predictions, y):\\n  num_timeslots ...or.predict(X)\\n  return -mape(X, predictions, y)', u'from sklearn.linear_model import LogisticRegre...\\n\\n# Should return 0.0\\nmape(X, predictions, y)', u'get_ipython().run_cell_magic(u\\'sql\\', u\\'--mo...\\n\\\\n# The above query randomizes its outputs.\")', u'query = bq.Query(q_all)\\ntableresult = query.results()', u\"all_data = np.zeros((tableresult.length, len(f...\\n    print 'processed {} rows'.format(rcounter)\", u'# Get timeslots to test from GCS\\nitem = stora...'\".format(x), timeslots_to_test))\\nprint(tquery)', u'get_ipython().run_cell_magic(u\\'sql\\', u\\'--mo... if estimator can generalize well to new data.\")', u'query_t = bq.Query(q_all_t)\\ntableresult_t = query_t.results()', u\"all_data_t = np.zeros((tableresult_t.length, l...\\n    print 'processed {} rows'.format(rcounter)\", u'# Useful code to check NaN and Inf values. Thi...l_data))\\nprint \"np.max=\", np.max(abs(all_data))', u'all_data[np.isnan(all_data)] = 0\\nall_data_t[np.isnan(all_data_t)] = 0', u'# Useful code to check NaN and Inf values. Thi...l_data))\\nprint \"np.max=\", np.max(abs(all_data))', ...], 'LogisticRegression': <class 'sklearn.linear_model.logistic.LogisticRegression'>, 'Out': {3: 0.0, 9: 0.0, 20: Pipeline(steps=[('estimate', DecisionTreeRegress...random_state=None,\n           splitter='best'))]), 24: Pipeline(steps=[('estimate', RandomForestRegress...=None,\n           verbose=0, warm_start=False))]), 27: Pipeline(steps=[('estimate', RandomForestRegress...=None,\n           verbose=0, warm_start=False))])}, 'Pipeline': <class 'sklearn.pipeline.Pipeline'>, 'RandomForestRegressor': <class 'sklearn.ensemble.forest.RandomForestRegressor'>, ...}\n        self.user_ns = {'AdaBoostRegressor': <class 'sklearn.ensemble.weight_boosting.AdaBoostRegressor'>, 'DecisionTreeRegressor': <class 'sklearn.tree.tree.DecisionTreeRegressor'>, 'EST_PICKLE_FILENAME': 'baseline_final_estimator.pkl', 'GridSearchCV': <class 'sklearn.grid_search.GridSearchCV'>, 'Imputer': <class 'sklearn.preprocessing.imputation.Imputer'>, 'In': ['', u'import pdb\\nimport numpy as np\\nimport gcp.big...ields_str.split(\\'\\\\t\\'))\\nfeatures = fields[1:]', u'def mape(X, predictions, y):\\n  num_timeslots ...or.predict(X)\\n  return -mape(X, predictions, y)', u'from sklearn.linear_model import LogisticRegre...\\n\\n# Should return 0.0\\nmape(X, predictions, y)', u'get_ipython().run_cell_magic(u\\'sql\\', u\\'--mo...\\n\\\\n# The above query randomizes its outputs.\")', u'query = bq.Query(q_all)\\ntableresult = query.results()', u\"all_data = np.zeros((tableresult.length, len(f...\\n    print 'processed {} rows'.format(rcounter)\", u'import pdb\\nimport numpy as np\\nimport gcp.big...ields_str.split(\\'\\\\t\\'))\\nfeatures = fields[1:]', u'def mape(X, predictions, y):\\n  num_timeslots ...or.predict(X)\\n  return -mape(X, predictions, y)', u'from sklearn.linear_model import LogisticRegre...\\n\\n# Should return 0.0\\nmape(X, predictions, y)', u'get_ipython().run_cell_magic(u\\'sql\\', u\\'--mo...\\n\\\\n# The above query randomizes its outputs.\")', u'query = bq.Query(q_all)\\ntableresult = query.results()', u\"all_data = np.zeros((tableresult.length, len(f...\\n    print 'processed {} rows'.format(rcounter)\", u'# Get timeslots to test from GCS\\nitem = stora...'\".format(x), timeslots_to_test))\\nprint(tquery)', u'get_ipython().run_cell_magic(u\\'sql\\', u\\'--mo... if estimator can generalize well to new data.\")', u'query_t = bq.Query(q_all_t)\\ntableresult_t = query_t.results()', u\"all_data_t = np.zeros((tableresult_t.length, l...\\n    print 'processed {} rows'.format(rcounter)\", u'# Useful code to check NaN and Inf values. Thi...l_data))\\nprint \"np.max=\", np.max(abs(all_data))', u'all_data[np.isnan(all_data)] = 0\\nall_data_t[np.isnan(all_data_t)] = 0', u'# Useful code to check NaN and Inf values. Thi...l_data))\\nprint \"np.max=\", np.max(abs(all_data))', ...], 'LogisticRegression': <class 'sklearn.linear_model.logistic.LogisticRegression'>, 'Out': {3: 0.0, 9: 0.0, 20: Pipeline(steps=[('estimate', DecisionTreeRegress...random_state=None,\n           splitter='best'))]), 24: Pipeline(steps=[('estimate', RandomForestRegress...=None,\n           verbose=0, warm_start=False))]), 27: Pipeline(steps=[('estimate', RandomForestRegress...=None,\n           verbose=0, warm_start=False))])}, 'Pipeline': <class 'sklearn.pipeline.Pipeline'>, 'RandomForestRegressor': <class 'sklearn.ensemble.forest.RandomForestRegressor'>, ...}\n   2886             finally:\n   2887                 # Reset our crash handler in place\n   2888                 sys.excepthook = old_excepthook\n   2889         except SystemExit as e:\n\n...........................................................................\n/content/TeguhWPurwanto@gmail.com/Xiaojukeji Algorithm Competition/<ipython-input-31-77a67d18d2e5> in <module>()\n     45   scoring=mape_scorer,\n     46   n_jobs=2,\n     47   verbose=1\n     48 )\n     49 \n---> 50 search_params.fit(data_train, targets_train)\n     51 print(search_params.grid_scores_)\n     52 print(search_params.best_params_)\n     53 print(search_params.best_score_)\n     54 search_params.best_estimator_\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/sklearn/grid_search.py in fit(self=GridSearchCV(cv=5, error_score='raise',\n       e...nction mape_scorer at 0x7f99d626d398>, verbose=1), X=array([[  17.,    3.,    0., ...,  106.,    1., ...[  56.,    5.,    0., ...,    0.,    0.,    4.]]), y=array([ 46.,  32.,  33., ...,   9.,  34.,  42.]))\n    727         y : array-like, shape = [n_samples] or [n_samples, n_output], optional\n    728             Target relative to X for classification or regression;\n    729             None for unsupervised learning.\n    730 \n    731         \"\"\"\n--> 732         return self._fit(X, y, ParameterGrid(self.param_grid))\n        self._fit = <bound method GridSearchCV._fit of GridSearchCV(...ction mape_scorer at 0x7f99d626d398>, verbose=1)>\n        X = array([[  17.,    3.,    0., ...,  106.,    1., ...[  56.,    5.,    0., ...,    0.,    0.,    4.]])\n        y = array([ 46.,  32.,  33., ...,   9.,  34.,  42.])\n        self.param_grid = {'estimate__n_estimators': [5, 10, 20, 50, 60, 80], 'estimate_learning_rate': [0.1, 0.3, 0.7, 1, 3, 5, 10]}\n    733 \n    734 \n    735 class RandomizedSearchCV(BaseSearchCV):\n    736     \"\"\"Randomized search on hyper parameters.\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/sklearn/grid_search.py in _fit(self=GridSearchCV(cv=5, error_score='raise',\n       e...nction mape_scorer at 0x7f99d626d398>, verbose=1), X=array([[  17.,    3.,    0., ...,  106.,    1., ...[  56.,    5.,    0., ...,    0.,    0.,    4.]]), y=array([ 46.,  32.,  33., ...,   9.,  34.,  42.]), parameter_iterable=<sklearn.grid_search.ParameterGrid object>)\n    500         )(\n    501             delayed(_fit_and_score)(clone(base_estimator), X, y, self.scorer_,\n    502                                     train, test, self.verbose, parameters,\n    503                                     self.fit_params, return_parameters=True,\n    504                                     error_score=self.error_score)\n--> 505                 for parameters in parameter_iterable\n        parameters = undefined\n        parameter_iterable = <sklearn.grid_search.ParameterGrid object>\n    506                 for train, test in cv)\n    507 \n    508         # Out is a list of triplet: score, estimator, n_test_samples\n    509         n_fits = len(out)\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=2), iterable=<itertools.islice object>)\n    661             if pre_dispatch == \"all\" or n_jobs == 1:\n    662                 # The iterable was consumed all at once by the above for loop.\n    663                 # No need to wait for async callbacks to trigger to\n    664                 # consumption.\n    665                 self._iterating = False\n--> 666             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=2)>\n    667             # Make sure that we get a last message telling us we are done\n    668             elapsed_time = time.time() - self._start_time\n    669             self._print('Done %3i out of %3i | elapsed: %s finished',\n    670                         (len(self._output),\n\n    ---------------------------------------------------------------------------\n    Sub-process traceback:\n    ---------------------------------------------------------------------------\n    ValueError                                         Sun Jun 12 12:52:44 2016\nPID: 4116                                     Python 2.7.9: /usr/bin/python\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/sklearn/cross_validation.pyc in _fit_and_score(estimator=Pipeline(steps=[('estimate', AdaBoostRegressor(b...,\n         n_estimators=50, random_state=None))]), X=array([[  17.,    3.,    0., ...,  106.,    1., ...[  56.,    5.,    0., ...,    0.,    0.,    4.]]), y=array([ 46.,  32.,  33., ...,   9.,  34.,  42.]), scorer=<function mape_scorer>, train=array([ 20536,  20537,  20538, ..., 102677, 102678, 102679]), test=array([    0,     1,     2, ..., 20533, 20534, 20535]), verbose=1, parameters={'estimate__n_estimators': 5, 'estimate_learning_rate': 0.1}, fit_params={}, return_train_score=False, return_parameters=True, error_score='raise')\n   1443     fit_params = fit_params if fit_params is not None else {}\n   1444     fit_params = dict([(k, _index_param_value(X, v, train))\n   1445                       for k, v in fit_params.items()])\n   1446 \n   1447     if parameters is not None:\n-> 1448         estimator.set_params(**parameters)\n   1449 \n   1450     start_time = time.time()\n   1451 \n   1452     X_train, y_train = _safe_split(estimator, X, y, train)\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/sklearn/base.pyc in set_params(self=Pipeline(steps=[('estimate', AdaBoostRegressor(b...,\n         n_estimators=50, random_state=None))]), **params={'estimate__n_estimators': 5, 'estimate_learning_rate': 0.1})\n    251                 sub_object.set_params(**{sub_name: value})\n    252             else:\n    253                 # simple objects case\n    254                 if not key in valid_params:\n    255                     raise ValueError('Invalid parameter %s ' 'for estimator %s'\n--> 256                                      % (key, self.__class__.__name__))\n    257                 setattr(self, key, value)\n    258         return self\n    259 \n    260     def __repr__(self):\n\nValueError: Invalid parameter estimate_learning_rate for estimator Pipeline\n___________________________________________________________________________"
     ]
    },
    {
     "ename": "JoblibValueError",
     "evalue": "JoblibValueError\n___________________________________________________________________________\nMultiprocessing exception:\n    ...........................................................................\n/usr/lib/python2.7/runpy.py in _run_module_as_main(mod_name='ipykernel.__main__', alter_argv=1)\n    157     pkg_name = mod_name.rpartition('.')[0]\n    158     main_globals = sys.modules[\"__main__\"].__dict__\n    159     if alter_argv:\n    160         sys.argv[0] = fname\n    161     return _run_code(code, main_globals, None,\n--> 162                      \"__main__\", fname, loader, pkg_name)\n        fname = '/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py'\n        loader = <pkgutil.ImpLoader instance>\n        pkg_name = 'ipykernel'\n    163 \n    164 def run_module(mod_name, init_globals=None,\n    165                run_name=None, alter_sys=False):\n    166     \"\"\"Execute a module's code without importing it\n\n...........................................................................\n/usr/lib/python2.7/runpy.py in _run_code(code=<code object <module> at 0x7f99f453b330, file \"/...2.7/dist-packages/ipykernel/__main__.py\", line 1>, run_globals={'__builtins__': <module '__builtin__' (built-in)>, '__doc__': None, '__file__': '/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py', '__loader__': <pkgutil.ImpLoader instance>, '__name__': '__main__', '__package__': 'ipykernel', 'app': <module 'ipykernel.kernelapp' from '/usr/local/lib/python2.7/dist-packages/ipykernel/kernelapp.pyc'>}, init_globals=None, mod_name='__main__', mod_fname='/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py', mod_loader=<pkgutil.ImpLoader instance>, pkg_name='ipykernel')\n     67         run_globals.update(init_globals)\n     68     run_globals.update(__name__ = mod_name,\n     69                        __file__ = mod_fname,\n     70                        __loader__ = mod_loader,\n     71                        __package__ = pkg_name)\n---> 72     exec code in run_globals\n        code = <code object <module> at 0x7f99f453b330, file \"/...2.7/dist-packages/ipykernel/__main__.py\", line 1>\n        run_globals = {'__builtins__': <module '__builtin__' (built-in)>, '__doc__': None, '__file__': '/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py', '__loader__': <pkgutil.ImpLoader instance>, '__name__': '__main__', '__package__': 'ipykernel', 'app': <module 'ipykernel.kernelapp' from '/usr/local/lib/python2.7/dist-packages/ipykernel/kernelapp.pyc'>}\n     73     return run_globals\n     74 \n     75 def _run_module_code(code, init_globals=None,\n     76                     mod_name=None, mod_fname=None,\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py in <module>()\n      1 \n      2 \n----> 3 \n      4 if __name__ == '__main__':\n      5     from ipykernel import kernelapp as app\n      6     app.launch_new_instance()\n      7 \n      8 \n      9 \n     10 \n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/traitlets/config/application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    591         \n    592         If a global instance already exists, this reinitializes and starts it\n    593         \"\"\"\n    594         app = cls.instance(**kwargs)\n    595         app.initialize(argv)\n--> 596         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    597 \n    598 #-----------------------------------------------------------------------------\n    599 # utility functions, for convenience\n    600 #-----------------------------------------------------------------------------\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/ipykernel/kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    437         \n    438         if self.poller is not None:\n    439             self.poller.start()\n    440         self.kernel.start()\n    441         try:\n--> 442             ioloop.IOLoop.instance().start()\n    443         except KeyboardInterrupt:\n    444             pass\n    445 \n    446 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/zmq/eventloop/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    157             PollIOLoop.configure(ZMQIOLoop)\n    158         return PollIOLoop.current(*args, **kwargs)\n    159     \n    160     def start(self):\n    161         try:\n--> 162             super(ZMQIOLoop, self).start()\n        self.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    163         except ZMQError as e:\n    164             if e.errno == ETERM:\n    165                 # quietly return on ETERM\n    166                 pass\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/tornado/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    878                 self._events.update(event_pairs)\n    879                 while self._events:\n    880                     fd, events = self._events.popitem()\n    881                     try:\n    882                         fd_obj, handler_func = self._handlers[fd]\n--> 883                         handler_func(fd_obj, events)\n        handler_func = <function null_wrapper>\n        fd_obj = <zmq.sugar.socket.Socket object>\n        events = 1\n    884                     except (OSError, IOError) as e:\n    885                         if errno_from_exception(e) == errno.EPIPE:\n    886                             # Happens when the client closes the connection\n    887                             pass\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/tornado/stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    270         # Fast path when there are no active contexts.\n    271         def null_wrapper(*args, **kwargs):\n    272             try:\n    273                 current_state = _state.contexts\n    274                 _state.contexts = cap_contexts[0]\n--> 275                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    276             finally:\n    277                 _state.contexts = current_state\n    278         null_wrapper._wrapped = True\n    279         return null_wrapper\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    435             # dispatch events:\n    436             if events & IOLoop.ERROR:\n    437                 gen_log.error(\"got POLLERR event on ZMQStream, which doesn't make sense\")\n    438                 return\n    439             if events & IOLoop.READ:\n--> 440                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    441                 if not self.socket:\n    442                     return\n    443             if events & IOLoop.WRITE:\n    444                 self._handle_send()\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    467                 gen_log.error(\"RECV Error: %s\"%zmq.strerror(e.errno))\n    468         else:\n    469             if self._recv_callback:\n    470                 callback = self._recv_callback\n    471                 # self._recv_callback = None\n--> 472                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    473                 \n    474         # self.update_state()\n    475         \n    476 \n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    409         close our socket.\"\"\"\n    410         try:\n    411             # Use a NullContext to ensure that all StackContexts are run\n    412             # inside our blanket exception handler rather than outside.\n    413             with stack_context.NullContext():\n--> 414                 callback(*args, **kwargs)\n        callback = <function null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    415         except:\n    416             gen_log.error(\"Uncaught exception, closing connection.\",\n    417                           exc_info=True)\n    418             # Close the socket on an uncaught exception from a user callback\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/tornado/stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    270         # Fast path when there are no active contexts.\n    271         def null_wrapper(*args, **kwargs):\n    272             try:\n    273                 current_state = _state.contexts\n    274                 _state.contexts = cap_contexts[0]\n--> 275                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    276             finally:\n    277                 _state.contexts = current_state\n    278         null_wrapper._wrapped = True\n    279         return null_wrapper\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    271         if self.control_stream:\n    272             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    273 \n    274         def make_dispatcher(stream):\n    275             def dispatcher(msg):\n--> 276                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    277             return dispatcher\n    278 \n    279         for s in self.shell_streams:\n    280             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {u'allow_stdin': True, u'code': u'from sklearn.feature_selection import SelectKB...rams.best_score_)\\nsearch_params.best_estimator_', u'silent': False, u'stop_on_error': True, u'store_history': True, u'user_expressions': {}}, 'header': {'date': '2016-06-12T12:52:44.380983', u'msg_id': u'51BC7D2045F34C1DBFB596E8921EC318', u'msg_type': u'execute_request', u'session': u'CEF40C66C22B4B51AB5041666FFC5A00', u'username': u'username', u'version': u'5.0'}, 'metadata': {}, 'msg_id': u'51BC7D2045F34C1DBFB596E8921EC318', 'msg_type': u'execute_request', 'parent_header': {}})\n    223             self.log.error(\"UNKNOWN MESSAGE TYPE: %r\", msg_type)\n    224         else:\n    225             self.log.debug(\"%s: %s\", msg_type, msg)\n    226             self.pre_handler_hook()\n    227             try:\n--> 228                 handler(stream, idents, msg)\n        handler = <bound method IPythonKernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = ['CEF40C66C22B4B51AB5041666FFC5A00']\n        msg = {'buffers': [], 'content': {u'allow_stdin': True, u'code': u'from sklearn.feature_selection import SelectKB...rams.best_score_)\\nsearch_params.best_estimator_', u'silent': False, u'stop_on_error': True, u'store_history': True, u'user_expressions': {}}, 'header': {'date': '2016-06-12T12:52:44.380983', u'msg_id': u'51BC7D2045F34C1DBFB596E8921EC318', u'msg_type': u'execute_request', u'session': u'CEF40C66C22B4B51AB5041666FFC5A00', u'username': u'username', u'version': u'5.0'}, 'metadata': {}, 'msg_id': u'51BC7D2045F34C1DBFB596E8921EC318', 'msg_type': u'execute_request', 'parent_header': {}}\n    229             except Exception:\n    230                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    231             finally:\n    232                 self.post_handler_hook()\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=['CEF40C66C22B4B51AB5041666FFC5A00'], parent={'buffers': [], 'content': {u'allow_stdin': True, u'code': u'from sklearn.feature_selection import SelectKB...rams.best_score_)\\nsearch_params.best_estimator_', u'silent': False, u'stop_on_error': True, u'store_history': True, u'user_expressions': {}}, 'header': {'date': '2016-06-12T12:52:44.380983', u'msg_id': u'51BC7D2045F34C1DBFB596E8921EC318', u'msg_type': u'execute_request', u'session': u'CEF40C66C22B4B51AB5041666FFC5A00', u'username': u'username', u'version': u'5.0'}, 'metadata': {}, 'msg_id': u'51BC7D2045F34C1DBFB596E8921EC318', 'msg_type': u'execute_request', 'parent_header': {}})\n    386         if not silent:\n    387             self.execution_count += 1\n    388             self._publish_execute_input(code, parent, self.execution_count)\n    389 \n    390         reply_content = self.do_execute(code, silent, store_history,\n--> 391                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    392 \n    393         # Flush output before sending the reply.\n    394         sys.stdout.flush()\n    395         sys.stderr.flush()\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/ipykernel/ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code=u'from sklearn.feature_selection import SelectKB...rams.best_score_)\\nsearch_params.best_estimator_', silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    194 \n    195         reply_content = {}\n    196         # FIXME: the shell calls the exception handler itself.\n    197         shell._reply_content = None\n    198         try:\n--> 199             shell.run_cell(code, store_history=store_history, silent=silent)\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = u'from sklearn.feature_selection import SelectKB...rams.best_score_)\\nsearch_params.best_estimator_'\n        store_history = True\n        silent = False\n    200         except:\n    201             status = u'error'\n    202             # FIXME: this code right now isn't being used yet by default,\n    203             # because the run_cell() call above directly fires off exception\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell=u'from sklearn.feature_selection import SelectKB...rams.best_score_)\\nsearch_params.best_estimator_', store_history=True, silent=False, shell_futures=True)\n   2718                 self.displayhook.exec_result = result\n   2719 \n   2720                 # Execute the user code\n   2721                 interactivity = \"none\" if silent else self.ast_node_interactivity\n   2722                 self.run_ast_nodes(code_ast.body, cell_name,\n-> 2723                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler instance>\n   2724 \n   2725                 # Reset this so later displayed values do not modify the\n   2726                 # ExecutionResult\n   2727                 self.displayhook.exec_result = None\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.ImportFrom object>, <_ast.ImportFrom object>, <_ast.ImportFrom object>, <_ast.ImportFrom object>, <_ast.ImportFrom object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Expr object>, <_ast.Print object>, <_ast.Print object>, <_ast.Print object>, <_ast.Expr object>], cell_name='<ipython-input-31-77a67d18d2e5>', interactivity='last', compiler=<IPython.core.compilerop.CachingCompiler instance>, result=<IPython.core.interactiveshell.ExecutionResult object>)\n   2820 \n   2821         try:\n   2822             for i, node in enumerate(to_run_exec):\n   2823                 mod = ast.Module([node])\n   2824                 code = compiler(mod, cell_name, \"exec\")\n-> 2825                 if self.run_code(code, result):\n        self.run_code = <bound method ZMQInteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x7f99bfbd0a30, file \"<ipython-input-31-77a67d18d2e5>\", line 50>\n        result = <IPython.core.interactiveshell.ExecutionResult object>\n   2826                     return True\n   2827 \n   2828             for i, node in enumerate(to_run_interactive):\n   2829                 mod = ast.Interactive([node])\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x7f99bfbd0a30, file \"<ipython-input-31-77a67d18d2e5>\", line 50>, result=<IPython.core.interactiveshell.ExecutionResult object>)\n   2880         outflag = 1  # happens in more places, so it's easier as default\n   2881         try:\n   2882             try:\n   2883                 self.hooks.pre_run_code_hook()\n   2884                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2885                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x7f99bfbd0a30, file \"<ipython-input-31-77a67d18d2e5>\", line 50>\n        self.user_global_ns = {'AdaBoostRegressor': <class 'sklearn.ensemble.weight_boosting.AdaBoostRegressor'>, 'DecisionTreeRegressor': <class 'sklearn.tree.tree.DecisionTreeRegressor'>, 'EST_PICKLE_FILENAME': 'baseline_final_estimator.pkl', 'GridSearchCV': <class 'sklearn.grid_search.GridSearchCV'>, 'Imputer': <class 'sklearn.preprocessing.imputation.Imputer'>, 'In': ['', u'import pdb\\nimport numpy as np\\nimport gcp.big...ields_str.split(\\'\\\\t\\'))\\nfeatures = fields[1:]', u'def mape(X, predictions, y):\\n  num_timeslots ...or.predict(X)\\n  return -mape(X, predictions, y)', u'from sklearn.linear_model import LogisticRegre...\\n\\n# Should return 0.0\\nmape(X, predictions, y)', u'get_ipython().run_cell_magic(u\\'sql\\', u\\'--mo...\\n\\\\n# The above query randomizes its outputs.\")', u'query = bq.Query(q_all)\\ntableresult = query.results()', u\"all_data = np.zeros((tableresult.length, len(f...\\n    print 'processed {} rows'.format(rcounter)\", u'import pdb\\nimport numpy as np\\nimport gcp.big...ields_str.split(\\'\\\\t\\'))\\nfeatures = fields[1:]', u'def mape(X, predictions, y):\\n  num_timeslots ...or.predict(X)\\n  return -mape(X, predictions, y)', u'from sklearn.linear_model import LogisticRegre...\\n\\n# Should return 0.0\\nmape(X, predictions, y)', u'get_ipython().run_cell_magic(u\\'sql\\', u\\'--mo...\\n\\\\n# The above query randomizes its outputs.\")', u'query = bq.Query(q_all)\\ntableresult = query.results()', u\"all_data = np.zeros((tableresult.length, len(f...\\n    print 'processed {} rows'.format(rcounter)\", u'# Get timeslots to test from GCS\\nitem = stora...'\".format(x), timeslots_to_test))\\nprint(tquery)', u'get_ipython().run_cell_magic(u\\'sql\\', u\\'--mo... if estimator can generalize well to new data.\")', u'query_t = bq.Query(q_all_t)\\ntableresult_t = query_t.results()', u\"all_data_t = np.zeros((tableresult_t.length, l...\\n    print 'processed {} rows'.format(rcounter)\", u'# Useful code to check NaN and Inf values. Thi...l_data))\\nprint \"np.max=\", np.max(abs(all_data))', u'all_data[np.isnan(all_data)] = 0\\nall_data_t[np.isnan(all_data_t)] = 0', u'# Useful code to check NaN and Inf values. Thi...l_data))\\nprint \"np.max=\", np.max(abs(all_data))', ...], 'LogisticRegression': <class 'sklearn.linear_model.logistic.LogisticRegression'>, 'Out': {3: 0.0, 9: 0.0, 20: Pipeline(steps=[('estimate', DecisionTreeRegress...random_state=None,\n           splitter='best'))]), 24: Pipeline(steps=[('estimate', RandomForestRegress...=None,\n           verbose=0, warm_start=False))]), 27: Pipeline(steps=[('estimate', RandomForestRegress...=None,\n           verbose=0, warm_start=False))])}, 'Pipeline': <class 'sklearn.pipeline.Pipeline'>, 'RandomForestRegressor': <class 'sklearn.ensemble.forest.RandomForestRegressor'>, ...}\n        self.user_ns = {'AdaBoostRegressor': <class 'sklearn.ensemble.weight_boosting.AdaBoostRegressor'>, 'DecisionTreeRegressor': <class 'sklearn.tree.tree.DecisionTreeRegressor'>, 'EST_PICKLE_FILENAME': 'baseline_final_estimator.pkl', 'GridSearchCV': <class 'sklearn.grid_search.GridSearchCV'>, 'Imputer': <class 'sklearn.preprocessing.imputation.Imputer'>, 'In': ['', u'import pdb\\nimport numpy as np\\nimport gcp.big...ields_str.split(\\'\\\\t\\'))\\nfeatures = fields[1:]', u'def mape(X, predictions, y):\\n  num_timeslots ...or.predict(X)\\n  return -mape(X, predictions, y)', u'from sklearn.linear_model import LogisticRegre...\\n\\n# Should return 0.0\\nmape(X, predictions, y)', u'get_ipython().run_cell_magic(u\\'sql\\', u\\'--mo...\\n\\\\n# The above query randomizes its outputs.\")', u'query = bq.Query(q_all)\\ntableresult = query.results()', u\"all_data = np.zeros((tableresult.length, len(f...\\n    print 'processed {} rows'.format(rcounter)\", u'import pdb\\nimport numpy as np\\nimport gcp.big...ields_str.split(\\'\\\\t\\'))\\nfeatures = fields[1:]', u'def mape(X, predictions, y):\\n  num_timeslots ...or.predict(X)\\n  return -mape(X, predictions, y)', u'from sklearn.linear_model import LogisticRegre...\\n\\n# Should return 0.0\\nmape(X, predictions, y)', u'get_ipython().run_cell_magic(u\\'sql\\', u\\'--mo...\\n\\\\n# The above query randomizes its outputs.\")', u'query = bq.Query(q_all)\\ntableresult = query.results()', u\"all_data = np.zeros((tableresult.length, len(f...\\n    print 'processed {} rows'.format(rcounter)\", u'# Get timeslots to test from GCS\\nitem = stora...'\".format(x), timeslots_to_test))\\nprint(tquery)', u'get_ipython().run_cell_magic(u\\'sql\\', u\\'--mo... if estimator can generalize well to new data.\")', u'query_t = bq.Query(q_all_t)\\ntableresult_t = query_t.results()', u\"all_data_t = np.zeros((tableresult_t.length, l...\\n    print 'processed {} rows'.format(rcounter)\", u'# Useful code to check NaN and Inf values. Thi...l_data))\\nprint \"np.max=\", np.max(abs(all_data))', u'all_data[np.isnan(all_data)] = 0\\nall_data_t[np.isnan(all_data_t)] = 0', u'# Useful code to check NaN and Inf values. Thi...l_data))\\nprint \"np.max=\", np.max(abs(all_data))', ...], 'LogisticRegression': <class 'sklearn.linear_model.logistic.LogisticRegression'>, 'Out': {3: 0.0, 9: 0.0, 20: Pipeline(steps=[('estimate', DecisionTreeRegress...random_state=None,\n           splitter='best'))]), 24: Pipeline(steps=[('estimate', RandomForestRegress...=None,\n           verbose=0, warm_start=False))]), 27: Pipeline(steps=[('estimate', RandomForestRegress...=None,\n           verbose=0, warm_start=False))])}, 'Pipeline': <class 'sklearn.pipeline.Pipeline'>, 'RandomForestRegressor': <class 'sklearn.ensemble.forest.RandomForestRegressor'>, ...}\n   2886             finally:\n   2887                 # Reset our crash handler in place\n   2888                 sys.excepthook = old_excepthook\n   2889         except SystemExit as e:\n\n...........................................................................\n/content/TeguhWPurwanto@gmail.com/Xiaojukeji Algorithm Competition/<ipython-input-31-77a67d18d2e5> in <module>()\n     45   scoring=mape_scorer,\n     46   n_jobs=2,\n     47   verbose=1\n     48 )\n     49 \n---> 50 search_params.fit(data_train, targets_train)\n     51 print(search_params.grid_scores_)\n     52 print(search_params.best_params_)\n     53 print(search_params.best_score_)\n     54 search_params.best_estimator_\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/sklearn/grid_search.py in fit(self=GridSearchCV(cv=5, error_score='raise',\n       e...nction mape_scorer at 0x7f99d626d398>, verbose=1), X=array([[  17.,    3.,    0., ...,  106.,    1., ...[  56.,    5.,    0., ...,    0.,    0.,    4.]]), y=array([ 46.,  32.,  33., ...,   9.,  34.,  42.]))\n    727         y : array-like, shape = [n_samples] or [n_samples, n_output], optional\n    728             Target relative to X for classification or regression;\n    729             None for unsupervised learning.\n    730 \n    731         \"\"\"\n--> 732         return self._fit(X, y, ParameterGrid(self.param_grid))\n        self._fit = <bound method GridSearchCV._fit of GridSearchCV(...ction mape_scorer at 0x7f99d626d398>, verbose=1)>\n        X = array([[  17.,    3.,    0., ...,  106.,    1., ...[  56.,    5.,    0., ...,    0.,    0.,    4.]])\n        y = array([ 46.,  32.,  33., ...,   9.,  34.,  42.])\n        self.param_grid = {'estimate__n_estimators': [5, 10, 20, 50, 60, 80], 'estimate_learning_rate': [0.1, 0.3, 0.7, 1, 3, 5, 10]}\n    733 \n    734 \n    735 class RandomizedSearchCV(BaseSearchCV):\n    736     \"\"\"Randomized search on hyper parameters.\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/sklearn/grid_search.py in _fit(self=GridSearchCV(cv=5, error_score='raise',\n       e...nction mape_scorer at 0x7f99d626d398>, verbose=1), X=array([[  17.,    3.,    0., ...,  106.,    1., ...[  56.,    5.,    0., ...,    0.,    0.,    4.]]), y=array([ 46.,  32.,  33., ...,   9.,  34.,  42.]), parameter_iterable=<sklearn.grid_search.ParameterGrid object>)\n    500         )(\n    501             delayed(_fit_and_score)(clone(base_estimator), X, y, self.scorer_,\n    502                                     train, test, self.verbose, parameters,\n    503                                     self.fit_params, return_parameters=True,\n    504                                     error_score=self.error_score)\n--> 505                 for parameters in parameter_iterable\n        parameters = undefined\n        parameter_iterable = <sklearn.grid_search.ParameterGrid object>\n    506                 for train, test in cv)\n    507 \n    508         # Out is a list of triplet: score, estimator, n_test_samples\n    509         n_fits = len(out)\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=2), iterable=<itertools.islice object>)\n    661             if pre_dispatch == \"all\" or n_jobs == 1:\n    662                 # The iterable was consumed all at once by the above for loop.\n    663                 # No need to wait for async callbacks to trigger to\n    664                 # consumption.\n    665                 self._iterating = False\n--> 666             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=2)>\n    667             # Make sure that we get a last message telling us we are done\n    668             elapsed_time = time.time() - self._start_time\n    669             self._print('Done %3i out of %3i | elapsed: %s finished',\n    670                         (len(self._output),\n\n    ---------------------------------------------------------------------------\n    Sub-process traceback:\n    ---------------------------------------------------------------------------\n    ValueError                                         Sun Jun 12 12:52:44 2016\nPID: 4116                                     Python 2.7.9: /usr/bin/python\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/sklearn/cross_validation.pyc in _fit_and_score(estimator=Pipeline(steps=[('estimate', AdaBoostRegressor(b...,\n         n_estimators=50, random_state=None))]), X=array([[  17.,    3.,    0., ...,  106.,    1., ...[  56.,    5.,    0., ...,    0.,    0.,    4.]]), y=array([ 46.,  32.,  33., ...,   9.,  34.,  42.]), scorer=<function mape_scorer>, train=array([ 20536,  20537,  20538, ..., 102677, 102678, 102679]), test=array([    0,     1,     2, ..., 20533, 20534, 20535]), verbose=1, parameters={'estimate__n_estimators': 5, 'estimate_learning_rate': 0.1}, fit_params={}, return_train_score=False, return_parameters=True, error_score='raise')\n   1443     fit_params = fit_params if fit_params is not None else {}\n   1444     fit_params = dict([(k, _index_param_value(X, v, train))\n   1445                       for k, v in fit_params.items()])\n   1446 \n   1447     if parameters is not None:\n-> 1448         estimator.set_params(**parameters)\n   1449 \n   1450     start_time = time.time()\n   1451 \n   1452     X_train, y_train = _safe_split(estimator, X, y, train)\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/sklearn/base.pyc in set_params(self=Pipeline(steps=[('estimate', AdaBoostRegressor(b...,\n         n_estimators=50, random_state=None))]), **params={'estimate__n_estimators': 5, 'estimate_learning_rate': 0.1})\n    251                 sub_object.set_params(**{sub_name: value})\n    252             else:\n    253                 # simple objects case\n    254                 if not key in valid_params:\n    255                     raise ValueError('Invalid parameter %s ' 'for estimator %s'\n--> 256                                      % (key, self.__class__.__name__))\n    257                 setattr(self, key, value)\n    258         return self\n    259 \n    260     def __repr__(self):\n\nValueError: Invalid parameter estimate_learning_rate for estimator Pipeline\n___________________________________________________________________________",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m\u001b[0m",
      "\u001b[1;31mJoblibValueError\u001b[0mTraceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-77a67d18d2e5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     48\u001b[0m )\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 50\u001b[1;33m \u001b[0msearch_params\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     51\u001b[0m \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msearch_params\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrid_scores_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msearch_params\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/sklearn/grid_search.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    730\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    731\u001b[0m         \"\"\"\n\u001b[1;32m--> 732\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    733\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    734\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/sklearn/grid_search.pyc\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, parameter_iterable)\u001b[0m\n\u001b[0;32m    503\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_parameters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    504\u001b[0m                                     error_score=self.error_score)\n\u001b[1;32m--> 505\u001b[1;33m                 \u001b[1;32mfor\u001b[0m \u001b[0mparameters\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mparameter_iterable\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    506\u001b[0m                 for train, test in cv)\n\u001b[0;32m    507\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    664\u001b[0m                 \u001b[1;31m# consumption.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    665\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 666\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    667\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    668\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    547\u001b[0m                         \u001b[1;31m# Convert this to a JoblibException\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    548\u001b[0m                         \u001b[0mexception_type\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_mk_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexception\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0metype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 549\u001b[1;33m                         \u001b[1;32mraise\u001b[0m \u001b[0mexception_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreport\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    550\u001b[0m                     \u001b[1;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    551\u001b[0m                 \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mJoblibValueError\u001b[0m: JoblibValueError\n___________________________________________________________________________\nMultiprocessing exception:\n    ...........................................................................\n/usr/lib/python2.7/runpy.py in _run_module_as_main(mod_name='ipykernel.__main__', alter_argv=1)\n    157     pkg_name = mod_name.rpartition('.')[0]\n    158     main_globals = sys.modules[\"__main__\"].__dict__\n    159     if alter_argv:\n    160         sys.argv[0] = fname\n    161     return _run_code(code, main_globals, None,\n--> 162                      \"__main__\", fname, loader, pkg_name)\n        fname = '/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py'\n        loader = <pkgutil.ImpLoader instance>\n        pkg_name = 'ipykernel'\n    163 \n    164 def run_module(mod_name, init_globals=None,\n    165                run_name=None, alter_sys=False):\n    166     \"\"\"Execute a module's code without importing it\n\n...........................................................................\n/usr/lib/python2.7/runpy.py in _run_code(code=<code object <module> at 0x7f99f453b330, file \"/...2.7/dist-packages/ipykernel/__main__.py\", line 1>, run_globals={'__builtins__': <module '__builtin__' (built-in)>, '__doc__': None, '__file__': '/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py', '__loader__': <pkgutil.ImpLoader instance>, '__name__': '__main__', '__package__': 'ipykernel', 'app': <module 'ipykernel.kernelapp' from '/usr/local/lib/python2.7/dist-packages/ipykernel/kernelapp.pyc'>}, init_globals=None, mod_name='__main__', mod_fname='/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py', mod_loader=<pkgutil.ImpLoader instance>, pkg_name='ipykernel')\n     67         run_globals.update(init_globals)\n     68     run_globals.update(__name__ = mod_name,\n     69                        __file__ = mod_fname,\n     70                        __loader__ = mod_loader,\n     71                        __package__ = pkg_name)\n---> 72     exec code in run_globals\n        code = <code object <module> at 0x7f99f453b330, file \"/...2.7/dist-packages/ipykernel/__main__.py\", line 1>\n        run_globals = {'__builtins__': <module '__builtin__' (built-in)>, '__doc__': None, '__file__': '/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py', '__loader__': <pkgutil.ImpLoader instance>, '__name__': '__main__', '__package__': 'ipykernel', 'app': <module 'ipykernel.kernelapp' from '/usr/local/lib/python2.7/dist-packages/ipykernel/kernelapp.pyc'>}\n     73     return run_globals\n     74 \n     75 def _run_module_code(code, init_globals=None,\n     76                     mod_name=None, mod_fname=None,\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py in <module>()\n      1 \n      2 \n----> 3 \n      4 if __name__ == '__main__':\n      5     from ipykernel import kernelapp as app\n      6     app.launch_new_instance()\n      7 \n      8 \n      9 \n     10 \n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/traitlets/config/application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    591         \n    592         If a global instance already exists, this reinitializes and starts it\n    593         \"\"\"\n    594         app = cls.instance(**kwargs)\n    595         app.initialize(argv)\n--> 596         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    597 \n    598 #-----------------------------------------------------------------------------\n    599 # utility functions, for convenience\n    600 #-----------------------------------------------------------------------------\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/ipykernel/kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    437         \n    438         if self.poller is not None:\n    439             self.poller.start()\n    440         self.kernel.start()\n    441         try:\n--> 442             ioloop.IOLoop.instance().start()\n    443         except KeyboardInterrupt:\n    444             pass\n    445 \n    446 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/zmq/eventloop/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    157             PollIOLoop.configure(ZMQIOLoop)\n    158         return PollIOLoop.current(*args, **kwargs)\n    159     \n    160     def start(self):\n    161         try:\n--> 162             super(ZMQIOLoop, self).start()\n        self.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    163         except ZMQError as e:\n    164             if e.errno == ETERM:\n    165                 # quietly return on ETERM\n    166                 pass\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/tornado/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    878                 self._events.update(event_pairs)\n    879                 while self._events:\n    880                     fd, events = self._events.popitem()\n    881                     try:\n    882                         fd_obj, handler_func = self._handlers[fd]\n--> 883                         handler_func(fd_obj, events)\n        handler_func = <function null_wrapper>\n        fd_obj = <zmq.sugar.socket.Socket object>\n        events = 1\n    884                     except (OSError, IOError) as e:\n    885                         if errno_from_exception(e) == errno.EPIPE:\n    886                             # Happens when the client closes the connection\n    887                             pass\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/tornado/stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    270         # Fast path when there are no active contexts.\n    271         def null_wrapper(*args, **kwargs):\n    272             try:\n    273                 current_state = _state.contexts\n    274                 _state.contexts = cap_contexts[0]\n--> 275                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    276             finally:\n    277                 _state.contexts = current_state\n    278         null_wrapper._wrapped = True\n    279         return null_wrapper\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    435             # dispatch events:\n    436             if events & IOLoop.ERROR:\n    437                 gen_log.error(\"got POLLERR event on ZMQStream, which doesn't make sense\")\n    438                 return\n    439             if events & IOLoop.READ:\n--> 440                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    441                 if not self.socket:\n    442                     return\n    443             if events & IOLoop.WRITE:\n    444                 self._handle_send()\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    467                 gen_log.error(\"RECV Error: %s\"%zmq.strerror(e.errno))\n    468         else:\n    469             if self._recv_callback:\n    470                 callback = self._recv_callback\n    471                 # self._recv_callback = None\n--> 472                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    473                 \n    474         # self.update_state()\n    475         \n    476 \n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    409         close our socket.\"\"\"\n    410         try:\n    411             # Use a NullContext to ensure that all StackContexts are run\n    412             # inside our blanket exception handler rather than outside.\n    413             with stack_context.NullContext():\n--> 414                 callback(*args, **kwargs)\n        callback = <function null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    415         except:\n    416             gen_log.error(\"Uncaught exception, closing connection.\",\n    417                           exc_info=True)\n    418             # Close the socket on an uncaught exception from a user callback\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/tornado/stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    270         # Fast path when there are no active contexts.\n    271         def null_wrapper(*args, **kwargs):\n    272             try:\n    273                 current_state = _state.contexts\n    274                 _state.contexts = cap_contexts[0]\n--> 275                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    276             finally:\n    277                 _state.contexts = current_state\n    278         null_wrapper._wrapped = True\n    279         return null_wrapper\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    271         if self.control_stream:\n    272             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    273 \n    274         def make_dispatcher(stream):\n    275             def dispatcher(msg):\n--> 276                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    277             return dispatcher\n    278 \n    279         for s in self.shell_streams:\n    280             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {u'allow_stdin': True, u'code': u'from sklearn.feature_selection import SelectKB...rams.best_score_)\\nsearch_params.best_estimator_', u'silent': False, u'stop_on_error': True, u'store_history': True, u'user_expressions': {}}, 'header': {'date': '2016-06-12T12:52:44.380983', u'msg_id': u'51BC7D2045F34C1DBFB596E8921EC318', u'msg_type': u'execute_request', u'session': u'CEF40C66C22B4B51AB5041666FFC5A00', u'username': u'username', u'version': u'5.0'}, 'metadata': {}, 'msg_id': u'51BC7D2045F34C1DBFB596E8921EC318', 'msg_type': u'execute_request', 'parent_header': {}})\n    223             self.log.error(\"UNKNOWN MESSAGE TYPE: %r\", msg_type)\n    224         else:\n    225             self.log.debug(\"%s: %s\", msg_type, msg)\n    226             self.pre_handler_hook()\n    227             try:\n--> 228                 handler(stream, idents, msg)\n        handler = <bound method IPythonKernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = ['CEF40C66C22B4B51AB5041666FFC5A00']\n        msg = {'buffers': [], 'content': {u'allow_stdin': True, u'code': u'from sklearn.feature_selection import SelectKB...rams.best_score_)\\nsearch_params.best_estimator_', u'silent': False, u'stop_on_error': True, u'store_history': True, u'user_expressions': {}}, 'header': {'date': '2016-06-12T12:52:44.380983', u'msg_id': u'51BC7D2045F34C1DBFB596E8921EC318', u'msg_type': u'execute_request', u'session': u'CEF40C66C22B4B51AB5041666FFC5A00', u'username': u'username', u'version': u'5.0'}, 'metadata': {}, 'msg_id': u'51BC7D2045F34C1DBFB596E8921EC318', 'msg_type': u'execute_request', 'parent_header': {}}\n    229             except Exception:\n    230                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    231             finally:\n    232                 self.post_handler_hook()\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=['CEF40C66C22B4B51AB5041666FFC5A00'], parent={'buffers': [], 'content': {u'allow_stdin': True, u'code': u'from sklearn.feature_selection import SelectKB...rams.best_score_)\\nsearch_params.best_estimator_', u'silent': False, u'stop_on_error': True, u'store_history': True, u'user_expressions': {}}, 'header': {'date': '2016-06-12T12:52:44.380983', u'msg_id': u'51BC7D2045F34C1DBFB596E8921EC318', u'msg_type': u'execute_request', u'session': u'CEF40C66C22B4B51AB5041666FFC5A00', u'username': u'username', u'version': u'5.0'}, 'metadata': {}, 'msg_id': u'51BC7D2045F34C1DBFB596E8921EC318', 'msg_type': u'execute_request', 'parent_header': {}})\n    386         if not silent:\n    387             self.execution_count += 1\n    388             self._publish_execute_input(code, parent, self.execution_count)\n    389 \n    390         reply_content = self.do_execute(code, silent, store_history,\n--> 391                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    392 \n    393         # Flush output before sending the reply.\n    394         sys.stdout.flush()\n    395         sys.stderr.flush()\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/ipykernel/ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code=u'from sklearn.feature_selection import SelectKB...rams.best_score_)\\nsearch_params.best_estimator_', silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    194 \n    195         reply_content = {}\n    196         # FIXME: the shell calls the exception handler itself.\n    197         shell._reply_content = None\n    198         try:\n--> 199             shell.run_cell(code, store_history=store_history, silent=silent)\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = u'from sklearn.feature_selection import SelectKB...rams.best_score_)\\nsearch_params.best_estimator_'\n        store_history = True\n        silent = False\n    200         except:\n    201             status = u'error'\n    202             # FIXME: this code right now isn't being used yet by default,\n    203             # because the run_cell() call above directly fires off exception\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell=u'from sklearn.feature_selection import SelectKB...rams.best_score_)\\nsearch_params.best_estimator_', store_history=True, silent=False, shell_futures=True)\n   2718                 self.displayhook.exec_result = result\n   2719 \n   2720                 # Execute the user code\n   2721                 interactivity = \"none\" if silent else self.ast_node_interactivity\n   2722                 self.run_ast_nodes(code_ast.body, cell_name,\n-> 2723                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler instance>\n   2724 \n   2725                 # Reset this so later displayed values do not modify the\n   2726                 # ExecutionResult\n   2727                 self.displayhook.exec_result = None\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.ImportFrom object>, <_ast.ImportFrom object>, <_ast.ImportFrom object>, <_ast.ImportFrom object>, <_ast.ImportFrom object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Expr object>, <_ast.Print object>, <_ast.Print object>, <_ast.Print object>, <_ast.Expr object>], cell_name='<ipython-input-31-77a67d18d2e5>', interactivity='last', compiler=<IPython.core.compilerop.CachingCompiler instance>, result=<IPython.core.interactiveshell.ExecutionResult object>)\n   2820 \n   2821         try:\n   2822             for i, node in enumerate(to_run_exec):\n   2823                 mod = ast.Module([node])\n   2824                 code = compiler(mod, cell_name, \"exec\")\n-> 2825                 if self.run_code(code, result):\n        self.run_code = <bound method ZMQInteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x7f99bfbd0a30, file \"<ipython-input-31-77a67d18d2e5>\", line 50>\n        result = <IPython.core.interactiveshell.ExecutionResult object>\n   2826                     return True\n   2827 \n   2828             for i, node in enumerate(to_run_interactive):\n   2829                 mod = ast.Interactive([node])\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x7f99bfbd0a30, file \"<ipython-input-31-77a67d18d2e5>\", line 50>, result=<IPython.core.interactiveshell.ExecutionResult object>)\n   2880         outflag = 1  # happens in more places, so it's easier as default\n   2881         try:\n   2882             try:\n   2883                 self.hooks.pre_run_code_hook()\n   2884                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2885                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x7f99bfbd0a30, file \"<ipython-input-31-77a67d18d2e5>\", line 50>\n        self.user_global_ns = {'AdaBoostRegressor': <class 'sklearn.ensemble.weight_boosting.AdaBoostRegressor'>, 'DecisionTreeRegressor': <class 'sklearn.tree.tree.DecisionTreeRegressor'>, 'EST_PICKLE_FILENAME': 'baseline_final_estimator.pkl', 'GridSearchCV': <class 'sklearn.grid_search.GridSearchCV'>, 'Imputer': <class 'sklearn.preprocessing.imputation.Imputer'>, 'In': ['', u'import pdb\\nimport numpy as np\\nimport gcp.big...ields_str.split(\\'\\\\t\\'))\\nfeatures = fields[1:]', u'def mape(X, predictions, y):\\n  num_timeslots ...or.predict(X)\\n  return -mape(X, predictions, y)', u'from sklearn.linear_model import LogisticRegre...\\n\\n# Should return 0.0\\nmape(X, predictions, y)', u'get_ipython().run_cell_magic(u\\'sql\\', u\\'--mo...\\n\\\\n# The above query randomizes its outputs.\")', u'query = bq.Query(q_all)\\ntableresult = query.results()', u\"all_data = np.zeros((tableresult.length, len(f...\\n    print 'processed {} rows'.format(rcounter)\", u'import pdb\\nimport numpy as np\\nimport gcp.big...ields_str.split(\\'\\\\t\\'))\\nfeatures = fields[1:]', u'def mape(X, predictions, y):\\n  num_timeslots ...or.predict(X)\\n  return -mape(X, predictions, y)', u'from sklearn.linear_model import LogisticRegre...\\n\\n# Should return 0.0\\nmape(X, predictions, y)', u'get_ipython().run_cell_magic(u\\'sql\\', u\\'--mo...\\n\\\\n# The above query randomizes its outputs.\")', u'query = bq.Query(q_all)\\ntableresult = query.results()', u\"all_data = np.zeros((tableresult.length, len(f...\\n    print 'processed {} rows'.format(rcounter)\", u'# Get timeslots to test from GCS\\nitem = stora...'\".format(x), timeslots_to_test))\\nprint(tquery)', u'get_ipython().run_cell_magic(u\\'sql\\', u\\'--mo... if estimator can generalize well to new data.\")', u'query_t = bq.Query(q_all_t)\\ntableresult_t = query_t.results()', u\"all_data_t = np.zeros((tableresult_t.length, l...\\n    print 'processed {} rows'.format(rcounter)\", u'# Useful code to check NaN and Inf values. Thi...l_data))\\nprint \"np.max=\", np.max(abs(all_data))', u'all_data[np.isnan(all_data)] = 0\\nall_data_t[np.isnan(all_data_t)] = 0', u'# Useful code to check NaN and Inf values. Thi...l_data))\\nprint \"np.max=\", np.max(abs(all_data))', ...], 'LogisticRegression': <class 'sklearn.linear_model.logistic.LogisticRegression'>, 'Out': {3: 0.0, 9: 0.0, 20: Pipeline(steps=[('estimate', DecisionTreeRegress...random_state=None,\n           splitter='best'))]), 24: Pipeline(steps=[('estimate', RandomForestRegress...=None,\n           verbose=0, warm_start=False))]), 27: Pipeline(steps=[('estimate', RandomForestRegress...=None,\n           verbose=0, warm_start=False))])}, 'Pipeline': <class 'sklearn.pipeline.Pipeline'>, 'RandomForestRegressor': <class 'sklearn.ensemble.forest.RandomForestRegressor'>, ...}\n        self.user_ns = {'AdaBoostRegressor': <class 'sklearn.ensemble.weight_boosting.AdaBoostRegressor'>, 'DecisionTreeRegressor': <class 'sklearn.tree.tree.DecisionTreeRegressor'>, 'EST_PICKLE_FILENAME': 'baseline_final_estimator.pkl', 'GridSearchCV': <class 'sklearn.grid_search.GridSearchCV'>, 'Imputer': <class 'sklearn.preprocessing.imputation.Imputer'>, 'In': ['', u'import pdb\\nimport numpy as np\\nimport gcp.big...ields_str.split(\\'\\\\t\\'))\\nfeatures = fields[1:]', u'def mape(X, predictions, y):\\n  num_timeslots ...or.predict(X)\\n  return -mape(X, predictions, y)', u'from sklearn.linear_model import LogisticRegre...\\n\\n# Should return 0.0\\nmape(X, predictions, y)', u'get_ipython().run_cell_magic(u\\'sql\\', u\\'--mo...\\n\\\\n# The above query randomizes its outputs.\")', u'query = bq.Query(q_all)\\ntableresult = query.results()', u\"all_data = np.zeros((tableresult.length, len(f...\\n    print 'processed {} rows'.format(rcounter)\", u'import pdb\\nimport numpy as np\\nimport gcp.big...ields_str.split(\\'\\\\t\\'))\\nfeatures = fields[1:]', u'def mape(X, predictions, y):\\n  num_timeslots ...or.predict(X)\\n  return -mape(X, predictions, y)', u'from sklearn.linear_model import LogisticRegre...\\n\\n# Should return 0.0\\nmape(X, predictions, y)', u'get_ipython().run_cell_magic(u\\'sql\\', u\\'--mo...\\n\\\\n# The above query randomizes its outputs.\")', u'query = bq.Query(q_all)\\ntableresult = query.results()', u\"all_data = np.zeros((tableresult.length, len(f...\\n    print 'processed {} rows'.format(rcounter)\", u'# Get timeslots to test from GCS\\nitem = stora...'\".format(x), timeslots_to_test))\\nprint(tquery)', u'get_ipython().run_cell_magic(u\\'sql\\', u\\'--mo... if estimator can generalize well to new data.\")', u'query_t = bq.Query(q_all_t)\\ntableresult_t = query_t.results()', u\"all_data_t = np.zeros((tableresult_t.length, l...\\n    print 'processed {} rows'.format(rcounter)\", u'# Useful code to check NaN and Inf values. Thi...l_data))\\nprint \"np.max=\", np.max(abs(all_data))', u'all_data[np.isnan(all_data)] = 0\\nall_data_t[np.isnan(all_data_t)] = 0', u'# Useful code to check NaN and Inf values. Thi...l_data))\\nprint \"np.max=\", np.max(abs(all_data))', ...], 'LogisticRegression': <class 'sklearn.linear_model.logistic.LogisticRegression'>, 'Out': {3: 0.0, 9: 0.0, 20: Pipeline(steps=[('estimate', DecisionTreeRegress...random_state=None,\n           splitter='best'))]), 24: Pipeline(steps=[('estimate', RandomForestRegress...=None,\n           verbose=0, warm_start=False))]), 27: Pipeline(steps=[('estimate', RandomForestRegress...=None,\n           verbose=0, warm_start=False))])}, 'Pipeline': <class 'sklearn.pipeline.Pipeline'>, 'RandomForestRegressor': <class 'sklearn.ensemble.forest.RandomForestRegressor'>, ...}\n   2886             finally:\n   2887                 # Reset our crash handler in place\n   2888                 sys.excepthook = old_excepthook\n   2889         except SystemExit as e:\n\n...........................................................................\n/content/TeguhWPurwanto@gmail.com/Xiaojukeji Algorithm Competition/<ipython-input-31-77a67d18d2e5> in <module>()\n     45   scoring=mape_scorer,\n     46   n_jobs=2,\n     47   verbose=1\n     48 )\n     49 \n---> 50 search_params.fit(data_train, targets_train)\n     51 print(search_params.grid_scores_)\n     52 print(search_params.best_params_)\n     53 print(search_params.best_score_)\n     54 search_params.best_estimator_\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/sklearn/grid_search.py in fit(self=GridSearchCV(cv=5, error_score='raise',\n       e...nction mape_scorer at 0x7f99d626d398>, verbose=1), X=array([[  17.,    3.,    0., ...,  106.,    1., ...[  56.,    5.,    0., ...,    0.,    0.,    4.]]), y=array([ 46.,  32.,  33., ...,   9.,  34.,  42.]))\n    727         y : array-like, shape = [n_samples] or [n_samples, n_output], optional\n    728             Target relative to X for classification or regression;\n    729             None for unsupervised learning.\n    730 \n    731         \"\"\"\n--> 732         return self._fit(X, y, ParameterGrid(self.param_grid))\n        self._fit = <bound method GridSearchCV._fit of GridSearchCV(...ction mape_scorer at 0x7f99d626d398>, verbose=1)>\n        X = array([[  17.,    3.,    0., ...,  106.,    1., ...[  56.,    5.,    0., ...,    0.,    0.,    4.]])\n        y = array([ 46.,  32.,  33., ...,   9.,  34.,  42.])\n        self.param_grid = {'estimate__n_estimators': [5, 10, 20, 50, 60, 80], 'estimate_learning_rate': [0.1, 0.3, 0.7, 1, 3, 5, 10]}\n    733 \n    734 \n    735 class RandomizedSearchCV(BaseSearchCV):\n    736     \"\"\"Randomized search on hyper parameters.\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/sklearn/grid_search.py in _fit(self=GridSearchCV(cv=5, error_score='raise',\n       e...nction mape_scorer at 0x7f99d626d398>, verbose=1), X=array([[  17.,    3.,    0., ...,  106.,    1., ...[  56.,    5.,    0., ...,    0.,    0.,    4.]]), y=array([ 46.,  32.,  33., ...,   9.,  34.,  42.]), parameter_iterable=<sklearn.grid_search.ParameterGrid object>)\n    500         )(\n    501             delayed(_fit_and_score)(clone(base_estimator), X, y, self.scorer_,\n    502                                     train, test, self.verbose, parameters,\n    503                                     self.fit_params, return_parameters=True,\n    504                                     error_score=self.error_score)\n--> 505                 for parameters in parameter_iterable\n        parameters = undefined\n        parameter_iterable = <sklearn.grid_search.ParameterGrid object>\n    506                 for train, test in cv)\n    507 \n    508         # Out is a list of triplet: score, estimator, n_test_samples\n    509         n_fits = len(out)\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=2), iterable=<itertools.islice object>)\n    661             if pre_dispatch == \"all\" or n_jobs == 1:\n    662                 # The iterable was consumed all at once by the above for loop.\n    663                 # No need to wait for async callbacks to trigger to\n    664                 # consumption.\n    665                 self._iterating = False\n--> 666             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=2)>\n    667             # Make sure that we get a last message telling us we are done\n    668             elapsed_time = time.time() - self._start_time\n    669             self._print('Done %3i out of %3i | elapsed: %s finished',\n    670                         (len(self._output),\n\n    ---------------------------------------------------------------------------\n    Sub-process traceback:\n    ---------------------------------------------------------------------------\n    ValueError                                         Sun Jun 12 12:52:44 2016\nPID: 4116                                     Python 2.7.9: /usr/bin/python\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/sklearn/cross_validation.pyc in _fit_and_score(estimator=Pipeline(steps=[('estimate', AdaBoostRegressor(b...,\n         n_estimators=50, random_state=None))]), X=array([[  17.,    3.,    0., ...,  106.,    1., ...[  56.,    5.,    0., ...,    0.,    0.,    4.]]), y=array([ 46.,  32.,  33., ...,   9.,  34.,  42.]), scorer=<function mape_scorer>, train=array([ 20536,  20537,  20538, ..., 102677, 102678, 102679]), test=array([    0,     1,     2, ..., 20533, 20534, 20535]), verbose=1, parameters={'estimate__n_estimators': 5, 'estimate_learning_rate': 0.1}, fit_params={}, return_train_score=False, return_parameters=True, error_score='raise')\n   1443     fit_params = fit_params if fit_params is not None else {}\n   1444     fit_params = dict([(k, _index_param_value(X, v, train))\n   1445                       for k, v in fit_params.items()])\n   1446 \n   1447     if parameters is not None:\n-> 1448         estimator.set_params(**parameters)\n   1449 \n   1450     start_time = time.time()\n   1451 \n   1452     X_train, y_train = _safe_split(estimator, X, y, train)\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/sklearn/base.pyc in set_params(self=Pipeline(steps=[('estimate', AdaBoostRegressor(b...,\n         n_estimators=50, random_state=None))]), **params={'estimate__n_estimators': 5, 'estimate_learning_rate': 0.1})\n    251                 sub_object.set_params(**{sub_name: value})\n    252             else:\n    253                 # simple objects case\n    254                 if not key in valid_params:\n    255                     raise ValueError('Invalid parameter %s ' 'for estimator %s'\n--> 256                                      % (key, self.__class__.__name__))\n    257                 setattr(self, key, value)\n    258         return self\n    259 \n    260     def __repr__(self):\n\nValueError: Invalid parameter estimate_learning_rate for estimator Pipeline\n___________________________________________________________________________"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "# from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.preprocessing import Imputer\n",
    "# from sklearn.grid_search import RandomizedSearchCV\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "\n",
    "steps = [\n",
    "#   ('impute', Imputer(0)),\n",
    "#   ('feature_selection', SelectKBest(f_classif)),\n",
    "  ('estimate', AdaBoostRegressor())\n",
    "]\n",
    "\n",
    "est = Pipeline(steps)\n",
    "\n",
    "data_train = all_data[:,1:]\n",
    "targets_train = all_data[:,0]\n",
    "data_test = all_data_t[:,1:]\n",
    "targets_test = all_data_t[:,0]\n",
    "\n",
    "params = {\n",
    "#   \"feature_selection__k\": [i for i in range(1, len(features) - 1)]\n",
    "#   'estimate__max_features': [i for i in range(1, len(features))],\n",
    "#   'estimate__n_estimators': [5, 10, 15, 20, 30]\n",
    "  'estimate_learning_rate': [0.1, 0.3, 0.7, 1, 3, 5, 10],\n",
    "  'estimate__n_estimators': [5, 10, 20, 50, 60, 80]\n",
    "}\n",
    "# cross_validation_iter = StratifiedShuffleSplit(y=targets_train, test_size=0.3,\n",
    "#                                                random_state=RANDOM_STATE, n_iter=10)\n",
    "# search_params = RandomizedSearchCV(\n",
    "#   estimator=est,\n",
    "#   param_distributions=params,\n",
    "# #   cv=10,\n",
    "#   scoring=mape_scorer,\n",
    "#   n_jobs=2,\n",
    "#   n_iter=5\n",
    "# )\n",
    "\n",
    "search_params = GridSearchCV(\n",
    "  estimator=est,\n",
    "  param_grid=params,\n",
    "  cv=5,\n",
    "  scoring=mape_scorer,\n",
    "  n_jobs=2,\n",
    "  verbose=1\n",
    ")\n",
    "\n",
    "search_params.fit(data_train, targets_train)\n",
    "print(search_params.grid_scores_)\n",
    "print(search_params.best_params_)\n",
    "print(search_params.best_score_)\n",
    "search_params.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test data's prediction MAPE score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.34569095992\n",
      "2.34569095992\n",
      "2.34569095992\n"
     ]
    }
   ],
   "source": [
    "final_est = search_params.best_estimator_\n",
    "test_predictions = final_est.predict(data_test)\n",
    "print(mape(data_test, test_predictions, targets_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(final_est, open(EST_PICKLE_FILENAME, \"w\") )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run \"Process Final Test Data With Final Algorithm\" to use pickled final algorithm against final test data to produce csv required by this competition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(102680, 18)\n",
      "[[  1.70000000e+01   3.00000000e+00   0.00000000e+00   3.27000000e+02\n",
      "    2.97272727e+01   1.87671617e+04  -2.45115880e+03  -1.62980717e+04\n",
      "   -2.21621266e+04  -1.19145310e+03   7.28000000e+02   7.40000000e+01\n",
      "    2.30000000e+01   2.90000000e+01   2.00000000e+00   1.06000000e+02\n",
      "    1.00000000e+00   3.00000000e+00]\n",
      " [  1.09000000e+02   4.00000000e+00   0.00000000e+00   1.27000000e+02\n",
      "    1.81428571e+01  -6.11945684e+04   1.66019762e+03   2.40659554e+02\n",
      "    7.81203839e+03   3.14309459e+02   1.23000000e+02   1.90000000e+01\n",
      "    3.00000000e+00   1.00000000e+00   3.00000000e+00   1.24000000e+02\n",
      "    8.00000000e+00   4.00000000e+00]\n",
      " [  9.70000000e+01   4.00000000e+00   0.00000000e+00   2.49000000e+02\n",
      "    1.55625000e+01  -5.73741656e+04  -3.33111579e+03   2.33390366e+03\n",
      "    3.77453856e+03  -7.61532298e+02   2.34000000e+02   6.60000000e+01\n",
      "    1.80000000e+01   8.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   2.00000000e+00]\n",
      " [  3.50000000e+01   6.00000000e+00   0.00000000e+00   6.00000000e+00\n",
      "    6.00000000e+00  -6.42277681e+04   2.78168341e+03   2.42397866e+03\n",
      "    6.50884795e+03   3.59594688e+02   5.50000000e+01   0.00000000e+00\n",
      "    6.00000000e+00   2.00000000e+00   2.00000000e+00   1.79000000e+02\n",
      "    7.00000000e+00   1.00000000e+00]\n",
      " [  4.00000000e+01   2.00000000e+00   0.00000000e+00   4.65000000e+02\n",
      "    2.90625000e+01   1.87671617e+04  -2.45115880e+03  -1.62980717e+04\n",
      "   -2.21621266e+04  -1.19145310e+03   1.00100000e+03   1.08000000e+02\n",
      "    4.70000000e+01   4.10000000e+01   1.00000000e+00   1.50000000e+02\n",
      "    0.00000000e+00   6.00000000e+00]\n",
      " [  1.12000000e+02   2.00000000e+00   0.00000000e+00   1.70240000e+03\n",
      "    1.89155556e+01   1.95232410e+04  -4.96296783e+03   1.37424953e+03\n",
      "   -1.60827084e+04  -3.46889739e+03   9.90000000e+02   4.50000000e+02\n",
      "    1.14000000e+02   7.90000000e+01   4.00000000e+00   4.20000000e+01\n",
      "    8.00000000e+00   3.00000000e+00]\n",
      " [  1.05000000e+02   4.00000000e+00   0.00000000e+00   1.55100000e+02\n",
      "    2.58500000e+01  -4.91075399e+04   2.69284708e+03  -9.93523172e+03\n",
      "    3.29862388e+03   5.93549458e+03   4.22000000e+02   7.80000000e+01\n",
      "    2.50000000e+01   2.60000000e+01   3.00000000e+00   1.20000000e+02\n",
      "    9.00000000e+00   2.00000000e+00]\n",
      " [  8.00000000e+01   5.00000000e+00   0.00000000e+00   4.24700000e+02\n",
      "    1.93045455e+01  -5.55286688e+04   3.66578773e+03  -1.21680839e+02\n",
      "    5.69616021e+03   1.43615864e+03   5.49000000e+02   7.20000000e+01\n",
      "    3.00000000e+01   1.50000000e+01   2.00000000e+00   2.32000000e+02\n",
      "    1.00000000e+01   1.00000000e+00]\n",
      " [  9.90000000e+01   1.00000000e+00   0.00000000e+00   2.91030000e+03\n",
      "    1.90215686e+01   7.38786693e+04  -7.54669860e+03  -5.38295572e+03\n",
      "   -3.31725544e+04   1.29374034e+04   1.52000000e+03   3.91000000e+02\n",
      "    1.10000000e+02   1.03000000e+02   4.00000000e+00   5.50000000e+01\n",
      "    6.00000000e+00   6.00000000e+00]\n",
      " [  8.10000000e+01   6.00000000e+00   0.00000000e+00   4.70000000e+01\n",
      "    9.40000000e+00  -6.52416963e+04   3.02562811e+03   3.99735138e+03\n",
      "    9.04914780e+03  -1.38483728e+03   1.07000000e+02   1.10000000e+01\n",
      "    3.00000000e+00   0.00000000e+00   2.00000000e+00   1.57000000e+02\n",
      "    9.00000000e+00   2.00000000e+00]]\n",
      "(102680, 18)\n",
      "[[  1.70000000e+01   3.00000000e+00   0.00000000e+00   3.27000000e+02\n",
      "    2.97272727e+01   1.87671617e+04  -2.45115880e+03  -1.62980717e+04\n",
      "   -2.21621266e+04  -1.19145310e+03   7.28000000e+02   7.40000000e+01\n",
      "    2.30000000e+01   2.90000000e+01   2.00000000e+00   1.06000000e+02\n",
      "    1.00000000e+00   3.00000000e+00]\n",
      " [  1.09000000e+02   4.00000000e+00   0.00000000e+00   1.27000000e+02\n",
      "    1.81428571e+01  -6.11945684e+04   1.66019762e+03   2.40659554e+02\n",
      "    7.81203839e+03   3.14309459e+02   1.23000000e+02   1.90000000e+01\n",
      "    3.00000000e+00   1.00000000e+00   3.00000000e+00   1.24000000e+02\n",
      "    8.00000000e+00   4.00000000e+00]\n",
      " [  9.70000000e+01   4.00000000e+00   0.00000000e+00   2.49000000e+02\n",
      "    1.55625000e+01  -5.73741656e+04  -3.33111579e+03   2.33390366e+03\n",
      "    3.77453856e+03  -7.61532298e+02   2.34000000e+02   6.60000000e+01\n",
      "    1.80000000e+01   8.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   2.00000000e+00]\n",
      " [  3.50000000e+01   6.00000000e+00   0.00000000e+00   6.00000000e+00\n",
      "    6.00000000e+00  -6.42277681e+04   2.78168341e+03   2.42397866e+03\n",
      "    6.50884795e+03   3.59594688e+02   5.50000000e+01   0.00000000e+00\n",
      "    6.00000000e+00   2.00000000e+00   2.00000000e+00   1.79000000e+02\n",
      "    7.00000000e+00   1.00000000e+00]\n",
      " [  4.00000000e+01   2.00000000e+00   0.00000000e+00   4.65000000e+02\n",
      "    2.90625000e+01   1.87671617e+04  -2.45115880e+03  -1.62980717e+04\n",
      "   -2.21621266e+04  -1.19145310e+03   1.00100000e+03   1.08000000e+02\n",
      "    4.70000000e+01   4.10000000e+01   1.00000000e+00   1.50000000e+02\n",
      "    0.00000000e+00   6.00000000e+00]\n",
      " [  1.12000000e+02   2.00000000e+00   0.00000000e+00   1.70240000e+03\n",
      "    1.89155556e+01   1.95232410e+04  -4.96296783e+03   1.37424953e+03\n",
      "   -1.60827084e+04  -3.46889739e+03   9.90000000e+02   4.50000000e+02\n",
      "    1.14000000e+02   7.90000000e+01   4.00000000e+00   4.20000000e+01\n",
      "    8.00000000e+00   3.00000000e+00]\n",
      " [  1.05000000e+02   4.00000000e+00   0.00000000e+00   1.55100000e+02\n",
      "    2.58500000e+01  -4.91075399e+04   2.69284708e+03  -9.93523172e+03\n",
      "    3.29862388e+03   5.93549458e+03   4.22000000e+02   7.80000000e+01\n",
      "    2.50000000e+01   2.60000000e+01   3.00000000e+00   1.20000000e+02\n",
      "    9.00000000e+00   2.00000000e+00]\n",
      " [  8.00000000e+01   5.00000000e+00   0.00000000e+00   4.24700000e+02\n",
      "    1.93045455e+01  -5.55286688e+04   3.66578773e+03  -1.21680839e+02\n",
      "    5.69616021e+03   1.43615864e+03   5.49000000e+02   7.20000000e+01\n",
      "    3.00000000e+01   1.50000000e+01   2.00000000e+00   2.32000000e+02\n",
      "    1.00000000e+01   1.00000000e+00]\n",
      " [  9.90000000e+01   1.00000000e+00   0.00000000e+00   2.91030000e+03\n",
      "    1.90215686e+01   7.38786693e+04  -7.54669860e+03  -5.38295572e+03\n",
      "   -3.31725544e+04   1.29374034e+04   1.52000000e+03   3.91000000e+02\n",
      "    1.10000000e+02   1.03000000e+02   4.00000000e+00   5.50000000e+01\n",
      "    6.00000000e+00   6.00000000e+00]\n",
      " [  8.10000000e+01   6.00000000e+00   0.00000000e+00   4.70000000e+01\n",
      "    9.40000000e+00  -6.52416963e+04   3.02562811e+03   3.99735138e+03\n",
      "    9.04914780e+03  -1.38483728e+03   1.07000000e+02   1.10000000e+01\n",
      "    3.00000000e+00   0.00000000e+00   2.00000000e+00   1.57000000e+02\n",
      "    9.00000000e+00   2.00000000e+00]]\n",
      "(102680, 18)\n",
      "[[  1.70000000e+01   3.00000000e+00   0.00000000e+00   3.27000000e+02\n",
      "    2.97272727e+01   1.87671617e+04  -2.45115880e+03  -1.62980717e+04\n",
      "   -2.21621266e+04  -1.19145310e+03   7.28000000e+02   7.40000000e+01\n",
      "    2.30000000e+01   2.90000000e+01   2.00000000e+00   1.06000000e+02\n",
      "    1.00000000e+00   3.00000000e+00]\n",
      " [  1.09000000e+02   4.00000000e+00   0.00000000e+00   1.27000000e+02\n",
      "    1.81428571e+01  -6.11945684e+04   1.66019762e+03   2.40659554e+02\n",
      "    7.81203839e+03   3.14309459e+02   1.23000000e+02   1.90000000e+01\n",
      "    3.00000000e+00   1.00000000e+00   3.00000000e+00   1.24000000e+02\n",
      "    8.00000000e+00   4.00000000e+00]\n",
      " [  9.70000000e+01   4.00000000e+00   0.00000000e+00   2.49000000e+02\n",
      "    1.55625000e+01  -5.73741656e+04  -3.33111579e+03   2.33390366e+03\n",
      "    3.77453856e+03  -7.61532298e+02   2.34000000e+02   6.60000000e+01\n",
      "    1.80000000e+01   8.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   2.00000000e+00]\n",
      " [  3.50000000e+01   6.00000000e+00   0.00000000e+00   6.00000000e+00\n",
      "    6.00000000e+00  -6.42277681e+04   2.78168341e+03   2.42397866e+03\n",
      "    6.50884795e+03   3.59594688e+02   5.50000000e+01   0.00000000e+00\n",
      "    6.00000000e+00   2.00000000e+00   2.00000000e+00   1.79000000e+02\n",
      "    7.00000000e+00   1.00000000e+00]\n",
      " [  4.00000000e+01   2.00000000e+00   0.00000000e+00   4.65000000e+02\n",
      "    2.90625000e+01   1.87671617e+04  -2.45115880e+03  -1.62980717e+04\n",
      "   -2.21621266e+04  -1.19145310e+03   1.00100000e+03   1.08000000e+02\n",
      "    4.70000000e+01   4.10000000e+01   1.00000000e+00   1.50000000e+02\n",
      "    0.00000000e+00   6.00000000e+00]\n",
      " [  1.12000000e+02   2.00000000e+00   0.00000000e+00   1.70240000e+03\n",
      "    1.89155556e+01   1.95232410e+04  -4.96296783e+03   1.37424953e+03\n",
      "   -1.60827084e+04  -3.46889739e+03   9.90000000e+02   4.50000000e+02\n",
      "    1.14000000e+02   7.90000000e+01   4.00000000e+00   4.20000000e+01\n",
      "    8.00000000e+00   3.00000000e+00]\n",
      " [  1.05000000e+02   4.00000000e+00   0.00000000e+00   1.55100000e+02\n",
      "    2.58500000e+01  -4.91075399e+04   2.69284708e+03  -9.93523172e+03\n",
      "    3.29862388e+03   5.93549458e+03   4.22000000e+02   7.80000000e+01\n",
      "    2.50000000e+01   2.60000000e+01   3.00000000e+00   1.20000000e+02\n",
      "    9.00000000e+00   2.00000000e+00]\n",
      " [  8.00000000e+01   5.00000000e+00   0.00000000e+00   4.24700000e+02\n",
      "    1.93045455e+01  -5.55286688e+04   3.66578773e+03  -1.21680839e+02\n",
      "    5.69616021e+03   1.43615864e+03   5.49000000e+02   7.20000000e+01\n",
      "    3.00000000e+01   1.50000000e+01   2.00000000e+00   2.32000000e+02\n",
      "    1.00000000e+01   1.00000000e+00]\n",
      " [  9.90000000e+01   1.00000000e+00   0.00000000e+00   2.91030000e+03\n",
      "    1.90215686e+01   7.38786693e+04  -7.54669860e+03  -5.38295572e+03\n",
      "   -3.31725544e+04   1.29374034e+04   1.52000000e+03   3.91000000e+02\n",
      "    1.10000000e+02   1.03000000e+02   4.00000000e+00   5.50000000e+01\n",
      "    6.00000000e+00   6.00000000e+00]\n",
      " [  8.10000000e+01   6.00000000e+00   0.00000000e+00   4.70000000e+01\n",
      "    9.40000000e+00  -6.52416963e+04   3.02562811e+03   3.99735138e+03\n",
      "    9.04914780e+03  -1.38483728e+03   1.07000000e+02   1.10000000e+01\n",
      "    3.00000000e+00   0.00000000e+00   2.00000000e+00   1.57000000e+02\n",
      "    9.00000000e+00   2.00000000e+00]]\n",
      "(102680, 18)\n",
      "[[  1.70000000e+01   3.00000000e+00   0.00000000e+00   3.27000000e+02\n",
      "    2.97272727e+01   1.87671617e+04  -2.45115880e+03  -1.62980717e+04\n",
      "   -2.21621266e+04  -1.19145310e+03   7.28000000e+02   7.40000000e+01\n",
      "    2.30000000e+01   2.90000000e+01   2.00000000e+00   1.06000000e+02\n",
      "    1.00000000e+00   3.00000000e+00]\n",
      " [  1.09000000e+02   4.00000000e+00   0.00000000e+00   1.27000000e+02\n",
      "    1.81428571e+01  -6.11945684e+04   1.66019762e+03   2.40659554e+02\n",
      "    7.81203839e+03   3.14309459e+02   1.23000000e+02   1.90000000e+01\n",
      "    3.00000000e+00   1.00000000e+00   3.00000000e+00   1.24000000e+02\n",
      "    8.00000000e+00   4.00000000e+00]\n",
      " [  9.70000000e+01   4.00000000e+00   0.00000000e+00   2.49000000e+02\n",
      "    1.55625000e+01  -5.73741656e+04  -3.33111579e+03   2.33390366e+03\n",
      "    3.77453856e+03  -7.61532298e+02   2.34000000e+02   6.60000000e+01\n",
      "    1.80000000e+01   8.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   2.00000000e+00]\n",
      " [  3.50000000e+01   6.00000000e+00   0.00000000e+00   6.00000000e+00\n",
      "    6.00000000e+00  -6.42277681e+04   2.78168341e+03   2.42397866e+03\n",
      "    6.50884795e+03   3.59594688e+02   5.50000000e+01   0.00000000e+00\n",
      "    6.00000000e+00   2.00000000e+00   2.00000000e+00   1.79000000e+02\n",
      "    7.00000000e+00   1.00000000e+00]\n",
      " [  4.00000000e+01   2.00000000e+00   0.00000000e+00   4.65000000e+02\n",
      "    2.90625000e+01   1.87671617e+04  -2.45115880e+03  -1.62980717e+04\n",
      "   -2.21621266e+04  -1.19145310e+03   1.00100000e+03   1.08000000e+02\n",
      "    4.70000000e+01   4.10000000e+01   1.00000000e+00   1.50000000e+02\n",
      "    0.00000000e+00   6.00000000e+00]\n",
      " [  1.12000000e+02   2.00000000e+00   0.00000000e+00   1.70240000e+03\n",
      "    1.89155556e+01   1.95232410e+04  -4.96296783e+03   1.37424953e+03\n",
      "   -1.60827084e+04  -3.46889739e+03   9.90000000e+02   4.50000000e+02\n",
      "    1.14000000e+02   7.90000000e+01   4.00000000e+00   4.20000000e+01\n",
      "    8.00000000e+00   3.00000000e+00]\n",
      " [  1.05000000e+02   4.00000000e+00   0.00000000e+00   1.55100000e+02\n",
      "    2.58500000e+01  -4.91075399e+04   2.69284708e+03  -9.93523172e+03\n",
      "    3.29862388e+03   5.93549458e+03   4.22000000e+02   7.80000000e+01\n",
      "    2.50000000e+01   2.60000000e+01   3.00000000e+00   1.20000000e+02\n",
      "    9.00000000e+00   2.00000000e+00]\n",
      " [  8.00000000e+01   5.00000000e+00   0.00000000e+00   4.24700000e+02\n",
      "    1.93045455e+01  -5.55286688e+04   3.66578773e+03  -1.21680839e+02\n",
      "    5.69616021e+03   1.43615864e+03   5.49000000e+02   7.20000000e+01\n",
      "    3.00000000e+01   1.50000000e+01   2.00000000e+00   2.32000000e+02\n",
      "    1.00000000e+01   1.00000000e+00]\n",
      " [  9.90000000e+01   1.00000000e+00   0.00000000e+00   2.91030000e+03\n",
      "    1.90215686e+01   7.38786693e+04  -7.54669860e+03  -5.38295572e+03\n",
      "   -3.31725544e+04   1.29374034e+04   1.52000000e+03   3.91000000e+02\n",
      "    1.10000000e+02   1.03000000e+02   4.00000000e+00   5.50000000e+01\n",
      "    6.00000000e+00   6.00000000e+00]\n",
      " [  8.10000000e+01   6.00000000e+00   0.00000000e+00   4.70000000e+01\n",
      "    9.40000000e+00  -6.52416963e+04   3.02562811e+03   3.99735138e+03\n",
      "    9.04914780e+03  -1.38483728e+03   1.07000000e+02   1.10000000e+01\n",
      "    3.00000000e+00   0.00000000e+00   2.00000000e+00   1.57000000e+02\n",
      "    9.00000000e+00   2.00000000e+00]]\n",
      "(102680, 18)\n",
      "[[  1.70000000e+01   3.00000000e+00   0.00000000e+00   3.27000000e+02\n",
      "    2.97272727e+01   1.87671617e+04  -2.45115880e+03  -1.62980717e+04\n",
      "   -2.21621266e+04  -1.19145310e+03   7.28000000e+02   7.40000000e+01\n",
      "    2.30000000e+01   2.90000000e+01   2.00000000e+00   1.06000000e+02\n",
      "    1.00000000e+00   3.00000000e+00]\n",
      " [  1.09000000e+02   4.00000000e+00   0.00000000e+00   1.27000000e+02\n",
      "    1.81428571e+01  -6.11945684e+04   1.66019762e+03   2.40659554e+02\n",
      "    7.81203839e+03   3.14309459e+02   1.23000000e+02   1.90000000e+01\n",
      "    3.00000000e+00   1.00000000e+00   3.00000000e+00   1.24000000e+02\n",
      "    8.00000000e+00   4.00000000e+00]\n",
      " [  9.70000000e+01   4.00000000e+00   0.00000000e+00   2.49000000e+02\n",
      "    1.55625000e+01  -5.73741656e+04  -3.33111579e+03   2.33390366e+03\n",
      "    3.77453856e+03  -7.61532298e+02   2.34000000e+02   6.60000000e+01\n",
      "    1.80000000e+01   8.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   2.00000000e+00]\n",
      " [  3.50000000e+01   6.00000000e+00   0.00000000e+00   6.00000000e+00\n",
      "    6.00000000e+00  -6.42277681e+04   2.78168341e+03   2.42397866e+03\n",
      "    6.50884795e+03   3.59594688e+02   5.50000000e+01   0.00000000e+00\n",
      "    6.00000000e+00   2.00000000e+00   2.00000000e+00   1.79000000e+02\n",
      "    7.00000000e+00   1.00000000e+00]\n",
      " [  4.00000000e+01   2.00000000e+00   0.00000000e+00   4.65000000e+02\n",
      "    2.90625000e+01   1.87671617e+04  -2.45115880e+03  -1.62980717e+04\n",
      "   -2.21621266e+04  -1.19145310e+03   1.00100000e+03   1.08000000e+02\n",
      "    4.70000000e+01   4.10000000e+01   1.00000000e+00   1.50000000e+02\n",
      "    0.00000000e+00   6.00000000e+00]\n",
      " [  1.12000000e+02   2.00000000e+00   0.00000000e+00   1.70240000e+03\n",
      "    1.89155556e+01   1.95232410e+04  -4.96296783e+03   1.37424953e+03\n",
      "   -1.60827084e+04  -3.46889739e+03   9.90000000e+02   4.50000000e+02\n",
      "    1.14000000e+02   7.90000000e+01   4.00000000e+00   4.20000000e+01\n",
      "    8.00000000e+00   3.00000000e+00]\n",
      " [  1.05000000e+02   4.00000000e+00   0.00000000e+00   1.55100000e+02\n",
      "    2.58500000e+01  -4.91075399e+04   2.69284708e+03  -9.93523172e+03\n",
      "    3.29862388e+03   5.93549458e+03   4.22000000e+02   7.80000000e+01\n",
      "    2.50000000e+01   2.60000000e+01   3.00000000e+00   1.20000000e+02\n",
      "    9.00000000e+00   2.00000000e+00]\n",
      " [  8.00000000e+01   5.00000000e+00   0.00000000e+00   4.24700000e+02\n",
      "    1.93045455e+01  -5.55286688e+04   3.66578773e+03  -1.21680839e+02\n",
      "    5.69616021e+03   1.43615864e+03   5.49000000e+02   7.20000000e+01\n",
      "    3.00000000e+01   1.50000000e+01   2.00000000e+00   2.32000000e+02\n",
      "    1.00000000e+01   1.00000000e+00]\n",
      " [  9.90000000e+01   1.00000000e+00   0.00000000e+00   2.91030000e+03\n",
      "    1.90215686e+01   7.38786693e+04  -7.54669860e+03  -5.38295572e+03\n",
      "   -3.31725544e+04   1.29374034e+04   1.52000000e+03   3.91000000e+02\n",
      "    1.10000000e+02   1.03000000e+02   4.00000000e+00   5.50000000e+01\n",
      "    6.00000000e+00   6.00000000e+00]\n",
      " [  8.10000000e+01   6.00000000e+00   0.00000000e+00   4.70000000e+01\n",
      "    9.40000000e+00  -6.52416963e+04   3.02562811e+03   3.99735138e+03\n",
      "    9.04914780e+03  -1.38483728e+03   1.07000000e+02   1.10000000e+01\n",
      "    3.00000000e+00   0.00000000e+00   2.00000000e+00   1.57000000e+02\n",
      "    9.00000000e+00   2.00000000e+00]]\n",
      "(102680, 18)\n",
      "[[  1.70000000e+01   3.00000000e+00   0.00000000e+00   3.27000000e+02\n",
      "    2.97272727e+01   1.87671617e+04  -2.45115880e+03  -1.62980717e+04\n",
      "   -2.21621266e+04  -1.19145310e+03   7.28000000e+02   7.40000000e+01\n",
      "    2.30000000e+01   2.90000000e+01   2.00000000e+00   1.06000000e+02\n",
      "    1.00000000e+00   3.00000000e+00]\n",
      " [  1.09000000e+02   4.00000000e+00   0.00000000e+00   1.27000000e+02\n",
      "    1.81428571e+01  -6.11945684e+04   1.66019762e+03   2.40659554e+02\n",
      "    7.81203839e+03   3.14309459e+02   1.23000000e+02   1.90000000e+01\n",
      "    3.00000000e+00   1.00000000e+00   3.00000000e+00   1.24000000e+02\n",
      "    8.00000000e+00   4.00000000e+00]\n",
      " [  9.70000000e+01   4.00000000e+00   0.00000000e+00   2.49000000e+02\n",
      "    1.55625000e+01  -5.73741656e+04  -3.33111579e+03   2.33390366e+03\n",
      "    3.77453856e+03  -7.61532298e+02   2.34000000e+02   6.60000000e+01\n",
      "    1.80000000e+01   8.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   2.00000000e+00]\n",
      " [  3.50000000e+01   6.00000000e+00   0.00000000e+00   6.00000000e+00\n",
      "    6.00000000e+00  -6.42277681e+04   2.78168341e+03   2.42397866e+03\n",
      "    6.50884795e+03   3.59594688e+02   5.50000000e+01   0.00000000e+00\n",
      "    6.00000000e+00   2.00000000e+00   2.00000000e+00   1.79000000e+02\n",
      "    7.00000000e+00   1.00000000e+00]\n",
      " [  4.00000000e+01   2.00000000e+00   0.00000000e+00   4.65000000e+02\n",
      "    2.90625000e+01   1.87671617e+04  -2.45115880e+03  -1.62980717e+04\n",
      "   -2.21621266e+04  -1.19145310e+03   1.00100000e+03   1.08000000e+02\n",
      "    4.70000000e+01   4.10000000e+01   1.00000000e+00   1.50000000e+02\n",
      "    0.00000000e+00   6.00000000e+00]\n",
      " [  1.12000000e+02   2.00000000e+00   0.00000000e+00   1.70240000e+03\n",
      "    1.89155556e+01   1.95232410e+04  -4.96296783e+03   1.37424953e+03\n",
      "   -1.60827084e+04  -3.46889739e+03   9.90000000e+02   4.50000000e+02\n",
      "    1.14000000e+02   7.90000000e+01   4.00000000e+00   4.20000000e+01\n",
      "    8.00000000e+00   3.00000000e+00]\n",
      " [  1.05000000e+02   4.00000000e+00   0.00000000e+00   1.55100000e+02\n",
      "    2.58500000e+01  -4.91075399e+04   2.69284708e+03  -9.93523172e+03\n",
      "    3.29862388e+03   5.93549458e+03   4.22000000e+02   7.80000000e+01\n",
      "    2.50000000e+01   2.60000000e+01   3.00000000e+00   1.20000000e+02\n",
      "    9.00000000e+00   2.00000000e+00]\n",
      " [  8.00000000e+01   5.00000000e+00   0.00000000e+00   4.24700000e+02\n",
      "    1.93045455e+01  -5.55286688e+04   3.66578773e+03  -1.21680839e+02\n",
      "    5.69616021e+03   1.43615864e+03   5.49000000e+02   7.20000000e+01\n",
      "    3.00000000e+01   1.50000000e+01   2.00000000e+00   2.32000000e+02\n",
      "    1.00000000e+01   1.00000000e+00]\n",
      " [  9.90000000e+01   1.00000000e+00   0.00000000e+00   2.91030000e+03\n",
      "    1.90215686e+01   7.38786693e+04  -7.54669860e+03  -5.38295572e+03\n",
      "   -3.31725544e+04   1.29374034e+04   1.52000000e+03   3.91000000e+02\n",
      "    1.10000000e+02   1.03000000e+02   4.00000000e+00   5.50000000e+01\n",
      "    6.00000000e+00   6.00000000e+00]\n",
      " [  8.10000000e+01   6.00000000e+00   0.00000000e+00   4.70000000e+01\n",
      "    9.40000000e+00  -6.52416963e+04   3.02562811e+03   3.99735138e+03\n",
      "    9.04914780e+03  -1.38483728e+03   1.07000000e+02   1.10000000e+01\n",
      "    3.00000000e+00   0.00000000e+00   2.00000000e+00   1.57000000e+02\n",
      "    9.00000000e+00   2.00000000e+00]]\n",
      "2.53971690622\n",
      "2.53971690622\n",
      "2.53971690622\n"
     ]
    }
   ],
   "source": [
    "# Just testing Imputer. Turns out somehow Imputer causes number of features reduced, weird.\n",
    "\n",
    "# imputer = Imputer()\n",
    "est = DecisionTreeRegressor(max_features=len(features))\n",
    "\n",
    "data_train_i = np.copy(data_train)\n",
    "print(data_train.shape)\n",
    "print(data_train[0:10])\n",
    "# data_train_i = imputer.fit_transform(data_train)\n",
    "data_train_i[np.isnan(data_train_i)] = 0\n",
    "data_train_i.astype('float32')\n",
    "print(data_train_i.shape)\n",
    "print(data_train_i[0:10])\n",
    "est.fit(data_train_i, targets_train)\n",
    "predictions = est.predict(data_test)\n",
    "print(mape(data_test, predictions, targets_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
