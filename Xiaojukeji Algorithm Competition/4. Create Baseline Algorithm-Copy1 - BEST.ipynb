{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pdb\n",
    "import numpy as np\n",
    "import gcp.bigquery as bq\n",
    "import gcp.storage as storage\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import Imputer, MinMaxScaler, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "try:\n",
    "   import cPickle as pickle\n",
    "except:\n",
    "   import pickle\n",
    "EST_PICKLE_FILENAME = 'GradientBoostingRegressor_grid_best.pkl'\n",
    "\n",
    "seed = 13\n",
    "np.random.seed(seed)\n",
    "\n",
    "# Put all categorical data first for easier implementation of One Hot Encoding.\n",
    "fields_str = \"\"\"\n",
    "gap\tday_in_week\tweather_1_slots_ago\tweather_2_slots_ago\tweather_3_slots_ago\tbusy_time\t\n",
    "tj_level1_1_slots_ago\ttj_level2_1_slots_ago\ttj_level3_1_slots_ago\ttj_level4_1_slots_ago\t\n",
    "tj_level1_2_slots_ago\ttj_level2_2_slots_ago\ttj_level3_2_slots_ago\ttj_level4_2_slots_ago\t\n",
    "tj_level1_3_slots_ago\ttj_level2_3_slots_ago\ttj_level3_3_slots_ago\ttj_level4_3_slots_ago\t\n",
    "temperature_1_slots_ago\tpm25_1_slots_ago\t\n",
    "temperature_2_slots_ago\tpm25_2_slots_ago\t\n",
    "temperature_3_slots_ago\tpm25_3_slots_ago\t\n",
    "gap_1_slots_ago\tsum_price_1_slots_ago\t\n",
    "gap_2_slots_ago\tsum_price_2_slots_ago\t\n",
    "gap_3_slots_ago\tsum_price_3_slots_ago\t\n",
    "f1\tf11\tf11_1\tf11_2\tf11_3\tf11_4\tf11_5\tf11_6\tf11_7\t\n",
    "f11_8\tf13_4\tf13_8\tf14\tf14_1\tf14_10\tf14_2\tf14_3\tf14_6\tf14_8\tf15\tf15_1\t\n",
    "f15_2\tf15_3\tf15_4\tf15_6\tf15_7\tf15_8\tf16\tf16_1\tf16_10\tf16_11\tf16_12\tf16_3\t\n",
    "f16_4\tf16_6\tf17\tf17_2\tf17_3\tf17_4\tf17_5\tf19\tf19_1\tf19_2\tf19_3\tf19_4\tf1_1\t\n",
    "f1_10\tf1_11\tf1_2\tf1_3\tf1_4\tf1_5\tf1_6\tf1_7\tf1_8\tf20\tf20_1\tf20_2\t\n",
    "f20_4\tf20_5\tf20_6\tf20_7\tf20_8\tf20_9\tf21_1\tf21_2\tf22\tf22_1\tf22_2\tf22_3\t\n",
    "f22_4\tf22_5\tf23\tf23_1\tf23_2\tf23_3\tf23_4\tf23_5\tf23_6\tf24\tf24_1\tf24_2\tf24_3\t\n",
    "f25\tf25_1\tf25_3\tf25_7\tf25_8\tf25_9\tf2_1\tf2_10\tf2_11\tf2_12\tf2_13\tf2_2\t\n",
    "f2_4\tf2_5\tf2_6\tf2_7\tf2_8\tf3_1\tf3_2\tf3_3\tf4\tf4_1\tf4_10\tf4_11\t\n",
    "f4_13\tf4_14\tf4_16\tf4_17\tf4_18\tf4_2\tf4_3\tf4_5\tf4_6\tf4_7\tf4_8\tf4_9\t\n",
    "f5\tf5_1\tf5_3\tf5_4\tf6\tf6_1\tf6_2\tf6_4\tf7\tf8\tf8_1\tf8_2\tf8_3\tf8_4\t\n",
    "f8_5\n",
    "\"\"\"\n",
    "fields = map(lambda x: x.strip(), fields_str.split('\\t'))\n",
    "features = fields[1:]\n",
    "\n",
    "# Use this instead of len(features) since this variable can change\n",
    "# e.g. when one hot encoding is used and/or new features are added.\n",
    "n_features = len(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scorer Creation (MAPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def mape(y, predictions):\n",
    "#   num_timeslots = 43\n",
    "#   num_districts = 66\n",
    "  if len(y.shape) == 1:\n",
    "    y = np.asmatrix(y)\n",
    "  if len(predictions.shape) == 1:\n",
    "    predictions = np.asmatrix(predictions)\n",
    "  y = y.astype(float)\n",
    "  predictions = predictions.astype(float)\n",
    "  return np.mean(np.absolute((y-predictions)/y))\n",
    "\n",
    "# from keras import backend as K\n",
    "\n",
    "# def mape(y, predictions):\n",
    "#   return K.mean(K.abs(y-predictions/K.clip(K.abs(y), K.epsilon(), np.inf)), axis=-1)\n",
    "\n",
    "mape_scorer = make_scorer(mape, greater_is_better=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing MAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.145833333333\n",
      "254.604166667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "predictions = np.array([1.0, 2.0, 3.0, 4.0]).astype('float32')\n",
    "y = np.array([1.0, 2.0, 3.0, 4.0]).astype('float32')\n",
    "\n",
    "# Should return 0.0\n",
    "print mape(y, predictions)\n",
    "\n",
    "# Should return higher score\n",
    "predictions = np.array([1.0, 2.0, 2.0, 3.0]).astype('float32')\n",
    "print(mape(y, predictions))\n",
    "\n",
    "# Should return highest score\n",
    "predictions = np.array([1000.0, 22.0, 11.0, 31.0]).astype('float32')\n",
    "print(mape(y, predictions))\n",
    "\n",
    "# est = LogisticRegression()\n",
    "# X = np.random.rand(10,4)\n",
    "# y = X.sum(axis=1)\n",
    "# est.fit(X, y)\n",
    "# predictions = est.predict(X)\n",
    "# print(mape(y, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%sql --module q_all\n",
    "\n",
    "SELECT *, HASH(CAST(district_id AS STRING) +timeslot) AS hash_value,\n",
    "  IF(ABS(HASH(CAST(district_id AS STRING) + timeslot)) % 2 == 1, 'True', 'False')\n",
    "    AS included_in_sample, IF(timeofday_slot >= 50 AND timeofday_slot <= 53, 1, 0) AS busy_time\n",
    "FROM [datalab-projects-1331:xjk_algo_comp.gaps]\n",
    "WHERE gap > 0\n",
    "LIMIT 80000\n",
    "\n",
    "# The above query randomizes its outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 80000 rows\n",
      "processed 0 rows\n",
      "processed 5000 rows\n",
      "processed 10000 rows\n",
      "processed 15000 rows\n",
      "processed 20000 rows\n",
      "processed 25000 rows\n",
      "processed 30000 rows\n",
      "processed 35000 rows\n",
      "processed 40000 rows\n",
      "processed 45000 rows\n",
      "processed 50000 rows\n",
      "processed 55000 rows\n",
      "processed 60000 rows\n",
      "processed 65000 rows\n",
      "processed 70000 rows\n",
      "processed 75000 rows\n"
     ]
    }
   ],
   "source": [
    "query = bq.Query(q_all)\n",
    "tableresult = query.results()\n",
    "\n",
    "all_data = np.zeros((tableresult.length, len(fields)))\n",
    "print 'there are {} rows'.format(tableresult.length)\n",
    "for rcounter, row in enumerate(tableresult):\n",
    "  for fcounter, field in enumerate(fields):\n",
    "    all_data[rcounter, fcounter] = row[field]\n",
    "  if rcounter % 5000 == 0:\n",
    "    print 'processed {} rows'.format(rcounter)\n",
    "all_data_original = np.copy(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkinf for NaN and Inf\n",
      "np.nan= (array([    5,     5,    19, ..., 79999, 79999, 79999]), array([24, 25, 24, ..., 15, 16, 17])) total= 2\n",
      "is.inf= (array([], dtype=int64), array([], dtype=int64)) total= 2\n",
      "np.max= nan\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "where() takes no keyword arguments",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0mTraceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-b70b111cf8e1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[1;34m\"np.max=\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_data_original\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mnulls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_data_original\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[1;32mprint\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnulls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;31m# Impute all NaN with numbers (not sure what to replace inf yet)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: where() takes no keyword arguments"
     ]
    }
   ],
   "source": [
    "# This chunk does further wrangling to dataset to produce training and test sets.\n",
    "\n",
    "# Useful code to check NaN and Inf values. This is needed since these values would\n",
    "# cause \"Input contains NaN, infinity or a value too large for dtype('float32')\n",
    "# errors when left unchecked.\n",
    "print \"Checkinf for NaN and Inf\"\n",
    "print \"np.nan=\", np.where(np.isnan(all_data_original)), \"total=\", len(np.where(np.isnan(all_data_original)))\n",
    "print \"is.inf=\", np.where(np.isinf(all_data_original)), \"total=\", len(np.where(np.isinf(all_data_original)))\n",
    "print \"np.max=\", np.max(abs(all_data_original))\n",
    "\n",
    "# Impute all NaN with numbers (not sure what to replace inf yet)\n",
    "all_data[np.isnan(all_data_original)] = 0\n",
    "# all_data[np.isinf(all_data)] = 0\n",
    "\n",
    "# See that NaN and Inf values replaced\n",
    "print \"Checkinf for NaN and Inf\"\n",
    "print \"np.nan=\", np.where(np.isnan(all_data)), \"total=\", len(np.where(np.isnan(all_data)))\n",
    "print \"is.inf=\", np.where(np.isinf(all_data)), \"total=\", len(np.where(np.isinf(all_data)))\n",
    "print \"np.max=\", np.max(abs(all_data))\n",
    "\n",
    "# Split the data into train and test sets.\n",
    "data_size = all_data.shape[0]\n",
    "training_size = data_size * 80/100\n",
    "indices = np.random.permutation(data_size)\n",
    "training_idx, test_idx = indices[:training_size], indices[training_size:]\n",
    "all_data_train, all_data_test = all_data[training_idx,:], all_data[test_idx,:]\n",
    "\n",
    "data_train = all_data_train[:,1:]\n",
    "targets_train = all_data_train[:,0]\n",
    "data_test = all_data_test[:,1:]\n",
    "targets_test = all_data_test[:,0]\n",
    "data_train_original = np.copy(data_train)\n",
    "data_test_original = np.copy(data_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration - Find NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    5,    24],\n",
       "       [    5,    25],\n",
       "       [   19,    24],\n",
       "       ..., \n",
       "       [79999,    15],\n",
       "       [79999,    16],\n",
       "       [79999,    17]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is how to get position of NaNs\n",
    "\n",
    "nulls = np.isnan(all_data_original)\n",
    "nullspos = np.column_stack(np.where(nulls==True))\n",
    "nullspos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]\n",
      "('weather_1_slots_ago', 'weather_2_slots_ago', 'weather_3_slots_ago', 'tj_level1_1_slots_ago', 'tj_level2_1_slots_ago', 'tj_level3_1_slots_ago', 'tj_level4_1_slots_ago', 'tj_level1_2_slots_ago', 'tj_level2_2_slots_ago', 'tj_level3_2_slots_ago', 'tj_level4_2_slots_ago', 'tj_level1_3_slots_ago', 'tj_level2_3_slots_ago', 'tj_level3_3_slots_ago', 'tj_level4_3_slots_ago', 'temperature_1_slots_ago', 'pm25_1_slots_ago', 'temperature_2_slots_ago', 'pm25_2_slots_ago', 'temperature_3_slots_ago', 'pm25_3_slots_ago', 'gap_1_slots_ago', 'sum_price_1_slots_ago', 'gap_2_slots_ago', 'sum_price_2_slots_ago', 'gap_3_slots_ago', 'sum_price_3_slots_ago')\n"
     ]
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "print(np.unique(nullspos[:,1]).tolist())\n",
    "print(itemgetter(*np.unique(nullspos[:,1]).tolist())(fields))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f9ab20d8c10>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeAAAAFXCAYAAAB6G51YAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIT7w/wF204sAL8CLnQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9ac1163b50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(nullspos[:,0], nullspos[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80000, 164)\n",
      "163\n"
     ]
    }
   ],
   "source": [
    "print(all_data_original.shape)\n",
    "print(len(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66.0"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data_original[1,29]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bqtv\" id=\"3_146743975718\"></div>\n",
       "    <br />(rows: 0, time: 1.0s,     1MB processed, job: job_IQHGPF8vU6O46LKFVoRk4O2I2aM)<br />\n",
       "    <script>\n",
       "      require(['extensions/charting', 'element!3_146743975718', 'style!/static/extensions/charting.css'],\n",
       "        function(charts, dom) {\n",
       "          charts.render(dom,\n",
       "            {\n",
       "              chartStyle:\"table\",\n",
       "              dataName:\"2\",\n",
       "              fields:\"sum_price_3_slots_ago\",\n",
       "              totalRows:0,\n",
       "              rowsPerPage:25,\n",
       "            }, {}, {\"rows\": [], \"cols\": [{\"type\": \"number\", \"id\": \"sum_price_3_slots_ago\", \"label\": \"sum_price_3_slots_ago\"}]});\n",
       "        }\n",
       "      );\n",
       "    </script>\n",
       "  "
      ],
      "text/plain": [
       "QueryResultsTable job_IQHGPF8vU6O46LKFVoRk4O2I2aM"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "SELECT sum_price_3_slots_ago FROM [datalab-projects-1331:xjk_algo_comp.gaps]\n",
    "WHERE sum_price_3_slots_ago = NULL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Continue to One Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneHotEncoder(categorical_features=[0, 1, 2, 3], dtype=<type 'float'>,\n",
       "       handle_unknown='error', n_values='auto', sparse=False)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "# one_hot = OneHotEncoder(categorical_features=[0, 1, 14, 17, 20], n_values='auto')\n",
    "one_hot = OneHotEncoder(categorical_features=[0, 1, 2, 3], sparse=False)\n",
    "one_hot.fit(data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 7, 10, 10, 10])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot.n_values_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  7, 17, 27, 37])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot.feature_indices_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building and Testing Algorithm(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.451136351423\n"
     ]
    }
   ],
   "source": [
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "from scipy.sparse import coo_matrix, hstack\n",
    "\n",
    "class CustomRegressor(BaseEstimator, RegressorMixin):\n",
    "  def __init__(self):\n",
    "    pass\n",
    "\n",
    "  def fit(self, X, y):\n",
    "#     self.classes_, indices = np.unique([\"foo\", \"bar\", \"foo\"],\n",
    "#                                     return_inverse=True)\n",
    "#     self.majority_ = np.argmax(np.bincount(indices))\n",
    "    return self\n",
    "\n",
    "  def predict(self, X):\n",
    "    # 56: gap_1_slots_ago\n",
    "    # 58: gap_2_slots_ago\n",
    "    # 60: gap_3_slots_ago\n",
    "#     X = X.tocsr()\n",
    "#     v1 = coo_matrix(np.asmatrix(np.ones(X.shape[0])).T)\n",
    "    v1 = np.asmatrix(np.ones(X.shape[0]))\n",
    "    v2 = np.asmatrix((X[:, 23]*0.65+X[:, 25]*0.25+X[:, 27]*0.15)/2)\n",
    "    predictions = np.asarray(np.concatenate((v1, v2), axis=0).max(axis=0))\n",
    "    \n",
    "    return predictions\n",
    "  \n",
    "custom_est = CustomRegressor()\n",
    "custom_est.fit(data_train_original, data_test_original)\n",
    "custom_predictions = custom_est.predict(data_test_original)\n",
    "print(mape(targets_test, custom_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "[CV] estimate__learning_rate=0.1, estimate__n_estimators=110 .........\n",
      "[CV] estimate__learning_rate=0.1, estimate__n_estimators=110 .........\n",
      "[CV] estimate__learning_rate=0.1, estimate__n_estimators=110 .........\n",
      "[CV] estimate__learning_rate=0.1, estimate__n_estimators=110 .........\n",
      "[CV] estimate__learning_rate=0.1, estimate__n_estimators=110 .........\n",
      "[CV]  estimate__learning_rate=0.1, estimate__n_estimators=110, score=-0.874537 -21.9min\n",
      "[CV] estimate__learning_rate=0.1, estimate__n_estimators=130 .........\n",
      "[CV]  estimate__learning_rate=0.1, estimate__n_estimators=110, score=-0.886750 -21.9min\n",
      "[CV] estimate__learning_rate=0.1, estimate__n_estimators=130 .........\n",
      "[CV]  estimate__learning_rate=0.1, estimate__n_estimators=110, score=-0.867296 -22.0min\n",
      "[CV] estimate__learning_rate=0.1, estimate__n_estimators=130 .........\n",
      "[CV]  estimate__learning_rate=0.1, estimate__n_estimators=110, score=-0.878946 -22.5min\n",
      "[CV] estimate__learning_rate=0.1, estimate__n_estimators=130 .........\n",
      "[CV]  estimate__learning_rate=0.1, estimate__n_estimators=110, score=-0.866456 -22.7min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Done   1 jobs       | elapsed: 22.7min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] estimate__learning_rate=0.1, estimate__n_estimators=130 .........\n",
      "[CV]  estimate__learning_rate=0.1, estimate__n_estimators=130, score=-0.863527 -29.7min\n",
      "[CV] estimate__learning_rate=0.1, estimate__n_estimators=150 .........\n",
      "[CV]  estimate__learning_rate=0.1, estimate__n_estimators=130, score=-0.855026 -30.0min\n",
      "[CV] estimate__learning_rate=0.1, estimate__n_estimators=150 .........\n",
      "[CV]  estimate__learning_rate=0.1, estimate__n_estimators=130, score=-0.862286 -30.4min\n",
      "[CV] estimate__learning_rate=0.1, estimate__n_estimators=150 .........\n",
      "[CV]  estimate__learning_rate=0.1, estimate__n_estimators=130, score=-0.868889 -30.3min\n",
      "[CV] estimate__learning_rate=0.1, estimate__n_estimators=150 .........\n",
      "[CV]  estimate__learning_rate=0.1, estimate__n_estimators=130, score=-0.846937 -30.4min\n",
      "[CV] estimate__learning_rate=0.1, estimate__n_estimators=150 .........\n",
      "[CV]  estimate__learning_rate=0.1, estimate__n_estimators=150, score=-0.852371 -37.3min\n",
      "[CV] estimate__learning_rate=0.1, estimate__n_estimators=170 .........\n",
      "[CV]  estimate__learning_rate=0.1, estimate__n_estimators=150, score=-0.849532 -37.5min\n",
      "[CV] estimate__learning_rate=0.1, estimate__n_estimators=170 .........\n",
      "[CV]  estimate__learning_rate=0.1, estimate__n_estimators=150, score=-0.850113 -37.4min\n",
      "[CV] estimate__learning_rate=0.1, estimate__n_estimators=170 .........\n",
      "[CV]  estimate__learning_rate=0.1, estimate__n_estimators=150, score=-0.862197 -37.8min\n",
      "[CV] estimate__learning_rate=0.1, estimate__n_estimators=170 .........\n",
      "[CV]  estimate__learning_rate=0.1, estimate__n_estimators=150, score=-0.832220 -38.3min\n",
      "[CV] estimate__learning_rate=0.1, estimate__n_estimators=170 .........\n",
      "[CV]  estimate__learning_rate=0.1, estimate__n_estimators=170, score=-0.837837 -40.5min\n",
      "[CV] estimate__learning_rate=0.1, estimate__n_estimators=190 .........\n",
      "[CV]  estimate__learning_rate=0.1, estimate__n_estimators=170, score=-0.839305 -41.3min\n",
      "[CV] estimate__learning_rate=0.1, estimate__n_estimators=190 .........\n",
      "[CV]  estimate__learning_rate=0.1, estimate__n_estimators=170, score=-0.847533 -41.9min\n",
      "[CV] estimate__learning_rate=0.1, estimate__n_estimators=190 .........\n",
      "[CV]  estimate__learning_rate=0.1, estimate__n_estimators=170, score=-0.853956 -41.4min\n",
      "[CV] estimate__learning_rate=0.1, estimate__n_estimators=190 .........\n",
      "[CV]  estimate__learning_rate=0.1, estimate__n_estimators=170, score=-0.833629 -41.6min\n",
      "[CV] estimate__learning_rate=0.1, estimate__n_estimators=190 .........\n",
      "[CV]  estimate__learning_rate=0.1, estimate__n_estimators=190, score=-0.831853 -46.6min\n",
      "[CV] estimate__learning_rate=0.5, estimate__n_estimators=110 .........\n",
      "[CV]  estimate__learning_rate=0.1, estimate__n_estimators=190, score=-0.832230 -45.9min\n",
      "[CV] estimate__learning_rate=0.5, estimate__n_estimators=110 .........\n",
      "[CV]  estimate__learning_rate=0.1, estimate__n_estimators=190, score=-0.835731 -46.3min\n",
      "[CV] estimate__learning_rate=0.5, estimate__n_estimators=110 .........\n",
      "[CV]  estimate__learning_rate=0.1, estimate__n_estimators=190, score=-0.845529 -45.9min\n",
      "[CV] estimate__learning_rate=0.5, estimate__n_estimators=110 .........\n",
      "[CV]  estimate__learning_rate=0.1, estimate__n_estimators=190, score=-0.825329 -46.1min\n",
      "[CV] estimate__learning_rate=0.5, estimate__n_estimators=110 .........\n",
      "[CV]  estimate__learning_rate=0.5, estimate__n_estimators=110, score=-0.811726 -26.9min\n",
      "[CV] estimate__learning_rate=0.5, estimate__n_estimators=130 .........\n",
      "[CV]  estimate__learning_rate=0.5, estimate__n_estimators=110, score=-0.813344 -26.9min\n",
      "[CV] estimate__learning_rate=0.5, estimate__n_estimators=130 .........\n",
      "[CV]  estimate__learning_rate=0.5, estimate__n_estimators=110, score=-0.806914 -27.3min\n",
      "[CV] estimate__learning_rate=0.5, estimate__n_estimators=130 .........\n",
      "[CV]  estimate__learning_rate=0.5, estimate__n_estimators=110, score=-0.836271 -26.9min\n",
      "[CV] estimate__learning_rate=0.5, estimate__n_estimators=130 .........\n",
      "[CV]  estimate__learning_rate=0.5, estimate__n_estimators=110, score=-0.811101 -26.9min\n",
      "[CV] estimate__learning_rate=0.5, estimate__n_estimators=130 .........\n",
      "[CV]  estimate__learning_rate=0.5, estimate__n_estimators=130, score=-0.807818 -31.6min\n",
      "[CV] estimate__learning_rate=0.5, estimate__n_estimators=150 .........\n",
      "[CV]  estimate__learning_rate=0.5, estimate__n_estimators=130, score=-0.810413 -31.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Done  32 jobs       | elapsed: 235.7min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] estimate__learning_rate=0.5, estimate__n_estimators=150 .........\n",
      "[CV]  estimate__learning_rate=0.5, estimate__n_estimators=130, score=-0.810738 -31.3min\n",
      "[CV] estimate__learning_rate=0.5, estimate__n_estimators=150 .........\n",
      "[CV]  estimate__learning_rate=0.5, estimate__n_estimators=130, score=-0.827862 -31.8min\n",
      "[CV] estimate__learning_rate=0.5, estimate__n_estimators=150 .........\n",
      "[CV]  estimate__learning_rate=0.5, estimate__n_estimators=130, score=-0.804540 -31.2min\n",
      "[CV] estimate__learning_rate=0.5, estimate__n_estimators=150 .........\n",
      "[CV]  estimate__learning_rate=0.5, estimate__n_estimators=150, score=-0.817718 -25.4min\n",
      "[CV]  estimate__learning_rate=0.5, estimate__n_estimators=150, score=-0.813261 -24.8min\n",
      "[CV] estimate__learning_rate=0.5, estimate__n_estimators=170 .........\n",
      "[CV] estimate__learning_rate=0.5, estimate__n_estimators=170 .........\n",
      "[CV]  estimate__learning_rate=0.5, estimate__n_estimators=150, score=-0.810743 -24.6min\n",
      "[CV] estimate__learning_rate=0.5, estimate__n_estimators=170 .........\n",
      "[CV]  estimate__learning_rate=0.5, estimate__n_estimators=150, score=-0.831832 -24.3min\n",
      "[CV] estimate__learning_rate=0.5, estimate__n_estimators=170 .........\n",
      "[CV]  estimate__learning_rate=0.5, estimate__n_estimators=150, score=-0.795132 -24.2min\n",
      "[CV] estimate__learning_rate=0.5, estimate__n_estimators=170 .........\n",
      "[CV]  estimate__learning_rate=0.5, estimate__n_estimators=170, score=-0.814398 -26.9min\n",
      "[CV] estimate__learning_rate=0.5, estimate__n_estimators=190 .........\n",
      "[CV]  estimate__learning_rate=0.5, estimate__n_estimators=170, score=-0.815009 -27.0min\n",
      "[CV] estimate__learning_rate=0.5, estimate__n_estimators=190 .........\n",
      "[CV]  estimate__learning_rate=0.5, estimate__n_estimators=170, score=-0.817252 -27.7min\n",
      "[CV] estimate__learning_rate=0.5, estimate__n_estimators=190 .........\n",
      "[CV]  estimate__learning_rate=0.5, estimate__n_estimators=170, score=-0.825804 -27.2min\n",
      "[CV] estimate__learning_rate=0.5, estimate__n_estimators=190 .........\n",
      "[CV]  estimate__learning_rate=0.5, estimate__n_estimators=170, score=-0.805612 -27.5min\n",
      "[CV] estimate__learning_rate=0.5, estimate__n_estimators=190 .........\n",
      "[CV]  estimate__learning_rate=0.5, estimate__n_estimators=190, score=-0.809902 -33.3min\n",
      "[CV] estimate__learning_rate=1, estimate__n_estimators=110 ...........\n",
      "[CV]  estimate__learning_rate=0.5, estimate__n_estimators=190, score=-0.810688 -33.0min\n",
      "[CV] estimate__learning_rate=1, estimate__n_estimators=110 ...........\n",
      "[CV]  estimate__learning_rate=0.5, estimate__n_estimators=190, score=-0.823018 -33.2min\n",
      "[CV] estimate__learning_rate=1, estimate__n_estimators=110 ...........\n",
      "[CV]  estimate__learning_rate=0.5, estimate__n_estimators=190, score=-0.805750 -33.8min\n",
      "[CV] estimate__learning_rate=1, estimate__n_estimators=110 ...........\n",
      "[CV]  estimate__learning_rate=0.5, estimate__n_estimators=190, score=-0.800142 -33.5min\n",
      "[CV] estimate__learning_rate=1, estimate__n_estimators=110 ...........\n",
      "[CV]  estimate__learning_rate=1, estimate__n_estimators=110, score=-0.829033 -13.9min\n",
      "[CV] estimate__learning_rate=1, estimate__n_estimators=130 ...........\n",
      "[CV]  estimate__learning_rate=1, estimate__n_estimators=110, score=-0.859800 -14.2min\n",
      "[CV] estimate__learning_rate=1, estimate__n_estimators=130 ...........\n",
      "[CV]  estimate__learning_rate=1, estimate__n_estimators=110, score=-0.834761 -13.7min\n",
      "[CV] estimate__learning_rate=1, estimate__n_estimators=130 ...........\n",
      "[CV]  estimate__learning_rate=1, estimate__n_estimators=110, score=-0.870001 -13.6min\n",
      "[CV] estimate__learning_rate=1, estimate__n_estimators=130 ...........\n",
      "[CV]  estimate__learning_rate=1, estimate__n_estimators=110, score=-0.842385 -13.3min\n",
      "[CV] estimate__learning_rate=1, estimate__n_estimators=130 ...........\n",
      "[CV]  estimate__learning_rate=1, estimate__n_estimators=130, score=-0.844505 -14.2min\n",
      "[CV] estimate__learning_rate=1, estimate__n_estimators=150 ...........\n",
      "[CV]  estimate__learning_rate=1, estimate__n_estimators=130, score=-0.861480 -14.5min\n",
      "[CV] estimate__learning_rate=1, estimate__n_estimators=150 ...........\n",
      "[CV]  estimate__learning_rate=1, estimate__n_estimators=130, score=-0.839272 -14.3min\n",
      "[CV] estimate__learning_rate=1, estimate__n_estimators=150 ...........\n",
      "[CV]  estimate__learning_rate=1, estimate__n_estimators=130, score=-0.860530 -14.5min\n",
      "[CV] estimate__learning_rate=1, estimate__n_estimators=150 ...........\n",
      "[CV]  estimate__learning_rate=1, estimate__n_estimators=130, score=-0.836925 -14.4min\n",
      "[CV] estimate__learning_rate=1, estimate__n_estimators=150 ...........\n",
      "[CV]  estimate__learning_rate=1, estimate__n_estimators=150, score=-0.851785 -18.2min\n",
      "[CV] estimate__learning_rate=1, estimate__n_estimators=170 ...........\n",
      "[CV]  estimate__learning_rate=1, estimate__n_estimators=150, score=-0.846755 -17.9min\n",
      "[CV] estimate__learning_rate=1, estimate__n_estimators=170 ...........\n",
      "[CV]  estimate__learning_rate=1, estimate__n_estimators=150, score=-0.841111 -18.0min\n",
      "[CV] estimate__learning_rate=1, estimate__n_estimators=170 ...........\n",
      "[CV]  estimate__learning_rate=1, estimate__n_estimators=150, score=-0.830301 -17.7min\n",
      "[CV] estimate__learning_rate=1, estimate__n_estimators=170 ...........\n",
      "[CV]  estimate__learning_rate=1, estimate__n_estimators=150, score=-0.868845 -18.0min\n",
      "[CV] estimate__learning_rate=1, estimate__n_estimators=170 ...........\n",
      "[CV]  estimate__learning_rate=1, estimate__n_estimators=170, score=-0.844000 -17.9min\n",
      "[CV] estimate__learning_rate=1, estimate__n_estimators=190 ...........\n",
      "[CV]  estimate__learning_rate=1, estimate__n_estimators=170, score=-0.836046 -18.0min\n",
      "[CV] estimate__learning_rate=1, estimate__n_estimators=190 ...........\n",
      "[CV]  estimate__learning_rate=1, estimate__n_estimators=170, score=-0.860398 -18.1min\n",
      "[CV] estimate__learning_rate=1, estimate__n_estimators=190 ...........\n",
      "[CV]  estimate__learning_rate=1, estimate__n_estimators=170, score=-0.868008 -18.2min\n",
      "[CV] estimate__learning_rate=1, estimate__n_estimators=190 ...........\n",
      "[CV]  estimate__learning_rate=1, estimate__n_estimators=170, score=-0.836868 -18.7min\n",
      "[CV] estimate__learning_rate=1, estimate__n_estimators=190 ...........\n",
      "[CV]  estimate__learning_rate=1, estimate__n_estimators=190, score=-0.848399 -20.6min\n",
      "[CV] estimate__learning_rate=10, estimate__n_estimators=110 ..........\n",
      "[CV]  estimate__learning_rate=1, estimate__n_estimators=190, score=-0.867988 -21.0min\n",
      "[CV]  estimate__learning_rate=1, estimate__n_estimators=190, score=-0.850009 -20.8min\n",
      "[CV] estimate__learning_rate=10, estimate__n_estimators=110 ..........\n",
      "[CV] estimate__learning_rate=10, estimate__n_estimators=110 ..........\n",
      "[CV]  estimate__learning_rate=1, estimate__n_estimators=190, score=-0.879111 -21.4min\n",
      "[CV] estimate__learning_rate=10, estimate__n_estimators=110 ..........\n",
      "[CV]  estimate__learning_rate=1, estimate__n_estimators=190, score=-0.836483 -21.8min\n",
      "[CV] estimate__learning_rate=10, estimate__n_estimators=110 ..........\n",
      "[CV]  estimate__learning_rate=10, estimate__n_estimators=110, score=-4453554487192734386755844528315629674770697693938493857659660163110444622769751948552039969909574071222272.000000 -22.0min\n",
      "[CV] estimate__learning_rate=10, estimate__n_estimators=130 ..........\n",
      "[CV]  estimate__learning_rate=10, estimate__n_estimators=110, score=-4428399507682609966124701404199323335292628270480872742575239544590273979492857402108450796344580990042112.000000 -21.8min\n",
      "[CV] estimate__learning_rate=10, estimate__n_estimators=130 ..........\n",
      "[CV]  estimate__learning_rate=10, estimate__n_estimators=110, score=-4328306177892186112800568623633958108657994161138428020831783135785860648311720713968016056407480866963456.000000 -22.4min\n",
      "[CV] estimate__learning_rate=10, estimate__n_estimators=130 ..........\n",
      "[CV]  estimate__learning_rate=10, estimate__n_estimators=110, score=-4393200415624140613749205094637631251515659483615373251525602213552012369259881313836362609518107489730560.000000 -21.7min\n",
      "[CV] estimate__learning_rate=10, estimate__n_estimators=130 ..........\n",
      "[CV]  estimate__learning_rate=10, estimate__n_estimators=110, score=-4369608788794409608360400085681547615553846234093942543796575601329176907664370183725620422423698934333440.000000 -21.5min\n",
      "[CV] estimate__learning_rate=10, estimate__n_estimators=130 ..........\n",
      "[CV]  estimate__learning_rate=10, estimate__n_estimators=130, score=-54144825558727195673196414392468249558311052739960618584521930089662951311504286819696567710146894189505225185965758142742528.000000 -25.8min\n",
      "[CV] estimate__learning_rate=10, estimate__n_estimators=150 ..........\n",
      "[CV]  estimate__learning_rate=10, estimate__n_estimators=130, score=-53838999733470481345107056111942711094583164102596256449967790817591927466155480571867125842509711848343365675273287404355584.000000 -25.8min\n",
      "[CV] estimate__learning_rate=10, estimate__n_estimators=150 ..........\n",
      "[CV]  estimate__learning_rate=10, estimate__n_estimators=130, score=-52622098515081760849563183055974492267901023786445045818405125230359050624231252448951454412051879189186125221545340848570368.000000 -26.2min\n",
      "[CV] estimate__learning_rate=10, estimate__n_estimators=150 ..........\n",
      "[CV]  estimate__learning_rate=10, estimate__n_estimators=130, score=-53411060947610558347144302355231895382981260704204058370560293929972938252953235723809699531784306458885684237361130445471744.000000 -26.5min\n",
      "[CV] estimate__learning_rate=10, estimate__n_estimators=150 ..........\n",
      "[CV]  estimate__learning_rate=10, estimate__n_estimators=130, score=-53124241841104212759394932010858113652503653562519173092823704426898466861667068897621761539712137840912646186451668817674240.000000 -26.2min\n",
      "[CV] estimate__learning_rate=10, estimate__n_estimators=150 ..........\n",
      "[CV]  estimate__learning_rate=10, estimate__n_estimators=150, score=-658274675484621847890526623640808986441055873792887549123472091087217928802458812573815084237235620697603370420665069075247947133585100954927104.000000 -30.1min\n",
      "[CV] estimate__learning_rate=10, estimate__n_estimators=170 ..........\n",
      "[CV]  estimate__learning_rate=10, estimate__n_estimators=150, score=-654556547410668599858776021656282289821959474703969003512713242711206010818094471335975493929747742925302055493937363878514622184250407215169536.000000 -30.7min\n",
      "[CV] estimate__learning_rate=10, estimate__n_estimators=170 ..........\n",
      "[CV]  estimate__learning_rate=10, estimate__n_estimators=150, score=-639761869500362063707391757317459128746180125108793367234171740819106947742196229216795826961323010136812809289249679919800690917929638531432448.000000 -30.5min\n",
      "[CV] estimate__learning_rate=10, estimate__n_estimators=170 ..........\n",
      "[CV]  estimate__learning_rate=10, estimate__n_estimators=150, score=-649353810816750803753010932308771295369422678552345844905956159525703286139158201915417370537596482687041144352628851263549559315060531931381760.000000 -29.9min\n",
      "[CV] estimate__learning_rate=10, estimate__n_estimators=170 ..........\n",
      "[CV]  estimate__learning_rate=10, estimate__n_estimators=150, score=-645866760069251200889112370069592722521321848447373534508436132255727655539174398099910127711466756385367400984393834203808456391451498885677056.000000 -31.0min\n",
      "[CV] estimate__learning_rate=10, estimate__n_estimators=170 ..........\n",
      "[CV]  estimate__learning_rate=10, estimate__n_estimators=170, score=-1747481562548065035626429071651729466293824845526678651415625131872571564137470547675813265156526851711634734210568979673695327485667006266057721324308004864.000000 -35.0min\n",
      "[CV] estimate__learning_rate=10, estimate__n_estimators=190 ..........\n",
      "[CV]  estimate__learning_rate=10, estimate__n_estimators=170, score=-1639741945695404171995442840020740863309635556598758456215439580724061725054370240886376954493984037904463231132576346532997488123291048565402674454142648320.000000 -34.3min\n",
      "[CV]  estimate__learning_rate=10, estimate__n_estimators=170, score=-4913218354729829734851911174674216538131281615912163153747459206264397979251464703410516584284214790223132658067307730545613058141951324425890970487041818624.000000 -35.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Done  92 out of 100 | elapsed: 520.0min remaining: 45.2min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] estimate__learning_rate=10, estimate__n_estimators=190 ..........\n",
      "[CV] estimate__learning_rate=10, estimate__n_estimators=190 ..........\n",
      "[CV]  estimate__learning_rate=10, estimate__n_estimators=170, score=-148565613245029288216645135609479532989964496063309593371556673816536088435956618389322424105893963200787499516744270981523338150572416796958001387110662144.000000 -35.8min\n",
      "[CV] estimate__learning_rate=10, estimate__n_estimators=190 ..........\n",
      "[CV]  estimate__learning_rate=10, estimate__n_estimators=170, score=-2589181004803655742058033281118839680083212551442695399541342634523257079625067036722094737375600464481339087450504320592192160489379048473758137359823536128.000000 -35.1min\n",
      "[CV] estimate__learning_rate=10, estimate__n_estimators=190 ..........\n",
      "[CV]  estimate__learning_rate=10, estimate__n_estimators=190, score=-298888602674526976669409775235691259965430163850232525469712643525683788057293573837191684461552214169847359238298044688107084292115205888595991931474429914748770127446016.000000 -38.0min\n",
      "[CV]  estimate__learning_rate=10, estimate__n_estimators=190, score=-602236254208515998791683939135058074838900428988644191851326204428137173737186151448765556407521985237928199354881874441420659573923965941435422517002928073330056000176128.000000 -38.7min\n",
      "[CV]  estimate__learning_rate=10, estimate__n_estimators=190, score=-50814315919911956794873357579467674019569879862903605966869242536127109531797374928555121243376610133318521845715096067656445585277913538127985117953457809101965620150272.000000 -38.9min\n",
      "[CV]  estimate__learning_rate=10, estimate__n_estimators=190, score=-329666549289669631988652134954586025826594429300158603041391092175947767502678792515114954153416209171043438469555023228531643381868661050361399567142340916969396351533056.000000 -37.0min\n",
      "[CV]  estimate__learning_rate=10, estimate__n_estimators=190, score=-117403127572525715730341160799859080523307484535935856678189303552428580224369204796093947296934247199398345850353906440995573406372568058766229472082924998251978315268096.000000 -36.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Done 100 out of 100 | elapsed: 559.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[mean: -0.87480, std: 0.00756, params: {'estimate__learning_rate': 0.1, 'estimate__n_estimators': 110}, mean: -0.85933, std: 0.00761, params: {'estimate__learning_rate': 0.1, 'estimate__n_estimators': 130}, mean: -0.84929, std: 0.00968, params: {'estimate__learning_rate': 0.1, 'estimate__n_estimators': 150}, mean: -0.84245, std: 0.00731, params: {'estimate__learning_rate': 0.1, 'estimate__n_estimators': 170}, mean: -0.83413, std: 0.00661, params: {'estimate__learning_rate': 0.1, 'estimate__n_estimators': 190}, mean: -0.81587, std: 0.01042, params: {'estimate__learning_rate': 0.5, 'estimate__n_estimators': 110}, mean: -0.81227, std: 0.00811, params: {'estimate__learning_rate': 0.5, 'estimate__n_estimators': 130}, mean: -0.81374, std: 0.01182, params: {'estimate__learning_rate': 0.5, 'estimate__n_estimators': 150}, mean: -0.81562, std: 0.00646, params: {'estimate__learning_rate': 0.5, 'estimate__n_estimators': 170}, mean: -0.80990, std: 0.00755, params: {'estimate__learning_rate': 0.5, 'estimate__n_estimators': 190}, mean: -0.84720, std: 0.01541, params: {'estimate__learning_rate': 1, 'estimate__n_estimators': 110}, mean: -0.84854, std: 0.01047, params: {'estimate__learning_rate': 1, 'estimate__n_estimators': 130}, mean: -0.84776, std: 0.01273, params: {'estimate__learning_rate': 1, 'estimate__n_estimators': 150}, mean: -0.84906, std: 0.01289, params: {'estimate__learning_rate': 1, 'estimate__n_estimators': 170}, mean: -0.85640, std: 0.01518, params: {'estimate__learning_rate': 1, 'estimate__n_estimators': 190}, mean: -4394613875437216646817138030915139564269587270997962346144870548157616364534828651033422911754865016307712.00000, std: 43907693268301752165527793539505186652118115816676538985332236866923677590478143231156687664819279495168.00000, params: {'estimate__learning_rate': 10, 'estimate__n_estimators': 110}, mean: -53428245319198849310217442461561421637593940705023518065439925405520653166633373795458202173988004989203404132579286833954816.00000, std: 533815045804227943488043147630489640270282305383513333688900721744554568574611014042996043791853621366269215715636501544960.00000, params: {'estimate__learning_rate': 10, 'estimate__n_estimators': 130}, mean: -649562732656330955207320305763861501675253952803893299290145036576353150254708559152532302030954354565945470560792048994269460714772407296983040.00000, std: 6489944744688918161170429288954510459443472874331250308549181318649747417485175420954083195117499811933980339928643120007201558251758692597760.00000, params: {'estimate__learning_rate': 10, 'estimate__n_estimators': 150}, mean: -2207637696204396556379179123430535320959158444367395233857083575419782894262157361904942864085012505977987944189495166714541194536870983644995239338034855936.00000, std: inf, params: {'estimate__learning_rate': 10, 'estimate__n_estimators': 170}, mean: -279801769933030081469827140431866912225407973898682598812292756369212301485431762576495909852299509105868339468877301584402811802235159517589783063829699240704366394474496.00000, std: inf, params: {'estimate__learning_rate': 10, 'estimate__n_estimators': 190}]\n",
      "{'estimate__learning_rate': 0.5, 'estimate__n_estimators': 190}\n",
      "-0.809900071722\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('impute', Imputer(axis=0, copy=True, missing_values='NaN', strategy='mean', verbose=0)), ('one_hot', OneHotEncoder(categorical_features=[0, 1, 2, 3], dtype=<type 'float'>,\n",
       "       handle_unknown='error', n_values=[7, 10, 10, 10], sparse=False)), ('scale', StandardScaler(copy=True, with_mean=T...0.0, n_estimators=190,\n",
       "             random_state=None, subsample=1.0, verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.preprocessing import Imputer, OneHotEncoder\n",
    "from sklearn.grid_search import RandomizedSearchCV\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "steps = [\n",
    "#   ('one_hot', OneHotEncoder(categorical_features=[0, 1, 2, 3], sparse=False)),\n",
    "#   ('impute', Imputer(0)),\n",
    "#   ('feature_selection', SelectKBest(f_classif)),\n",
    "#   ('pca', PCA(n_components=120)),\n",
    "  \n",
    "  ('impute', Imputer()),\n",
    "  # Remember that gap, the first variable, is removed, thus categorical_features\n",
    "  # should start at index 0.\n",
    "  ('one_hot', OneHotEncoder(categorical_features=[0, 1, 2, 3], sparse=False,\n",
    "                           n_values=[7, 10, 10, 10])),\n",
    "  ('scale', StandardScaler()),\n",
    "  ('estimate', GradientBoostingRegressor())\n",
    "\n",
    "]\n",
    "\n",
    "est = Pipeline(steps)\n",
    "\n",
    "params = {\n",
    "#   'one_hot__n_values': [7, 10, 20],\n",
    "#   \"feature_selection__k\": [i for i in range(1, n_features - 1)]\n",
    "#   'estimate__max_features': [i for i in range(110, n_features, 10)],\n",
    "  'estimate__learning_rate': [0.1, 0.5, 1, 10],\n",
    "  'estimate__n_estimators': [i for i in range(110, n_features, 20)],\n",
    "#   'estimate__loss': ['linear', 'square', 'exponential']\n",
    "}\n",
    "# cross_validation_iter = StratifiedShuffleSplit(y=targets_train, test_size=0.3,\n",
    "#                                                random_state=RANDOM_STATE, n_iter=10)\n",
    "# search_params = RandomizedSearchCV(\n",
    "#   estimator=est,\n",
    "#   param_distributions=params,\n",
    "#   cv=5,\n",
    "#   scoring=mape_scorer,\n",
    "#   n_jobs=2,\n",
    "#   verbose=1\n",
    "# )\n",
    "\n",
    "search_params = GridSearchCV(\n",
    "  estimator=est,\n",
    "  param_grid=params,\n",
    "  cv=5,\n",
    "  scoring=mape_scorer,\n",
    "  n_jobs=5,\n",
    "  verbose=3\n",
    ")\n",
    "\n",
    "search_params.fit(data_train_original, targets_train)\n",
    "print(search_params.grid_scores_)\n",
    "print(search_params.best_params_)\n",
    "print(search_params.best_score_)\n",
    "search_params.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('impute',\n",
       "  Imputer(axis=0, copy=True, missing_values='NaN', strategy='mean', verbose=0)),\n",
       " ('one_hot',\n",
       "  OneHotEncoder(categorical_features=[0, 1, 2, 3], dtype=<type 'float'>,\n",
       "         handle_unknown='error', n_values=[7, 10, 10, 10], sparse=False)),\n",
       " ('scale', StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       " ('estimate',\n",
       "  GradientBoostingRegressor(alpha=0.9, init=None, learning_rate=0.5, loss='ls',\n",
       "               max_depth=3, max_features=None, max_leaf_nodes=None,\n",
       "               min_samples_leaf=1, min_samples_split=2,\n",
       "               min_weight_fraction_leaf=0.0, n_estimators=190,\n",
       "               random_state=None, subsample=1.0, verbose=0, warm_start=False))]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_params.best_estimator_.steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test data's prediction MAPE score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.797528122453\n"
     ]
    }
   ],
   "source": [
    "final_est = search_params.best_estimator_\n",
    "test_predictions = final_est.predict(data_test_original)\n",
    "print(mape(targets_test, test_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_predictions = search_params.predict(data_test_original)\n",
    "print(mape(targets_test, test_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(final_est, open(EST_PICKLE_FILENAME, \"w\") )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n",
      "loss: 10.10\n",
      "sample predictions:\n",
      "[[  6.47371387e+00]\n",
      " [  9.99732614e-01]\n",
      " [  8.96018438e+04]\n",
      " [  9.99730945e-01]\n",
      " [  4.54779688e+04]\n",
      " [  2.72998505e+01]\n",
      " [  9.99730945e-01]\n",
      " [  3.97196693e+01]\n",
      " [  3.78494692e+00]\n",
      " [  9.99730945e-01]]\n"
     ]
    }
   ],
   "source": [
    "# Compare baseline with final algorithm\n",
    "\n",
    "import pdb\n",
    "import numpy as np\n",
    "import gcp.bigquery as bq\n",
    "import gcp.storage as storage\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import backend as K\n",
    "from keras.optimizers import SGD\n",
    "import tensorflow as tf\n",
    "import h5py\n",
    "from sklearn.preprocessing import Imputer, MinMaxScaler, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "import time\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers import Dropout\n",
    "\n",
    "HDF_FILENAME = 'final_model3.hdf5'\n",
    "JSON_MODEL_FILENAME = 'final_model.json'\n",
    "\n",
    "\n",
    "steps = [\n",
    "  ('impute', Imputer()),\n",
    "  # Remember that gap, the first variable, is removed, thus categorical_features\n",
    "  # should start at index 0.\n",
    "  ('one_hot', OneHotEncoder(categorical_features=[0, 1, 2, 3], sparse=False,\n",
    "                           n_values=[7, 10, 10, 10])),\n",
    "  ('scale', StandardScaler()),\n",
    "#   ('pca', PCA(n_components=120)),\n",
    "#   ('estimate', final_model)\n",
    "]\n",
    "transformer = Pipeline(steps)\n",
    "data_test2 = transformer.fit_transform(data_test_original)\n",
    "\n",
    "\n",
    "\n",
    "def mape(y, predictions):\n",
    "  return K.mean(K.abs(y-predictions/K.clip(K.abs(y), K.epsilon(), np.inf)), axis=-1)\n",
    "\n",
    "epochs = 50\n",
    "\n",
    "def get_optimizer(epochs=50):\n",
    "  learning_rate = 0.2\n",
    "  decay_rate = learning_rate / epochs\n",
    "  momentum = 0.8\n",
    "  return SGD(lr=learning_rate, momentum=momentum, decay=decay_rate, nesterov=False)\n",
    "\n",
    "from keras.models import model_from_json\n",
    "json_file = open(JSON_MODEL_FILENAME, 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(HDF_FILENAME)\n",
    "print(\"Loaded model from disk\")\n",
    "\n",
    "# evaluate loaded model on test data\n",
    "loaded_model.compile(loss=mape, optimizer=get_optimizer(epochs))\n",
    "\n",
    "score = loaded_model.evaluate(data_test2, targets_test, verbose=0)\n",
    "print \"%s: %.2f\" % (loaded_model.metrics_names[0], score)\n",
    "test_predictions2 = loaded_model.predict(data_test2)\n",
    "print 'sample predictions:'\n",
    "print(test_predictions2[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run \"Process Final Test Data With Final Algorithm\" to use pickled final algorithm against final test data to produce csv required by this competition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results\n",
    "\n",
    "Pipeline(steps=[('one_hot', OneHotEncoder(categorical_features=[0, 1, 2, 3], dtype=<type 'float'>,\n",
    "       handle_unknown='error', n_values='auto', sparse=False)), ('pca', PCA(copy=True, n_components=120, whiten=False)), ('estimate', DecisionTreeRegressor(criterion='mse', max_depth=None, max_features=112,\n",
    "           max_leaf_nodes=None, min_samples_leaf=1, min_samples_split=2,\n",
    "           min_weight_fraction_leaf=0.0, random_state=None,\n",
    "           splitter='best'))])\n",
    "           \n",
    "1000 training data, Score: 0.924\n",
    "\n",
    "Pipeline(steps=[('one_hot', OneHotEncoder(categorical_features=[0, 1, 2, 3], dtype=<type 'float'>,\n",
    "       handle_unknown='error', n_values='auto', sparse=False)), ('pca', PCA(copy=True, n_components=120, whiten=False)), ('estimate', DecisionTreeRegressor(criterion='mse', max_depth=None, max_features=114,\n",
    "           max_leaf_nodes=None, min_samples_leaf=1, min_samples_split=2,\n",
    "           min_weight_fraction_leaf=0.0, random_state=None,\n",
    "           splitter='best'))])\n",
    "\n",
    "5000 training data, Score: 0.992\n",
    "\n",
    "\n",
    "Pipeline(steps=[('one_hot', OneHotEncoder(categorical_features=[0, 1, 2, 3], dtype=<type 'float'>,\n",
    "       handle_unknown='error', n_values='auto', sparse=False)), ('pca', PCA(copy=True, n_components=120, whiten=False)), ('estimate', DecisionTreeRegressor(criterion='mse', max_depth=None, max_features=111,\n",
    "           max_leaf_nodes=None, min_samples_leaf=1, min_samples_split=2,\n",
    "           min_weight_fraction_leaf=0.0, random_state=None,\n",
    "           splitter='best'))])\n",
    "           \n",
    "20000 training data, Score: 1.001\n",
    "\n",
    "Pipeline(steps=[('impute', Imputer(axis=0, copy=True, missing_values='NaN', strategy='mean', verbose=0)), ('one_hot', OneHotEncoder(categorical_features=[0, 1, 2, 3], dtype=<type 'float'>,\n",
    "       handle_unknown='error', n_values=[7, 10, 10, 10], sparse=False)), ('scale', StandardScaler(copy=True, with_mean=T...s_split=2,\n",
    "           min_weight_fraction_leaf=0.0, random_state=None,\n",
    "           splitter='best'))])\n",
    "           \n",
    "80000 training data, Score: 0.977 (submitted date 17)\n",
    "\n",
    "[('impute',\n",
    "  Imputer(axis=0, copy=True, missing_values='NaN', strategy='mean', verbose=0)),\n",
    " ('one_hot',\n",
    "  OneHotEncoder(categorical_features=[0, 1, 2, 3], dtype=<type 'float'>,\n",
    "         handle_unknown='error', n_values=[7, 10, 10, 10], sparse=False)),\n",
    " ('scale', StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
    " ('estimate',\n",
    "  GradientBoostingRegressor(alpha=0.9, init=None, learning_rate=0.5, loss='ls',\n",
    "               max_depth=3, max_features=None, max_leaf_nodes=None,\n",
    "               min_samples_leaf=1, min_samples_split=2,\n",
    "               min_weight_fraction_leaf=0.0, n_estimators=190,\n",
    "               random_state=None, subsample=1.0, verbose=0, warm_start=False))]\n",
    "               \n",
    "80000 training data, Score: 0.798"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
