{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import gcp.bigquery as bq\n",
    "import gcp.storage as storage\n",
    "import numpy as np\n",
    "try:\n",
    "   import cPickle as pickle\n",
    "except:\n",
    "   import pickle\n",
    "EST_PICKLE_FILENAME = 'baseline_final_estimator.pkl'\n",
    "\n",
    "# First feature HAS to be 'district_id' for MAPE calculation.\n",
    "fields_str = \"\"\"gap, district_id, sum_price, traffic_tj_level3, traffic_tj_level2, traffic_tj_level4, f23,\n",
    "  f16_10,f17_3, f19, f5_3, f11_3, f24_2, f20_2, f13_4, f4, f4_5, f11_2, f25, f25_3, f7, f11_4,\n",
    "  f23_3, f17_4, f8_4, f15_7, f4_17, f8_2, f4_10, f15_2, f11_6, f15, f17_5, f1_4, f24_1, f1,\n",
    "  f16_11, f19_3, f23_6, f2_2, f11, f15_3, f8_3, f15_6, f6_1, f6_4, f8, f11_8, f25_8, f23_4,\n",
    "  f17_2, f1_5, f4_9, f1_8, f4_11, f20_8, f2_5, f16, f25_9, f6_2, f14_3, f15_4, f4_7, f5_1, f5,\n",
    "  f4_18, f14_8, f11_7, f3_2, f20_5, f17, f11_1, f4_14, f23_5, f1_7, traffic_tj_level1, f23_2,\n",
    "  f20, f1_3, f13_8, f1_2, f8_1, f23_1, f11_5, f2_12, f4_1, f2_7, f22_1, f25_7\n",
    "\"\"\"\n",
    "fields = map(lambda x: x.strip(), fields_str.split(','))\n",
    "features = fields[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Final Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%sql --module q_all_f\n",
    "\n",
    "SELECT *\n",
    "FROM [datalab-projects-1331:xjk_algo_comp_test.future_gaps_processed]\n",
    "WHERE gap > 0 AND timeslot IN ('2016-01-22-46','2016-01-22-58','2016-01-22-70','2016-01-22-82',\n",
    "    '2016-01-22-94','2016-01-22-106','2016-01-22-118','2016-01-22-130','2016-01-22-142',\n",
    "    '2016-01-24-58','2016-01-24-70','2016-01-24-82','2016-01-24-94','2016-01-24-106',\n",
    "    '2016-01-24-118','2016-01-24-130','2016-01-24-142','2016-01-26-46','2016-01-26-58',\n",
    "    '2016-01-26-70','2016-01-26-82','2016-01-26-94','2016-01-26-106','2016-01-26-118',\n",
    "    '2016-01-26-130','2016-01-26-142','2016-01-28-58','2016-01-28-70','2016-01-28-82',\n",
    "    '2016-01-28-94','2016-01-28-106','2016-01-28-118','2016-01-28-130','2016-01-28-142',\n",
    "    '2016-01-30-46','2016-01-30-58','2016-01-30-70','2016-01-30-82','2016-01-30-94',\n",
    "    '2016-01-30-106','2016-01-30-118','2016-01-30-130','2016-01-30-142')\n",
    "ORDER BY timeslot, district_id\n",
    "\n",
    "# Final dataset - Used in final submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "query_f = bq.Query(q_all_f)\n",
    "tableresult_f = query_f.results()\n",
    "\n",
    "all_data_f = np.zeros((tableresult_f.length, len(fields)))\n",
    "print 'there are {} rows'.format(tableresult_f.length)\n",
    "for rcounter, row in enumerate(tableresult_f):\n",
    "  for fcounter, field in enumerate(fields):\n",
    "    all_data_f[rcounter, fcounter] = row[field]\n",
    "  if rcounter % 1000 == 0:\n",
    "    print 'processed {} rows'.format(rcounter)\n",
    "    \n",
    "all_data_f[np.isnan(all_data_f)] = 0\n",
    "data_final = all_data_f[:,1:]\n",
    "targets_final = all_data_f[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Prediction and Export CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_est = pickle.load(open(EST_PICKLE_FILENAME, \"r\") )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%sql --module q_districts\n",
    "\n",
    "SELECT district_id FROM [datalab-projects-1331:xjk_algo_comp_test.districts] ORDER BY district_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "query_districts = bq.Query(q_districts)\n",
    "tableresult_districts = query_districts.results()\n",
    "districts = [d['district_id'] for d in tableresult_districts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "final_predictions = final_est.predict(data_final)\n",
    "\n",
    "slots = ['2016-01-22-46','2016-01-22-58','2016-01-22-70','2016-01-22-82',\n",
    "    '2016-01-22-94','2016-01-22-106','2016-01-22-118','2016-01-22-130','2016-01-22-142',\n",
    "    '2016-01-24-58','2016-01-24-70','2016-01-24-82','2016-01-24-94','2016-01-24-106',\n",
    "    '2016-01-24-118','2016-01-24-130','2016-01-24-142','2016-01-26-46','2016-01-26-58',\n",
    "    '2016-01-26-70','2016-01-26-82','2016-01-26-94','2016-01-26-106','2016-01-26-118',\n",
    "    '2016-01-26-130','2016-01-26-142','2016-01-28-58','2016-01-28-70','2016-01-28-82',\n",
    "    '2016-01-28-94','2016-01-28-106','2016-01-28-118','2016-01-28-130','2016-01-28-142',\n",
    "    '2016-01-30-46','2016-01-30-58','2016-01-30-70','2016-01-30-82','2016-01-30-94',\n",
    "    '2016-01-30-106','2016-01-30-118','2016-01-30-130','2016-01-30-142']\n",
    "\n",
    "result_dicts = []\n",
    "print \"Preparing results...\"\n",
    "for slot in slots:\n",
    "  for district in districts:\n",
    "#     pred = 0.0\n",
    "#     try:\n",
    "#       id = (index for (index, item) in enumerate(tableresult_f) if \n",
    "#             item['timeslot'] == slot and item['district_id'] == id).next()\n",
    "#       pred = final_predictions[id]\n",
    "#     except:\n",
    "#       pass\n",
    "    result_dicts.append({'key': '{}:{}'.format(district, slot), 'value': \\\n",
    "      '{},{},{}'.format(district, slot,0.0)})\n",
    "\n",
    "print 'Replacing predictions...'\n",
    "for (index, item) in enumerate(tableresult_f):\n",
    "  id = (idx for (r_id, r_item) in enumerate(result_dicts) if \n",
    "    r_item['key'] == '{}:{}'.format(item['district_id'], item['timeslot'])).next()\n",
    "  print \"id: {}, pred: {}\".format(id, final_predictions[index])\n",
    "  result_dicts[id]['value'] = \\\n",
    "    '{},{},{}'.format(item['district_id'], item['timeslot'],final_predictions[index])\n",
    "  if index % 200 == 0:\n",
    "    print 'Done {}/{}...'.format(index, tableresult_f.length)\n",
    "    \n",
    "result = '\\n'.join(map(lambda d: d['value'], result_dicts))\n",
    "bucketname = 'datalab-projects-1331-datalab'\n",
    "itempath = 'result/final_result.csv'\n",
    "print 'Done, now writing to gs://{}/{}'.format(bucketname, itempath)\n",
    "item = storage.Item(bucketname, itempath)\n",
    "item.write_to(result, 'text/plain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
