{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bucket: gs://datalab-projects-1331-datalab/data\n"
     ]
    }
   ],
   "source": [
    "from cStringIO import StringIO\n",
    "import gzip\n",
    "import os\n",
    "import glob\n",
    "import re\n",
    "import pdb\n",
    "\n",
    "import gcp\n",
    "from gcp import storage\n",
    "from gcp import bigquery as bq\n",
    "import pandas as pd\n",
    "\n",
    "# Import zip file from Google Cloud Storage\n",
    "project = gcp.Context.default().project_id\n",
    "bucket_name = project + '-datalab'\n",
    "bucket_path = 'gs://' + bucket_name + '/data'\n",
    "print 'Bucket: ' + bucket_path\n",
    "compressed_filename = 'citydata'\n",
    "season_name = 'season_2'\n",
    "subdirectory_name = 'test_set_2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gzip_filename = '{}.tar.gz'.format(compressed_filename)\n",
    "tar_filename = '{}.tar'.format(compressed_filename)\n",
    "compressed_file = None\n",
    "datadir = season_name\n",
    "# If data has not been extracted, extract it.\n",
    "if not os.path.isdir(datadir):\n",
    "  # If citydata.tar has not been downloaded, download it\n",
    "  if not os.path.isfile(tar_filename):\n",
    "    bucket_object = '{}/{}'.format(bucket_path, gzip_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%storage read --object $bucket_object --variable compressed_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if compressed_file:\n",
    "  gzip_file = gzip.GzipFile(fileobj=StringIO(compressed_file))\n",
    "  del compressed_file\n",
    "\n",
    "  import shutil\n",
    "  with open(tar_filename, 'wb') as f_out:\n",
    "    shutil.copyfileobj(gzip_file, f_out)\n",
    "    \n",
    "  import tarfile\n",
    "  tar = tarfile.open(tar_filename, \"r\")\n",
    "  tar.extractall()\n",
    "  tar.close()\n",
    "  os.remove(tar_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Downloading and extracting the files from cloud storage.\n",
    "\n",
    "def process_datafile(localpath, storagepath, table, mode='create', overwrite=False):\n",
    "  # Upload extracted file into GCS\n",
    "  storagepath_r = storagepath.split('/')\n",
    "  bucketname = storagepath_r[2]\n",
    "  itempath = '/'.join(storagepath_r[3:])\n",
    "  item = storage.Item(bucketname, itempath)\n",
    "  if not item.exists() or overwrite:    \n",
    "    with open(localpath, 'rb') as f:\n",
    "      item.write_to(f.read(), 'text/plain')\n",
    "  # Load data into Google BigQuery\n",
    "  table.load(storagepath, mode=mode, csv_options=bq.CSVOptions(delimiter='\\t'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process Training Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Districts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "table = bq.Table('datalab-projects-1331:xjk_algo_comp_test.districts_preprocessed')\n",
    "if not table.exists():\n",
    "  schema = bq.Schema([\n",
    "      {'name': 'district_hash', 'type': 'STRING'},\n",
    "      {'name': 'district_id', 'type': 'INTEGER'}\n",
    "    ])\n",
    "  table.create(schema)\n",
    "  \n",
    "localpath = '{}/{}/cluster_map/cluster_map'.format(season_name, subdirectory_name)\n",
    "storagepath = os.path.join(bucket_path,localpath)\n",
    "process_datafile(localpath, storagepath, table, mode='append')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bigquery execute -t datalab-projects-1331:xjk_algo_comp_test.districts -m overwrite\n",
    "SELECT LAST(district_hash) AS district_hash, district_id\n",
    "FROM [datalab-projects-1331:xjk_algo_comp_test.districts_preprocessed]\n",
    "GROUP BY district_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "table = bq.Table('datalab-projects-1331:xjk_algo_comp_test.weather_preprocessed')\n",
    "if not table.exists():\n",
    "  schema = bq.Schema([\n",
    "      {'name': 'time', 'type': 'STRING'},\n",
    "      {'name': 'weather', 'type': 'INTEGER'},\n",
    "      {'name': 'temperature', 'type': 'FLOAT'},\n",
    "      {'name': 'pm25', 'type': 'FLOAT'}\n",
    "    ])\n",
    "  table.create(schema)\n",
    "  \n",
    "wildpath = '{}/{}/weather_data/*'.format(season_name, subdirectory_name)\n",
    "for localpath in glob.glob(wildpath):\n",
    "  print 'process {}'.format(storagepath)\n",
    "  storagepath = os.path.join(bucket_path,localpath)\n",
    "  process_datafile(localpath, storagepath, table, mode='append')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bigquery udf --module transform_weather_time\n",
    "\n",
    "/**\n",
    " * Pad with 0 or given string.\n",
    " *\n",
    " * @param int n Number to add padding to.\n",
    " * @param int width Width of number + padding.\n",
    " * @param string z (Optional) Other string to replace '0' as padding.\n",
    " */\n",
    "function pad(n, width, z) {\n",
    "  z = z || '0';\n",
    "  n = n + '';\n",
    "  return n.length >= width ? n : new Array(width - n.length + 1).join(z) + n;\n",
    "}\n",
    "\n",
    "/**\n",
    " * Transform timestamps of weather table into timeslots in weather table.\n",
    " *\n",
    " * @param {{time: string, weather: integer, temperature: float, pm25: float}} r\n",
    " * @param function({{time: string, weather: integer, temperature: float, pm25: float,\n",
    "                     timeslot: string, timeofday_slot: integer, day_in_week: integer,\n",
    "                     date: string}}) emitFn\n",
    " */\n",
    "function(r, emitFn) {\n",
    "  var t = r.time.split(/[ :\\-]/);\n",
    "  var slot = Math.floor((parseInt(t[3]) * 60 + parseInt(t[4])) / 10) + 1;\n",
    "  r.timeslot = t[0] + '-' + pad(t[1], 2) +\n",
    "               '-' + pad(t[2], 2) + '-' + slot;\n",
    "  r.timeofday_slot = slot;\n",
    "  r.date = t[0] + '-' + pad(t[1], 2) + '-' + pad(t[2], 2);\n",
    "  r.day_in_week = new Date(parseInt(t[0]), parseInt(t[1])-1, parseInt(t[2])).getDay();\n",
    "  emitFn(r);\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bigquery execute -t datalab-projects-1331:xjk_algo_comp_test.weather -m overwrite\n",
    "SELECT LAST(time) AS time, LAST(weather) AS weather,\n",
    "  LAST(temperature) AS temperature, LAST(pm25) AS pm25, timeslot\n",
    "FROM transform_weather_time([datalab-projects-1331:xjk_algo_comp_test.weather_preprocessed])\n",
    "GROUP BY timeslot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Traffic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "table = bq.Table('datalab-projects-1331:xjk_algo_comp_test.traffic_preprocessed')\n",
    "if not table.exists():\n",
    "  schema = bq.Schema([\n",
    "      {'name': 'district_hash', 'type': 'STRING'},\n",
    "      {'name': 'tj_level1', 'type': 'INTEGER'},\n",
    "      {'name': 'tj_level2', 'type': 'INTEGER'},\n",
    "      {'name': 'tj_level3', 'type': 'INTEGER'},\n",
    "      {'name': 'tj_level4', 'type': 'INTEGER'},\n",
    "      {'name': 'tj_time', 'type': 'STRING'}\n",
    "    ])\n",
    "  table.create(schema)\n",
    "  \n",
    "wildpath = '{}/{}/traffic_data/*'.format(season_name, subdirectory_name)\n",
    "for localpath in glob.glob(wildpath):\n",
    "  with open(localpath, 'rb') as f:\n",
    "    text = f.read()\n",
    "  with open(localpath, 'wb') as f:\n",
    "    f.write(re.sub(r'\\b\\t[0-9]:\\b', '\\t', text))\n",
    "  storagepath = os.path.join(bucket_path,localpath)\n",
    "  print 'process {}'.format(storagepath)\n",
    "  process_datafile(localpath, storagepath, table, mode='append', overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bigquery udf --module transform_traffic_time\n",
    "  \n",
    "/**\n",
    " * Pad with 0 or given string.\n",
    " *\n",
    " * @param int n Number to add padding to.\n",
    " * @param int width Width of number + padding.\n",
    " * @param string z (Optional) Other string to replace '0' as padding.\n",
    " */\n",
    "function pad(n, width, z) {\n",
    "  z = z || '0';\n",
    "  n = n + '';\n",
    "  return n.length >= width ? n : new Array(width - n.length + 1).join(z) + n;\n",
    "}\n",
    "\n",
    "/**\n",
    " * Transform timestamps of weather table into timeslots in traffic table.\n",
    " *\n",
    " * @param {{district_hash: string, tj_level1: integer, tj_level2: integer, tj_level3: integer, \n",
    "            tj_level4: integer, tj_time: string}} r\n",
    " * @param function({{district_hash: string, tj_level1: integer, tj_level2: integer, tj_level3: integer, \n",
    "                     tj_level4: integer, tj_time: string, timeslot: string, timeofday_slot: integer,\n",
    "                     day_in_week: integer, date: string}}) emitFn\n",
    " */\n",
    "function(r, emitFn) {\n",
    "  var t = r.tj_time.split(/[ :\\-]/);\n",
    "  var slot = Math.floor((parseInt(t[3]) * 60 + parseInt(t[4])) / 10) + 1;\n",
    "  r.timeslot = t[0] + '-' + pad(t[1], 2) +\n",
    "               '-' + pad(t[2], 2) + '-' + slot;\n",
    "  r.timeofday_slot = slot;\n",
    "  r.date = t[0] + '-' + pad(t[1], 2) + '-' + pad(t[2], 2);\n",
    "  r.day_in_week = new Date(parseInt(t[0]), parseInt(t[1])-1, parseInt(t[2])).getDay();\n",
    "  emitFn(r);\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(L3:50): Expression 'timeofday_slot' is not present in the GROUP BY list\n"
     ]
    }
   ],
   "source": [
    "%%bigquery execute -t datalab-projects-1331:xjk_algo_comp_test.traffic -m overwrite\n",
    "  \n",
    "SELECT district_hash, AVG(tj_level1) AS tj_level1,\n",
    "  AVG(tj_level2) AS tj_level2, AVG(tj_level3) AS tj_level3, AVG(tj_level4) AS tj_level4,\n",
    "  LAST(tj_time) AS tj_time, timeslot, timeofday_slot, day_in_week, date\n",
    "FROM transform_traffic_time([datalab-projects-1331:xjk_algo_comp_test.traffic_preprocessed])\n",
    "GROUP BY district_hash, timeslot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## POIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "table = bq.Table('datalab-projects-1331:xjk_algo_comp_test.pois_preprocessed')\n",
    "  \n",
    "localpath = '{}/{}/poi_data/poi_data'.format(season_name, subdirectory_name)\n",
    "\n",
    "pois = []\n",
    "pois_schema = [{'name': 'district_hash', 'type': 'STRING'}]\n",
    "with open(localpath, 'rb') as f:\n",
    "  for line in f:\n",
    "    line_pois = map(lambda x: ['f{}'.format(x.split(':')[0].replace('#', '_')), x.split(':')[1]],\n",
    "                    line.split('\\t')[1:])\n",
    "  for poi in line_pois:\n",
    "    if poi[0] not in pois:\n",
    "      pois.append(poi[0])\n",
    "      pois_schema.append({'name': poi[0], 'type': 'INTEGER'})\n",
    "pois.sort()\n",
    "pois_schema = sorted(pois_schema, key=lambda k: k['name']) \n",
    "\n",
    "if not table.exists():\n",
    "  schema = bq.Schema.from_data(pois_schema)\n",
    "  table.create(schema)\n",
    "  \n",
    "  pois_data = pd.DataFrame(columns=['district_hash'] + pois)\n",
    "  with open(localpath, 'rb') as f:\n",
    "    for line in f:\n",
    "      hash_pois = {}\n",
    "      for poi_line in line.split('\\t')[1:]:\n",
    "        hash_pois['f{}'.format(poi_line.split(':')[0].replace('#', '_'))] = poi_line.split(':')[1]\n",
    "      poi_data = [line.split('\\t')[0]]\n",
    "      # hash_pois = {f1_1: 15, ...}\n",
    "      # pois = ['f1_1', ...]\n",
    "      for poi in pois:\n",
    "        value = '0'\n",
    "        if poi in hash_pois:\n",
    "          value = hash_pois[poi].strip()\n",
    "        poi_data.append(value)\n",
    "      pois_data.loc[len(pois_data)] = poi_data\n",
    "  for poi in pois:\n",
    "    pois_data[poi] = pd.to_numeric(pois_data[poi])\n",
    "  table.insert_data(pois_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following code can be used to print out feature fields to be used when selecting from tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "final_text = ''\n",
    "for counter, poi_text in enumerate(map(lambda x: 'LAST(pois.{}) AS {}'.format(x,x), pois)):\n",
    "  if counter%3 == 0:\n",
    "    final_text = '{}\\n'.format(final_text)\n",
    "  final_text = '{}{}, '.format(final_text, poi_text)\n",
    "print final_text[1:(len(final_text)-2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bigquery execute -t datalab-projects-1331:xjk_algo_comp_test.pois -m overwrite\n",
    "  \n",
    "SELECT district_hash,\n",
    "LAST(pois.f1) AS f1, LAST(pois.f11) AS f11, LAST(pois.f11_1) AS f11_1, \n",
    "LAST(pois.f11_2) AS f11_2, LAST(pois.f11_3) AS f11_3, LAST(pois.f11_4) AS f11_4, \n",
    "LAST(pois.f11_5) AS f11_5, LAST(pois.f11_6) AS f11_6, LAST(pois.f11_7) AS f11_7, \n",
    "LAST(pois.f11_8) AS f11_8, LAST(pois.f13_4) AS f13_4, LAST(pois.f13_8) AS f13_8, \n",
    "LAST(pois.f14) AS f14, LAST(pois.f14_1) AS f14_1, LAST(pois.f14_10) AS f14_10, \n",
    "LAST(pois.f14_2) AS f14_2, LAST(pois.f14_3) AS f14_3, LAST(pois.f14_6) AS f14_6, \n",
    "LAST(pois.f14_8) AS f14_8, LAST(pois.f15) AS f15, LAST(pois.f15_1) AS f15_1, \n",
    "LAST(pois.f15_2) AS f15_2, LAST(pois.f15_3) AS f15_3, LAST(pois.f15_4) AS f15_4, \n",
    "LAST(pois.f15_6) AS f15_6, LAST(pois.f15_7) AS f15_7, LAST(pois.f15_8) AS f15_8, \n",
    "LAST(pois.f16) AS f16, LAST(pois.f16_1) AS f16_1, LAST(pois.f16_10) AS f16_10, \n",
    "LAST(pois.f16_11) AS f16_11, LAST(pois.f16_12) AS f16_12, LAST(pois.f16_3) AS f16_3, \n",
    "LAST(pois.f16_4) AS f16_4, LAST(pois.f16_6) AS f16_6, LAST(pois.f17) AS f17, \n",
    "LAST(pois.f17_2) AS f17_2, LAST(pois.f17_3) AS f17_3, LAST(pois.f17_4) AS f17_4, \n",
    "LAST(pois.f17_5) AS f17_5, LAST(pois.f19) AS f19, LAST(pois.f19_1) AS f19_1, \n",
    "LAST(pois.f19_2) AS f19_2, LAST(pois.f19_3) AS f19_3, LAST(pois.f19_4) AS f19_4, \n",
    "LAST(pois.f1_1) AS f1_1, LAST(pois.f1_10) AS f1_10, LAST(pois.f1_11) AS f1_11, \n",
    "LAST(pois.f1_2) AS f1_2, LAST(pois.f1_3) AS f1_3, LAST(pois.f1_4) AS f1_4, \n",
    "LAST(pois.f1_5) AS f1_5, LAST(pois.f1_6) AS f1_6, LAST(pois.f1_7) AS f1_7, \n",
    "LAST(pois.f1_8) AS f1_8, LAST(pois.f20) AS f20, LAST(pois.f20_1) AS f20_1, \n",
    "LAST(pois.f20_2) AS f20_2, LAST(pois.f20_4) AS f20_4, LAST(pois.f20_5) AS f20_5, \n",
    "LAST(pois.f20_6) AS f20_6, LAST(pois.f20_7) AS f20_7, LAST(pois.f20_8) AS f20_8, \n",
    "LAST(pois.f20_9) AS f20_9, LAST(pois.f21_1) AS f21_1, LAST(pois.f21_2) AS f21_2, \n",
    "LAST(pois.f22) AS f22, LAST(pois.f22_1) AS f22_1, LAST(pois.f22_2) AS f22_2, \n",
    "LAST(pois.f22_3) AS f22_3, LAST(pois.f22_4) AS f22_4, LAST(pois.f22_5) AS f22_5, \n",
    "LAST(pois.f23) AS f23, LAST(pois.f23_1) AS f23_1, LAST(pois.f23_2) AS f23_2, \n",
    "LAST(pois.f23_3) AS f23_3, LAST(pois.f23_4) AS f23_4, LAST(pois.f23_5) AS f23_5, \n",
    "LAST(pois.f23_6) AS f23_6, LAST(pois.f24) AS f24, LAST(pois.f24_1) AS f24_1, \n",
    "LAST(pois.f24_2) AS f24_2, LAST(pois.f24_3) AS f24_3, LAST(pois.f25) AS f25, \n",
    "LAST(pois.f25_1) AS f25_1, LAST(pois.f25_3) AS f25_3, LAST(pois.f25_7) AS f25_7, \n",
    "LAST(pois.f25_8) AS f25_8, LAST(pois.f25_9) AS f25_9, LAST(pois.f2_1) AS f2_1, \n",
    "LAST(pois.f2_10) AS f2_10, LAST(pois.f2_11) AS f2_11, LAST(pois.f2_12) AS f2_12, \n",
    "LAST(pois.f2_13) AS f2_13, LAST(pois.f2_2) AS f2_2, LAST(pois.f2_4) AS f2_4, \n",
    "LAST(pois.f2_5) AS f2_5, LAST(pois.f2_6) AS f2_6, LAST(pois.f2_7) AS f2_7, \n",
    "LAST(pois.f2_8) AS f2_8, LAST(pois.f3_1) AS f3_1, LAST(pois.f3_2) AS f3_2, \n",
    "LAST(pois.f3_3) AS f3_3, LAST(pois.f4) AS f4, LAST(pois.f4_1) AS f4_1, \n",
    "LAST(pois.f4_10) AS f4_10, LAST(pois.f4_11) AS f4_11, LAST(pois.f4_13) AS f4_13, \n",
    "LAST(pois.f4_14) AS f4_14, LAST(pois.f4_16) AS f4_16, LAST(pois.f4_17) AS f4_17, \n",
    "LAST(pois.f4_18) AS f4_18, LAST(pois.f4_2) AS f4_2, LAST(pois.f4_3) AS f4_3, \n",
    "LAST(pois.f4_5) AS f4_5, LAST(pois.f4_6) AS f4_6, LAST(pois.f4_7) AS f4_7, \n",
    "LAST(pois.f4_8) AS f4_8, LAST(pois.f4_9) AS f4_9, LAST(pois.f5) AS f5, \n",
    "LAST(pois.f5_1) AS f5_1, LAST(pois.f5_3) AS f5_3, LAST(pois.f5_4) AS f5_4, \n",
    "LAST(pois.f6) AS f6, LAST(pois.f6_1) AS f6_1, LAST(pois.f6_2) AS f6_2, \n",
    "LAST(pois.f6_4) AS f6_4, LAST(pois.f7) AS f7, LAST(pois.f8) AS f8, \n",
    "LAST(pois.f8_1) AS f8_1, LAST(pois.f8_2) AS f8_2, LAST(pois.f8_3) AS f8_3, \n",
    "LAST(pois.f8_4) AS f8_4, LAST(pois.f8_5) AS f8_5\n",
    "FROM [datalab-projects-1331:xjk_algo_comp_test.pois_preprocessed] AS pois\n",
    "GROUP BY district_hash"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "table = bq.Table('datalab-projects-1331:xjk_algo_comp_test.orders_preprocessed')\n",
    "if not table.exists():\n",
    "  schema = bq.Schema([{'name': 'order_id', 'type': 'STRING'},\n",
    "                      {'name': 'driver_id', 'type': 'STRING'},\n",
    "                      {'name': 'passenger_id', 'type': 'STRING'},\n",
    "                      {'name': 'start_district_hash', 'type': 'STRING'},\n",
    "                      {'name': 'dest_district_hash', 'type': 'STRING'},\n",
    "                      {'name': 'price', 'type': 'FLOAT'},\n",
    "                      {'name': 'time', 'type': 'STRING'}])\n",
    "  table.create(schema)\n",
    "  \n",
    "wildpath = '{}/{}/order_data/*'.format(season_name, subdirectory_name)\n",
    "for localpath in glob.glob(wildpath):\n",
    "  print 'loading {}'.format(localpath)\n",
    "  storagepath = os.path.join(bucket_path,localpath)\n",
    "  process_datafile(localpath, storagepath, table, mode='append')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bigquery execute -t datalab-projects-1331:xjk_algo_comp_test.orders_preprocessed2 -m overwrite\n",
    "\n",
    "SELECT order_id, LAST(driver_id) AS driver_id, LAST(passenger_id) AS passenger_id,\n",
    "  LAST(start_district_hash) AS start_district_hash, LAST(dest_district_hash) AS dest_district_hash,\n",
    "  LAST(price) AS price, LAST(time) AS time\n",
    "FROM [datalab-projects-1331:xjk_algo_comp_test.orders_preprocessed]\n",
    "GROUP BY order_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bigquery udf --module orders_create_additional_fields\n",
    "\n",
    "/**\n",
    " * Pad with 0 or given string.\n",
    " *\n",
    " * @param int n Number to add padding to.\n",
    " * @param int width Width of number + padding.\n",
    " * @param string z (Optional) Other string to replace '0' as padding.\n",
    " */\n",
    "function pad(n, width, z) {\n",
    "  z = z || '0';\n",
    "  n = n + '';\n",
    "  return n.length >= width ? n : new Array(width - n.length + 1).join(z) + n;\n",
    "}\n",
    "\n",
    "/**\n",
    " * Create additional fields on orders table for gaps table creation.\n",
    " *\n",
    " * @param {{order_id: string, driver_id: string, passenger_id: string,\n",
    "            start_district_hash: string, dest_district_hash: string, price: float,\n",
    "            time: string}} r\n",
    " * @param function({{order_id: string, driver_id: string, passenger_id: string,\n",
    "                     start_district_hash: string, dest_district_hash: string, price: float,\n",
    "                     time: string, timeslot: string, timeofday_slot: integer, day_in_week: integer,\n",
    "                     date: string}}) emitFn\n",
    " */\n",
    "function(r, emitFn) {\n",
    "  var t = r.time.split(/[ :\\-]/);\n",
    "  var slot = Math.floor((parseInt(t[3]) * 60 + parseInt(t[4])) / 10) + 1;\n",
    "  r.timeslot = t[0] + '-' + pad(t[1], 2) +\n",
    "               '-' + pad(t[2], 2) + '-' + slot;\n",
    "  r.timeofday_slot = slot;\n",
    "  r.date = t[0] + '-' + pad(t[1], 2) + '-' + pad(t[2], 2);\n",
    "  r.day_in_week = new Date(parseInt(t[0]), parseInt(t[1])-1, parseInt(t[2])).getDay();\n",
    "  emitFn(r);\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bigquery execute -t datalab-projects-1331:xjk_algo_comp_test.orders -m overwrite\n",
    "SELECT order_id, driver_id, passenger_id,\n",
    "  start_district_hash, dest_district_hash,\n",
    "  price, time, timeslot, timeofday_slot, day_in_week, date\n",
    "FROM orders_create_additional_fields([datalab-projects-1331:xjk_algo_comp_test.orders_preprocessed2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
