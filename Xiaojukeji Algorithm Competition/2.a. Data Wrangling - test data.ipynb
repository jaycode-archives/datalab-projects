{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gcp.storage as storage\n",
    "import gcp.bigquery as bq\n",
    "from datetime import date\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import date\n",
    "from datetime import timedelta\n",
    "import pdb\n",
    "prev_n_range = 3\n",
    "\n",
    "def calc_past_timeslot(timeslot, slots):\n",
    "  timeslot_r = map(lambda x: int(x), timeslot.split('-'))\n",
    "  slot = timeslot_r[3] - slots\n",
    "  date_obj = date(timeslot_r[0], timeslot_r[1], timeslot_r[2])\n",
    "  if slot <= 0:\n",
    "    slot = 144\n",
    "    date_obj = date_obj - timedelta(days=1)\n",
    "  return '{}-{}-{}-{}'.format(\n",
    "    date_obj.year, str(date_obj.month).zfill(2), str(date_obj.day).zfill(2), slot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaps Table Creation\n",
    "I learned the hard way that in Machine Learning competition it is better to start defining the requirements from the test data. Aside of it being much smaller than training data, there are usually also some hints to what the final algorithm should be.\n",
    "\n",
    "In this project, for example, by looking at, say `traffic` data, it appears that we are expected to predict gaps from 3 previous timeslots, as these rows are the only ones that are available. Let's wrangle the data accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pois_table = bq.Table('datalab-projects-1331:xjk_algo_comp_test.pois')\n",
    "pois_fields = [item['name'] for item in pois_table.schema][1:]\n",
    "traffic_fields = []\n",
    "weather_fields = []\n",
    "orders_fields = []\n",
    "for i in range(prev_n_range):\n",
    "  prev_n = i+1\n",
    "  traffic_fields.append('tj_level1_{}_slots_ago'.format(prev_n))\n",
    "  traffic_fields.append('tj_level2_{}_slots_ago'.format(prev_n))\n",
    "  traffic_fields.append('tj_level3_{}_slots_ago'.format(prev_n))\n",
    "  traffic_fields.append('tj_level4_{}_slots_ago'.format(prev_n))\n",
    "  weather_fields.append('weather_{}_slots_ago'.format(prev_n))\n",
    "  weather_fields.append('temperature_{}_slots_ago'.format(prev_n))\n",
    "  weather_fields.append('pm25_{}_slots_ago'.format(prev_n))\n",
    "  orders_fields.append('gap_{}_slots_ago'.format(prev_n))\n",
    "  orders_fields.append('sum_price_{}_slots_ago'.format(prev_n))\n",
    "columns = ['district_id', 'timeslot', 'day_in_week', 'timeofday_slot'] + \\\n",
    "  traffic_fields + weather_fields + orders_fields + pois_fields + ['gap']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, get all timeslots to test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'2016-01-23-46','2016-01-23-58','2016-01-23-70','2016-01-23-82','2016-01-23-94','2016-01-23-106','2016-01-23-118','2016-01-23-130','2016-01-23-142','2016-01-25-58','2016-01-25-70','2016-01-25-82','2016-01-25-94','2016-01-25-106','2016-01-25-118','2016-01-25-130','2016-01-25-142','2016-01-27-46','2016-01-27-58','2016-01-27-70','2016-01-27-82','2016-01-27-94','2016-01-27-106','2016-01-27-118','2016-01-27-130','2016-01-27-142','2016-01-29-58','2016-01-29-70','2016-01-29-82','2016-01-29-94','2016-01-29-106','2016-01-29-118','2016-01-29-130','2016-01-29-142','2016-01-31-46','2016-01-31-58','2016-01-31-70','2016-01-31-82','2016-01-31-94','2016-01-31-106','2016-01-31-118','2016-01-31-130','2016-01-31-142'\n"
     ]
    }
   ],
   "source": [
    "# Get timeslots to test from GCS\n",
    "item = storage.Item('datalab-projects-1331-datalab','data/timeslots_to_test2.txt')\n",
    "all_timeslots = map(lambda x: x.strip(), item.read_from().strip().split('\\n'))\n",
    "tquery = ','.join(map(lambda x: \"'{}'\".format(x.strip()), all_timeslots))\n",
    "print(tquery)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From each timeslot, get three previous timeslots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2016-01-23-46', '2016-01-23-45', '2016-01-23-44', '2016-01-23-43', '2016-01-23-58', '2016-01-23-57', '2016-01-23-56', '2016-01-23-55', '2016-01-23-70', '2016-01-23-69', '2016-01-23-68', '2016-01-23-67', '2016-01-23-82', '2016-01-23-81', '2016-01-23-80', '2016-01-23-79', '2016-01-23-94', '2016-01-23-93', '2016-01-23-92', '2016-01-23-91', '2016-01-23-106', '2016-01-23-105', '2016-01-23-104', '2016-01-23-103', '2016-01-23-118', '2016-01-23-117', '2016-01-23-116', '2016-01-23-115', '2016-01-23-130', '2016-01-23-129', '2016-01-23-128', '2016-01-23-127', '2016-01-23-142', '2016-01-23-141', '2016-01-23-140', '2016-01-23-139', '2016-01-25-58', '2016-01-25-57', '2016-01-25-56', '2016-01-25-55', '2016-01-25-70', '2016-01-25-69', '2016-01-25-68', '2016-01-25-67', '2016-01-25-82', '2016-01-25-81', '2016-01-25-80', '2016-01-25-79', '2016-01-25-94', '2016-01-25-93', '2016-01-25-92', '2016-01-25-91', '2016-01-25-106', '2016-01-25-105', '2016-01-25-104', '2016-01-25-103', '2016-01-25-118', '2016-01-25-117', '2016-01-25-116', '2016-01-25-115', '2016-01-25-130', '2016-01-25-129', '2016-01-25-128', '2016-01-25-127', '2016-01-25-142', '2016-01-25-141', '2016-01-25-140', '2016-01-25-139', '2016-01-27-46', '2016-01-27-45', '2016-01-27-44', '2016-01-27-43', '2016-01-27-58', '2016-01-27-57', '2016-01-27-56', '2016-01-27-55', '2016-01-27-70', '2016-01-27-69', '2016-01-27-68', '2016-01-27-67', '2016-01-27-82', '2016-01-27-81', '2016-01-27-80', '2016-01-27-79', '2016-01-27-94', '2016-01-27-93', '2016-01-27-92', '2016-01-27-91', '2016-01-27-106', '2016-01-27-105', '2016-01-27-104', '2016-01-27-103', '2016-01-27-118', '2016-01-27-117', '2016-01-27-116', '2016-01-27-115', '2016-01-27-130', '2016-01-27-129', '2016-01-27-128', '2016-01-27-127', '2016-01-27-142', '2016-01-27-141', '2016-01-27-140', '2016-01-27-139', '2016-01-29-58', '2016-01-29-57', '2016-01-29-56', '2016-01-29-55', '2016-01-29-70', '2016-01-29-69', '2016-01-29-68', '2016-01-29-67', '2016-01-29-82', '2016-01-29-81', '2016-01-29-80', '2016-01-29-79', '2016-01-29-94', '2016-01-29-93', '2016-01-29-92', '2016-01-29-91', '2016-01-29-106', '2016-01-29-105', '2016-01-29-104', '2016-01-29-103', '2016-01-29-118', '2016-01-29-117', '2016-01-29-116', '2016-01-29-115', '2016-01-29-130', '2016-01-29-129', '2016-01-29-128', '2016-01-29-127', '2016-01-29-142', '2016-01-29-141', '2016-01-29-140', '2016-01-29-139', '2016-01-31-46', '2016-01-31-45', '2016-01-31-44', '2016-01-31-43', '2016-01-31-58', '2016-01-31-57', '2016-01-31-56', '2016-01-31-55', '2016-01-31-70', '2016-01-31-69', '2016-01-31-68', '2016-01-31-67', '2016-01-31-82', '2016-01-31-81', '2016-01-31-80', '2016-01-31-79', '2016-01-31-94', '2016-01-31-93', '2016-01-31-92', '2016-01-31-91', '2016-01-31-106', '2016-01-31-105', '2016-01-31-104', '2016-01-31-103', '2016-01-31-118', '2016-01-31-117', '2016-01-31-116', '2016-01-31-115', '2016-01-31-130', '2016-01-31-129', '2016-01-31-128', '2016-01-31-127', '2016-01-31-142', '2016-01-31-141', '2016-01-31-140', '2016-01-31-139']\n"
     ]
    }
   ],
   "source": [
    "prev_timeslots_flat = []\n",
    "prev_timeslots_dict = {}\n",
    "for timeslot in all_timeslots:\n",
    "  prev_timeslots_dict[timeslot] = []\n",
    "  for i in range(prev_n_range+1):\n",
    "    prev_n = i\n",
    "    prev_timeslot = calc_past_timeslot(timeslot, prev_n)\n",
    "    prev_timeslots_flat.append(prev_timeslot)\n",
    "    prev_timeslots_dict[timeslot].append(prev_timeslot)\n",
    "used = []\n",
    "prev_timeslots_flat = [x for x in prev_timeslots_flat if x not in used and (used.append(x) or True)]\n",
    "\n",
    "print prev_timeslots_flat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load all required data from previous timeslots from database."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Traffic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%sql --module q_traffic\n",
    "SELECT district_id, timeslot, tj_level1, tj_level2, tj_level3, tj_level4\n",
    "FROM xjk_algo_comp_test.traffic AS traffic\n",
    "JOIN xjk_algo_comp_test.districts AS districts\n",
    "  ON traffic.district_hash = districts.district_hash\n",
    "WHERE timeslot IN $timeslots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "traffic_df = bq.Query(q_traffic, timeslots=prev_timeslots_flat).to_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%sql --module q_weather\n",
    "SELECT * FROM xjk_algo_comp_test.weather\n",
    "WHERE timeslot IN $timeslots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weather_df = bq.Query(q_weather, timeslots=prev_timeslots_flat).to_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaps from Orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%sql --module q_order_gaps\n",
    "\n",
    "SELECT district_id, FIRST(orders.timeslot) AS timeslot, FIRST(orders.date) AS date,\n",
    "  FIRST(day_in_week) AS day_in_week, FIRST(timeofday_slot) AS timeofday_slot,\n",
    "  SUM(price) AS sum_price, AVG(price) AS avg_price,\n",
    "  IF(FIRST(timeofday_slot) >= 50 AND FIRST(timeofday_slot) <= 53, 1, 0) AS busy_time,\n",
    "  SUM(IF(driver_id = 'NULL', 1, 0)) AS gap\n",
    "FROM [datalab-projects-1331:xjk_algo_comp_test.orders] AS orders\n",
    "JOIN [datalab-projects-1331:xjk_algo_comp_test.districts] AS districts \n",
    "  ON orders.start_district_hash = districts.district_hash\n",
    "WHERE timeslot IN $timeslots\n",
    "GROUP BY district_id, orders.timeslot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "order_gaps_df = bq.Query(q_order_gaps, timeslots=prev_timeslots_flat).to_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## POIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1, f11, f11_1, f11_2, f11_3, f11_4, f11_5, f11_6, f11_7, f11_8, f13_4, f13_8, f14, f14_1, \n",
      "f14_10, f14_2, f14_3, f14_6, f14_8, f15, f15_1, f15_2, f15_3, f15_4, f15_6, f15_7, f15_8, \n",
      "f16, f16_1, f16_10, f16_11, f16_12, f16_3, f16_4, f16_6, f17, f17_2, f17_3, f17_4, f17_5, \n",
      "f19, f19_1, f19_2, f19_3, f19_4, f1_1, f1_10, f1_11, f1_2, f1_3, f1_4, f1_5, f1_6, \n",
      "f1_7, f1_8, f20, f20_1, f20_2, f20_4, f20_5, f20_6, f20_7, f20_8, f20_9, f21_1, f21_2, \n",
      "f22, f22_1, f22_2, f22_3, f22_4, f22_5, f23, f23_1, f23_2, f23_3, f23_4, f23_5, f23_6, \n",
      "f24, f24_1, f24_2, f24_3, f25, f25_1, f25_3, f25_7, f25_8, f25_9, f2_1, f2_10, f2_11, \n",
      "f2_12, f2_13, f2_2, f2_4, f2_5, f2_6, f2_7, f2_8, f3_1, f3_2, f3_3, f4, f4_1, \n",
      "f4_10, f4_11, f4_13, f4_14, f4_16, f4_17, f4_18, f4_2, f4_3, f4_5, f4_6, f4_7, f4_8, \n",
      "f4_9, f5, f5_1, f5_3, f5_4, f6, f6_1, f6_2, f6_4, f7, f8, f8_1, f8_2, \n",
      "f8_3, f8_4, f8_5\n"
     ]
    }
   ],
   "source": [
    "text = ''\n",
    "for counter, poi in enumerate(pois_fields):\n",
    "  text += '{}, '.format(poi)\n",
    "  if counter % 13 == 0 and counter > 0:\n",
    "    text += '\\n'\n",
    "print text.strip()[:len(text.strip())-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%sql --module q_pois\n",
    "SELECT district_id,\n",
    "f1, f11, f11_1, f11_2, f11_3, f11_4, f11_5, f11_6, f11_7, f11_8, f13_4, f13_8, f14, f14_1, \n",
    "f14_10, f14_2, f14_3, f14_6, f14_8, f15, f15_1, f15_2, f15_3, f15_4, f15_6, f15_7, f15_8, \n",
    "f16, f16_1, f16_10, f16_11, f16_12, f16_3, f16_4, f16_6, f17, f17_2, f17_3, f17_4, f17_5, \n",
    "f19, f19_1, f19_2, f19_3, f19_4, f1_1, f1_10, f1_11, f1_2, f1_3, f1_4, f1_5, f1_6, \n",
    "f1_7, f1_8, f20, f20_1, f20_2, f20_4, f20_5, f20_6, f20_7, f20_8, f20_9, f21_1, f21_2, \n",
    "f22, f22_1, f22_2, f22_3, f22_4, f22_5, f23, f23_1, f23_2, f23_3, f23_4, f23_5, f23_6, \n",
    "f24, f24_1, f24_2, f24_3, f25, f25_1, f25_3, f25_7, f25_8, f25_9, f2_1, f2_10, f2_11, \n",
    "f2_12, f2_13, f2_2, f2_4, f2_5, f2_6, f2_7, f2_8, f3_1, f3_2, f3_3, f4, f4_1, \n",
    "f4_10, f4_11, f4_13, f4_14, f4_16, f4_17, f4_18, f4_2, f4_3, f4_5, f4_6, f4_7, f4_8, \n",
    "f4_9, f5, f5_1, f5_3, f5_4, f6, f6_1, f6_2, f6_4, f7, f8, f8_1, f8_2, \n",
    "f8_3, f8_4, f8_5\n",
    "FROM xjk_algo_comp_test.pois AS pois\n",
    "JOIN xjk_algo_comp_test.districts AS districts ON districts.district_hash = pois.district_hash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pois_df = bq.Query(q_pois).to_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create **gaps** table. Each row of this table should contain all features from three previous timeslots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%sql --module q_districts\n",
    "\n",
    "SELECT district_id\n",
    "FROM xjk_algo_comp_test.districts\n",
    "ORDER BY district_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# When counter passes this limit, loads data to table and then resets dataframe.\n",
    "batch = 5000\n",
    "counter = 0\n",
    "\n",
    "gaps_df = pd.DataFrame(columns=columns)\n",
    "district_ids = [item['district_id'] for item in bq.Query(q_districts).results()]\n",
    "\n",
    "for timeslot in all_timeslots:\n",
    "  for district_id in district_ids:\n",
    "    timeslot_r = map(lambda x: int(x), timeslot.split('-'))\n",
    "    gap_data = {'timeslot': timeslot,\n",
    "                'day_in_week': date(timeslot_r[0], timeslot_r[1], timeslot_r[2]).weekday(),\n",
    "                'timeofday_slot': timeslot_r[3],\n",
    "                'district_id': int(district_id),\n",
    "                'gap': int(0)\n",
    "               }\n",
    "    poi_row = pois_df.loc[\n",
    "      (pois_df['district_id'] == district_id)\n",
    "    ]\n",
    "    for poi_field in pois_fields:\n",
    "      gap_data[poi_field] = poi_row.iloc[0][poi_field]\n",
    "    prev_gaps = order_gaps_df.loc[\n",
    "      (order_gaps_df['timeslot'].isin(prev_timeslots_dict[timeslot])) &\n",
    "      (order_gaps_df['district_id'] == district_id)\n",
    "    ]\n",
    "\n",
    "    for i in range(prev_n_range+1):\n",
    "      slot_diff = i\n",
    "      past_timeslot = calc_past_timeslot(timeslot, slot_diff)\n",
    "      prev_gap_loc = prev_gaps.loc[\n",
    "        prev_gaps['timeslot'] == past_timeslot\n",
    "      ]\n",
    "      if not prev_gap_loc.empty:\n",
    "        prev_gap = prev_gap_loc.iloc[0]\n",
    "        if prev_gap['timeslot'] == timeslot:\n",
    "          gap_data['gap'] = int(prev_gap['gap'])\n",
    "          gap_data['busy_time'] = prev_gap['busy_time']\n",
    "        else:\n",
    "          gap_data['gap_{}_slots_ago'.format(slot_diff)] = int(prev_gap['gap'])\n",
    "          gap_data['sum_price_{}_slots_ago'.format(slot_diff)] = prev_gap['sum_price']\n",
    "\n",
    "      if slot_diff > 0:\n",
    "        # There is a possibility that weather or traffic for previous\n",
    "        # slot does not get recorded, which means we need to get\n",
    "        # average weather conditions for other existing slots.\n",
    "\n",
    "        traffic_row = traffic_df.loc[\n",
    "          (traffic_df['timeslot'] == past_timeslot) &\n",
    "          (traffic_df['district_id'] == district_id)\n",
    "        ]\n",
    "        if not traffic_row.empty:\n",
    "          gap_data['tj_level1_{}_slots_ago'.format(slot_diff)] = traffic_row.iloc[0]['tj_level1']\n",
    "          gap_data['tj_level2_{}_slots_ago'.format(slot_diff)] = traffic_row.iloc[0]['tj_level2']\n",
    "          gap_data['tj_level3_{}_slots_ago'.format(slot_diff)] = traffic_row.iloc[0]['tj_level3']\n",
    "          gap_data['tj_level4_{}_slots_ago'.format(slot_diff)] = traffic_row.iloc[0]['tj_level4']\n",
    "        else:\n",
    "          # Traffic row is empty, lets get average of other three traffic rows\n",
    "          traffic_rows = traffic_df.loc[\n",
    "            (traffic_df['timeslot'].isin(prev_timeslots_dict[timeslot])) &\n",
    "            (traffic_df['district_id'] == district_id)\n",
    "          ]\n",
    "          gap_data['tj_level1_{}_slots_ago'.format(slot_diff)] = traffic_rows['tj_level1'].mean()\n",
    "          gap_data['tj_level2_{}_slots_ago'.format(slot_diff)] = traffic_rows['tj_level2'].mean()\n",
    "          gap_data['tj_level3_{}_slots_ago'.format(slot_diff)] = traffic_rows['tj_level3'].mean()\n",
    "          gap_data['tj_level4_{}_slots_ago'.format(slot_diff)] = traffic_rows['tj_level4'].mean()\n",
    "\n",
    "        weather_row = weather_df.loc[\n",
    "          (weather_df['timeslot']==past_timeslot)\n",
    "        ]\n",
    "        if not weather_row.empty:\n",
    "          gap_data['weather_{}_slots_ago'.format(slot_diff)] = weather_row.iloc[0]['weather']\n",
    "          gap_data['temperature_{}_slots_ago'.format(slot_diff)] = weather_row.iloc[0]['temperature']\n",
    "          gap_data['pm25_{}_slots_ago'.format(slot_diff)] = weather_row.iloc[0]['pm25']\n",
    "        else:\n",
    "          # Weather row is empty, lets get average of other three weather rows\n",
    "          weather_rows = weather_df.loc[\n",
    "            (weather_df['timeslot'].isin(prev_timeslots_dict[timeslot]))\n",
    "          ]\n",
    "          gap_data['weather_{}_slots_ago'.format(slot_diff)] = weather_rows['weather'].mean()\n",
    "          gap_data['temperature_{}_slots_ago'.format(slot_diff)] = weather_rows['temperature'].mean()\n",
    "          gap_data['pm25_{}_slots_ago'.format(slot_diff)] = weather_rows['pm25'].mean()\n",
    "  \n",
    "    gaps_df = gaps_df.append(gap_data, ignore_index=True)\n",
    "    counter += 1\n",
    "    if counter % 500 == 0:\n",
    "      print 'entered {} rows'.format(counter)\n",
    "gaps_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gaps_df.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gaps_df['district_id'] = gaps_df['district_id'].astype('int64')\n",
    "schema = []\n",
    "for index, column in enumerate(columns):\n",
    "  if index == 0:\n",
    "    schema.append({'name': column, 'type': 'INTEGER'})\n",
    "  elif index == 1:\n",
    "    schema.append({'name': column, 'type': 'STRING'})\n",
    "  else:\n",
    "    schema.append({'name': column, 'type': 'FLOAT'})\n",
    "table = bq.Table('datalab-projects-1331:xjk_algo_comp_test.gaps')\n",
    "if not table.exists():\n",
    "  table.create(bq.Schema(schema))\n",
    "\n",
    "table.insert_data(gaps_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
